{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LO4T_SbqKxwP"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?id=1f1gGVI-rxcHjA90WEGNvvtSXF1pAxQwg\" alt=\"Fasilkom UI\" width=\"300\"/>\n",
        "\n",
        "CSGE603130 â€¢ Kecerdasan Artifisial dan Sains Data Dasar\n",
        "\n",
        "Semester Ganjil 2022/2023\n",
        "\n",
        "Fakultas Ilmu Komputer, Universitas Indonesia\n",
        "\n",
        "##*Lab 4*: CART\n",
        "\n",
        "###**Tenggat Waktu: 8 Oktober 2023, 23.55 WIB**\n",
        "</center>\n",
        "\n",
        "####**Ketentuan:**\n",
        "\n",
        "1. Dokumen *template* lab dengan format .ipynb dan dataset (jika dibutuhkan) telah disediakan di SCeLe\n",
        "2. Jalankan kode pada dokumen .ipynb dan perhatikan dengan saksama apa yang potongan kode tersebut lakukan beserta dengan keluarannya. Jawablah **pertanyaan yang disisipkan** pada potongan program yang diberikan.\n",
        "3. Dokumen Jupyter Notebook yang telah dilengkapi dengan jawaban dikumpulkan dengan format penamaan **Kelas_LabX_NPM_Nama.ipynb**. Contoh: A_Lab4_2006123456_Budi.ipynb\n",
        "4. Kumpulkan dokumen tersebut pada submisi yang telah disediakan di SCeLe sesuai dengan kelas masing-masing sebelum **8 Oktober 2023, 23.55 WIB**. Keterlambatan pengumpulan akan dikenakan pinalti.\n",
        "5. Lab ini dirancang sebagai **tugas mandiri**. Plagiarisme tidak diperkenankan dalam bentuk apapun. Adapun kolaborasi berupa diskusi (tanpa menyalin maupun mengambil jawaban orang lain) dan literasi masih diperbolehkan dengan mencantumkan kolaborator dan sumber.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9cZkSNOLL2C"
      },
      "source": [
        "## **Pernyataan Integritas**\n",
        "\n",
        "Wajib diisi. Tanpa pernyataan integritas submisi akan dikenakan pinalti."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cLRtSkLqLAhE"
      },
      "outputs": [],
      "source": [
        "# Isi dengan data diri Anda\n",
        "NAMA = \"Jeremy Mervin\"\n",
        "KELAS = \"E\"\n",
        "NPM = \"2106654675\"\n",
        "\n",
        "# Isi dengan NPM teman yang berdiskusi dengan Anda\n",
        "KOLABORATOR = []\n",
        "\n",
        "# Isi dengan sumber referensi yang Anda gunakan dalam mengerjakan\n",
        "REFERENSI = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "oLXYmDNaLjqM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60135fb2-77db-4bed-bec2-6590d56859da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saya, Jeremy Mervin dari kelas E dengan NPM 2106654675, menyatakan bahwa seluruh jawaban pada pekerjaan ini murni saya kerjakan sendiri.\n",
            "Saya tidak mencontek jawaban, memberikan jawaban, maupun menyalin dari sumber manapun.\n",
            " \n",
            "Jika saya melanggar pernyataan tersebut, saya siap menerima konsekuensi apapun yang diberikan.\n",
            "   (Jeremy Mervin)\n"
          ]
        }
      ],
      "source": [
        "PERNYATAAN_INTEGRITAS = \"Saya, %s dari kelas %s dengan NPM %s, menyatakan bahwa seluruh jawaban pada pekerjaan ini murni saya kerjakan sendiri.\\n\\\n",
        "Saya tidak mencontek jawaban, memberikan jawaban, maupun menyalin dari sumber manapun.\\n \\\n",
        "\\n\\\n",
        "Jika saya melanggar pernyataan tersebut, saya siap menerima konsekuensi apapun yang diberikan.\\n   \\\n",
        "(%s)\" % (NAMA, KELAS, NPM, NAMA)\n",
        "\n",
        "print(PERNYATAAN_INTEGRITAS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3wTrRJxZ_LI"
      },
      "source": [
        "## Deskripsi Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBKCryIZaB_X"
      },
      "source": [
        "Lab ini akan menggunakan 2 dataset, yakni dataset untuk klasifikasi dan dataset untuk regresi.\n",
        "\n",
        "Dataset yang digunakan untuk klasifikasi adalah dataset **Red Wine Quality** (https://www.kaggle.com/datasets/uciml/red-wine-quality-cortez-et-al-2009) dengan modifikasi.\n",
        "\n",
        "Dataset yang akan digunakan untuk regresi adalah dataset **Graduate Admission 2** (https://www.kaggle.com/datasets/mohansacharya/graduate-admissions) dengan modifikasi."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMzukLM_k5AI"
      },
      "source": [
        "### Deskripsi Dataset Klasifikasi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgA_G-p1lADc"
      },
      "source": [
        "Dataset ini berisi informasi mengenai atribut-atribut yang dirasa berpengaruh terhadap kualitas dari suatu Red Wine yang diukur dengan angka 0 sampai dengan 10 (Quality).\n",
        "\n",
        "Atribut-atribut yang terdapat pada dataset ini adalah sebagai berikut:\n",
        "\n",
        "\n",
        "*   **Fixed Acidity**: Sebagian besar asam yang terlibat dalam anggur adalah asam tetap atau tidak mudah menguap (tidak menguap dengan mudah).\n",
        "*   **Volatile Acidity**: Jumlah asam asetat dalam anggur, yang pada kadar yang terlalu tinggi dapat menyebabkan rasa cuka yang tidak enak.\n",
        "*   **Citric Acid**: Ditemukan dalam jumlah kecil, asam sitrat dapat menambahkan 'kesegaran' dan rasa pada anggur.\n",
        "*   **Residual Sugar**: Jumlah gula yang tersisa setelah fermentasi berhenti.\n",
        "*   **Chlorides**: Jumlah kadar garam pada wine.\n",
        "*   **Free Sulfur Dioxide**: Bentuk bebas SO2 ada dalam keseimbangan antara SO2 molekuler (sebagai gas terlarut) dan ion bisulfit.\n",
        "*   **Total Sulfur Dioxide**: Jumlah bentuk bebas dan terikat dari SO2.\n",
        "*   **Density**: Kepadatan air tergantung pada persentase alkohol dan kandungan gula.\n",
        "*   **pH**: Menggambarkan seberapa asam atau basa suatu anggur pada skala dari 0 (sangat asam) hingga 14 (sangat basa).\n",
        "*   **Sulphates**: Sebuah tambahan untuk anggur yang dapat berkontribusi pada tingkat gas sulfur dioksida (SO2).\n",
        "*   **Alcohol**: Persentase kandungan alkohol dalam anggur.\n",
        "*   **Quality**: Variabel keluaran (berdasarkan data sensori, skor antara 0 dan 10).\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WEpRisif6Wb"
      },
      "source": [
        "### Deskripsi Dataset Regresi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z16Rms0val0H"
      },
      "source": [
        "Dataset ini berisi informasi mengenai atribut-atribut yang dirasa berpengaruh terhadap besarnya peluang (Chance of Admit) dari seorang pelamar untuk diterima pada program Magister-nya di daerah India.\n",
        "\n",
        "Atribut-atribut yang terdapat pada dataset ini adalah sebagai berikut:\n",
        "\n",
        "\n",
        "\n",
        "*   **GRE Scores (out of 340)**: Skor yang diperoleh oleh calon pelamar pada tes GRE.\n",
        "*   **TOEFL Scores (out of 120)**: Skor yang diperoleh oleh calon pelamar pada tes TOEFL.\n",
        "*   **University Rating (out of 5)**: Rating universitas yang didaftar oleh calon pelamar.\n",
        "*  **Statement of Purpose and Letter of Recommendation Strength (out of 5)**: Skor yang diperoleh dari surat rekomendasi yang dilampirkan oleh calon pelamar.\n",
        "*   **Undergraduate GPA (out of 10)**: GPA yang diperoleh oleh calon pelamar pada saat masa *undergraduate*.\n",
        "*   **Research Experience (either 0 or 1)**: Ada/tidaknya pengalaman meneliti yang dimiliki oleh calon pelamar. 0 berarti tidak, 1 berarti iya.\n",
        "*   **Chance of Admit (ranging from 0 to 1)**: Peluang diterimanya calon pelamar pada suatu universitas dengan skor-skor yang dimilikinya."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lbgDIfi3x8U"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "SmX8CPR63zY7"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
        "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn import tree\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import graphviz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzVC1D-XsuVS"
      },
      "source": [
        "## Read Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bacalah konten dari masing-masing dataset yang telah disediakan. Perhatikan tipe data dari masing-masing kolom, apakah sudah cocok untuk dijadikan input ke dalam model atau tidak.**"
      ],
      "metadata": {
        "id": "-eDrSLUsw971"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VTBROQgswup"
      },
      "source": [
        "### Dataset Red Wine"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Terapkan proses Read Dataset di bawah cell ini**"
      ],
      "metadata": {
        "id": "mZ4UBfodxLo6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_wine = pd.read_csv('Red_Wine_Quality_Train.csv')"
      ],
      "metadata": {
        "id": "UNWDa6sK-3cF"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9j1zqc9F1exw"
      },
      "source": [
        "### Dataset Admission Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Terapkan proses Read Dataset di bawah cell ini**"
      ],
      "metadata": {
        "id": "apnpZhkcxdfx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_admission = pd.read_csv('Admission_Prediction_Train.csv')"
      ],
      "metadata": {
        "id": "5inNitpG-4Jc"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MoSpnBpL2tkQ"
      },
      "source": [
        "## SOAL 1 Data Pre-processing [20]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Terapkanlah proses data pre-processing pada bagian ini agar dataset yang telah diberikan dapat dijadikan input dari model yang akan kalian buat. Terapkan proses tersebut untuk masing-masing dataset (Red Wine & Admission Prediction) hingga dataset terbagi menjadi train dan test**"
      ],
      "metadata": {
        "id": "aRFPlQC667kl"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyQew-2S4Jz6"
      },
      "source": [
        "### Dataset Red Wine"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Terapkan proses data pre-processing di bawah cell ini**"
      ],
      "metadata": {
        "id": "UGwT5g6cwdO5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Melihat shape dari dataframe\n",
        "total_rows, total_attributes = df_wine.shape\n",
        "print('Jumlah data:', total_rows)\n",
        "print(\"Jumlah atribut:\", total_attributes)\n",
        "\n",
        "# Melihat 5 elemen pertama dari dataset\n",
        "df_wine.head()"
      ],
      "metadata": {
        "id": "updpuyORMThB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "e5b5203a-f0ca-4d34-f177-e9b6d64957da"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jumlah data: 3466\n",
            "Jumlah atribut: 12\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
              "0      12.200000          0.450000     0.490000        1.400000   0.075000   \n",
              "1       7.100000          0.430000     0.170000        1.800000   0.082000   \n",
              "2       7.784053          0.280000     0.303572        1.993696   0.061832   \n",
              "3       7.960832          0.762917     0.015375        2.490418   0.085412   \n",
              "4       7.700000          0.705000     0.100000        2.600000   0.084000   \n",
              "\n",
              "   free sulfur dioxide  total sulfur dioxide   density        pH  sulphates  \\\n",
              "0             3.000000              6.000000  0.996900  3.130000   0.630000   \n",
              "1            27.000000             51.000000  0.996340  3.490000   0.640000   \n",
              "2            17.978987             33.957974  0.995235  3.277268   0.895167   \n",
              "3            13.341669             26.512503  0.997363  3.376833   0.470250   \n",
              "4             9.000000             26.000000  0.997600  3.390000   0.490000   \n",
              "\n",
              "     alcohol  quality  \n",
              "0  10.400000        5  \n",
              "1  10.400000        5  \n",
              "2  11.285291        7  \n",
              "3   9.856252        4  \n",
              "4   9.700000        5  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a1ed533c-734c-46f2-ac9f-687fe5ec23b1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fixed acidity</th>\n",
              "      <th>volatile acidity</th>\n",
              "      <th>citric acid</th>\n",
              "      <th>residual sugar</th>\n",
              "      <th>chlorides</th>\n",
              "      <th>free sulfur dioxide</th>\n",
              "      <th>total sulfur dioxide</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>quality</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12.200000</td>\n",
              "      <td>0.450000</td>\n",
              "      <td>0.490000</td>\n",
              "      <td>1.400000</td>\n",
              "      <td>0.075000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.996900</td>\n",
              "      <td>3.130000</td>\n",
              "      <td>0.630000</td>\n",
              "      <td>10.400000</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.100000</td>\n",
              "      <td>0.430000</td>\n",
              "      <td>0.170000</td>\n",
              "      <td>1.800000</td>\n",
              "      <td>0.082000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>0.996340</td>\n",
              "      <td>3.490000</td>\n",
              "      <td>0.640000</td>\n",
              "      <td>10.400000</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.784053</td>\n",
              "      <td>0.280000</td>\n",
              "      <td>0.303572</td>\n",
              "      <td>1.993696</td>\n",
              "      <td>0.061832</td>\n",
              "      <td>17.978987</td>\n",
              "      <td>33.957974</td>\n",
              "      <td>0.995235</td>\n",
              "      <td>3.277268</td>\n",
              "      <td>0.895167</td>\n",
              "      <td>11.285291</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7.960832</td>\n",
              "      <td>0.762917</td>\n",
              "      <td>0.015375</td>\n",
              "      <td>2.490418</td>\n",
              "      <td>0.085412</td>\n",
              "      <td>13.341669</td>\n",
              "      <td>26.512503</td>\n",
              "      <td>0.997363</td>\n",
              "      <td>3.376833</td>\n",
              "      <td>0.470250</td>\n",
              "      <td>9.856252</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.700000</td>\n",
              "      <td>0.705000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>2.600000</td>\n",
              "      <td>0.084000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.997600</td>\n",
              "      <td>3.390000</td>\n",
              "      <td>0.490000</td>\n",
              "      <td>9.700000</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a1ed533c-734c-46f2-ac9f-687fe5ec23b1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a1ed533c-734c-46f2-ac9f-687fe5ec23b1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a1ed533c-734c-46f2-ac9f-687fe5ec23b1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-21506d52-4017-4f1c-9b3f-3edaad53f249\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-21506d52-4017-4f1c-9b3f-3edaad53f249')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-21506d52-4017-4f1c-9b3f-3edaad53f249 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Melihat kolom-kolom pada dataframe\n",
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnmJsbZF_7OP",
        "outputId": "71a70e5e-b055-48a3-f2ce-df1a56c05adc"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3466 entries, 0 to 3465\n",
            "Data columns (total 12 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   fixed acidity         3466 non-null   float64\n",
            " 1   volatile acidity      3466 non-null   float64\n",
            " 2   citric acid           3466 non-null   float64\n",
            " 3   residual sugar        3466 non-null   float64\n",
            " 4   chlorides             3466 non-null   float64\n",
            " 5   free sulfur dioxide   3466 non-null   float64\n",
            " 6   total sulfur dioxide  3466 non-null   float64\n",
            " 7   density               3466 non-null   float64\n",
            " 8   pH                    3466 non-null   float64\n",
            " 9   sulphates             3466 non-null   float64\n",
            " 10  alcohol               3466 non-null   float64\n",
            " 11  quality               3466 non-null   int64  \n",
            "dtypes: float64(11), int64(1)\n",
            "memory usage: 325.1 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Membaca duplikasi data\n",
        "\n",
        "duplicates_wine = df_wine[df_wine.duplicated()]\n",
        "\n",
        "rows = duplicates_wine.count()[0]\n",
        "\n",
        "print(\"jumlah duplikasi baris: \")\n",
        "rows"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSDRYNqTAPYf",
        "outputId": "204699b6-1f8b-48e5-c05a-39f566fea6a4"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "jumlah duplikasi baris: \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "242"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Menangani duplikasi data\n",
        "\n",
        "drop_duplicates_wine = df_wine.drop_duplicates(subset=None, keep='first', inplace=False, ignore_index=False)\n",
        "\n",
        "drop_duplicates_wine"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "GLIWXr5RAgsi",
        "outputId": "0181b991-a4be-4030-b0d9-e751b3cbc383"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
              "0         12.200000          0.450000     0.490000        1.400000   0.075000   \n",
              "1          7.100000          0.430000     0.170000        1.800000   0.082000   \n",
              "2          7.784053          0.280000     0.303572        1.993696   0.061832   \n",
              "3          7.960832          0.762917     0.015375        2.490418   0.085412   \n",
              "4          7.700000          0.705000     0.100000        2.600000   0.084000   \n",
              "...             ...               ...          ...             ...        ...   \n",
              "3459       7.739080          0.747077     0.029631        2.759688   0.082086   \n",
              "3460       6.794068          0.811737     0.001186        1.235593   0.255788   \n",
              "3461       8.285252          1.017603     0.020000        3.385252   0.083945   \n",
              "3463       7.873784          0.350633     0.458011        3.585536   0.077837   \n",
              "3465       5.787771          0.925706     0.078195        1.423872   0.053355   \n",
              "\n",
              "      free sulfur dioxide  total sulfur dioxide   density        pH  \\\n",
              "0                3.000000              6.000000  0.996900  3.130000   \n",
              "1               27.000000             51.000000  0.996340  3.490000   \n",
              "2               17.978987             33.957974  0.995235  3.277268   \n",
              "3               13.341669             26.512503  0.997363  3.376833   \n",
              "4                9.000000             26.000000  0.997600  3.390000   \n",
              "...                   ...                   ...       ...       ...   \n",
              "3459            13.658457             26.987685  0.996957  3.383169   \n",
              "3460            15.406785             27.991534  0.994787  3.333644   \n",
              "3461             6.000000             11.009217  0.998893  3.480645   \n",
              "3463            15.036160             37.117519  0.997249  3.353345   \n",
              "3465            37.657942             93.116426  0.994612  3.609156   \n",
              "\n",
              "      sulphates    alcohol  quality  \n",
              "0      0.630000  10.400000        5  \n",
              "1      0.640000  10.400000        5  \n",
              "2      0.895167  11.285291        7  \n",
              "3      0.470250   9.856252        4  \n",
              "4      0.490000   9.700000        5  \n",
              "...         ...        ...      ...  \n",
              "3459   0.479754  10.093843        4  \n",
              "3460   0.517119   9.808898        3  \n",
              "3461   0.491290  10.990322        3  \n",
              "3463   0.858915  12.810848        8  \n",
              "3465   0.632780  10.165794        4  \n",
              "\n",
              "[3224 rows x 12 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-13baa519-5fc2-4725-aae5-4cfe3390c0c6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fixed acidity</th>\n",
              "      <th>volatile acidity</th>\n",
              "      <th>citric acid</th>\n",
              "      <th>residual sugar</th>\n",
              "      <th>chlorides</th>\n",
              "      <th>free sulfur dioxide</th>\n",
              "      <th>total sulfur dioxide</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>quality</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12.200000</td>\n",
              "      <td>0.450000</td>\n",
              "      <td>0.490000</td>\n",
              "      <td>1.400000</td>\n",
              "      <td>0.075000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.996900</td>\n",
              "      <td>3.130000</td>\n",
              "      <td>0.630000</td>\n",
              "      <td>10.400000</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.100000</td>\n",
              "      <td>0.430000</td>\n",
              "      <td>0.170000</td>\n",
              "      <td>1.800000</td>\n",
              "      <td>0.082000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>0.996340</td>\n",
              "      <td>3.490000</td>\n",
              "      <td>0.640000</td>\n",
              "      <td>10.400000</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.784053</td>\n",
              "      <td>0.280000</td>\n",
              "      <td>0.303572</td>\n",
              "      <td>1.993696</td>\n",
              "      <td>0.061832</td>\n",
              "      <td>17.978987</td>\n",
              "      <td>33.957974</td>\n",
              "      <td>0.995235</td>\n",
              "      <td>3.277268</td>\n",
              "      <td>0.895167</td>\n",
              "      <td>11.285291</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7.960832</td>\n",
              "      <td>0.762917</td>\n",
              "      <td>0.015375</td>\n",
              "      <td>2.490418</td>\n",
              "      <td>0.085412</td>\n",
              "      <td>13.341669</td>\n",
              "      <td>26.512503</td>\n",
              "      <td>0.997363</td>\n",
              "      <td>3.376833</td>\n",
              "      <td>0.470250</td>\n",
              "      <td>9.856252</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.700000</td>\n",
              "      <td>0.705000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>2.600000</td>\n",
              "      <td>0.084000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.997600</td>\n",
              "      <td>3.390000</td>\n",
              "      <td>0.490000</td>\n",
              "      <td>9.700000</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3459</th>\n",
              "      <td>7.739080</td>\n",
              "      <td>0.747077</td>\n",
              "      <td>0.029631</td>\n",
              "      <td>2.759688</td>\n",
              "      <td>0.082086</td>\n",
              "      <td>13.658457</td>\n",
              "      <td>26.987685</td>\n",
              "      <td>0.996957</td>\n",
              "      <td>3.383169</td>\n",
              "      <td>0.479754</td>\n",
              "      <td>10.093843</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3460</th>\n",
              "      <td>6.794068</td>\n",
              "      <td>0.811737</td>\n",
              "      <td>0.001186</td>\n",
              "      <td>1.235593</td>\n",
              "      <td>0.255788</td>\n",
              "      <td>15.406785</td>\n",
              "      <td>27.991534</td>\n",
              "      <td>0.994787</td>\n",
              "      <td>3.333644</td>\n",
              "      <td>0.517119</td>\n",
              "      <td>9.808898</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3461</th>\n",
              "      <td>8.285252</td>\n",
              "      <td>1.017603</td>\n",
              "      <td>0.020000</td>\n",
              "      <td>3.385252</td>\n",
              "      <td>0.083945</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>11.009217</td>\n",
              "      <td>0.998893</td>\n",
              "      <td>3.480645</td>\n",
              "      <td>0.491290</td>\n",
              "      <td>10.990322</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3463</th>\n",
              "      <td>7.873784</td>\n",
              "      <td>0.350633</td>\n",
              "      <td>0.458011</td>\n",
              "      <td>3.585536</td>\n",
              "      <td>0.077837</td>\n",
              "      <td>15.036160</td>\n",
              "      <td>37.117519</td>\n",
              "      <td>0.997249</td>\n",
              "      <td>3.353345</td>\n",
              "      <td>0.858915</td>\n",
              "      <td>12.810848</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3465</th>\n",
              "      <td>5.787771</td>\n",
              "      <td>0.925706</td>\n",
              "      <td>0.078195</td>\n",
              "      <td>1.423872</td>\n",
              "      <td>0.053355</td>\n",
              "      <td>37.657942</td>\n",
              "      <td>93.116426</td>\n",
              "      <td>0.994612</td>\n",
              "      <td>3.609156</td>\n",
              "      <td>0.632780</td>\n",
              "      <td>10.165794</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3224 rows Ã— 12 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-13baa519-5fc2-4725-aae5-4cfe3390c0c6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-13baa519-5fc2-4725-aae5-4cfe3390c0c6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-13baa519-5fc2-4725-aae5-4cfe3390c0c6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0d99a873-8c60-4dbb-8237-3f5b43c98f75\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0d99a873-8c60-4dbb-8237-3f5b43c98f75')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0d99a873-8c60-4dbb-8237-3f5b43c98f75 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79z1IdWu4MSA"
      },
      "source": [
        "### Dataset Admission Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Terapkan proses data pre-processing di bawah cell ini**"
      ],
      "metadata": {
        "id": "ka-r6a9wwicX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Melihat shape dari dataframe\n",
        "total_rows, total_attributes = df_admission.shape\n",
        "print('Jumlah data:', total_rows)\n",
        "print(\"Jumlah atribut:\", total_attributes)\n",
        "\n",
        "# Melihat 5 elemen pertama dari dataset\n",
        "df_admission.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "id": "RvrLyBAA_OIi",
        "outputId": "ff822e7d-1cff-4c0c-cf03-fbf3e5c5b33b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jumlah data: 350\n",
            "Jumlah atribut: 10\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0  Serial No.  GRE Score  TOEFL Score  University Rating  SOP  \\\n",
              "0           5           6        330          115                  5  4.5   \n",
              "1         116         117        299          102                  3  4.0   \n",
              "2          45          46        322          110                  5  5.0   \n",
              "3          16          17        317          107                  3  4.0   \n",
              "4         462         463        307          105                  4  3.0   \n",
              "\n",
              "   LOR   CGPA  Research  Chance of Admit  \n",
              "0   3.0  9.34         1             0.90  \n",
              "1   3.5  8.62         0             0.56  \n",
              "2   4.0  9.10         1             0.88  \n",
              "3   3.0  8.70         0             0.66  \n",
              "4   3.0  7.94         0             0.62  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6d855f3d-bdbf-478b-9ccd-6cad6b18e009\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Serial No.</th>\n",
              "      <th>GRE Score</th>\n",
              "      <th>TOEFL Score</th>\n",
              "      <th>University Rating</th>\n",
              "      <th>SOP</th>\n",
              "      <th>LOR</th>\n",
              "      <th>CGPA</th>\n",
              "      <th>Research</th>\n",
              "      <th>Chance of Admit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>330</td>\n",
              "      <td>115</td>\n",
              "      <td>5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>9.34</td>\n",
              "      <td>1</td>\n",
              "      <td>0.90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>116</td>\n",
              "      <td>117</td>\n",
              "      <td>299</td>\n",
              "      <td>102</td>\n",
              "      <td>3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>8.62</td>\n",
              "      <td>0</td>\n",
              "      <td>0.56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>45</td>\n",
              "      <td>46</td>\n",
              "      <td>322</td>\n",
              "      <td>110</td>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>9.10</td>\n",
              "      <td>1</td>\n",
              "      <td>0.88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>16</td>\n",
              "      <td>17</td>\n",
              "      <td>317</td>\n",
              "      <td>107</td>\n",
              "      <td>3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>8.70</td>\n",
              "      <td>0</td>\n",
              "      <td>0.66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>462</td>\n",
              "      <td>463</td>\n",
              "      <td>307</td>\n",
              "      <td>105</td>\n",
              "      <td>4</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>7.94</td>\n",
              "      <td>0</td>\n",
              "      <td>0.62</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6d855f3d-bdbf-478b-9ccd-6cad6b18e009')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6d855f3d-bdbf-478b-9ccd-6cad6b18e009 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6d855f3d-bdbf-478b-9ccd-6cad6b18e009');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-37f49234-f9e6-4e3f-b6bc-2cad62e33b5d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-37f49234-f9e6-4e3f-b6bc-2cad62e33b5d')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-37f49234-f9e6-4e3f-b6bc-2cad62e33b5d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_admission.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ha_3WPjbAr4R",
        "outputId": "b064e23e-f9a4-4222-fa84-9a643de60d96"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 350 entries, 0 to 349\n",
            "Data columns (total 10 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   Unnamed: 0         350 non-null    int64  \n",
            " 1   Serial No.         350 non-null    int64  \n",
            " 2   GRE Score          350 non-null    int64  \n",
            " 3   TOEFL Score        350 non-null    int64  \n",
            " 4   University Rating  350 non-null    int64  \n",
            " 5   SOP                350 non-null    float64\n",
            " 6   LOR                350 non-null    float64\n",
            " 7   CGPA               350 non-null    float64\n",
            " 8   Research           350 non-null    int64  \n",
            " 9   Chance of Admit    350 non-null    float64\n",
            "dtypes: float64(4), int64(6)\n",
            "memory usage: 27.5 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Membaca duplikasi data\n",
        "\n",
        "duplicates_admission = df_admission[df_admission.duplicated()]\n",
        "\n",
        "rows = duplicates_admission.count()[0]\n",
        "\n",
        "print(\"jumlah duplikasi baris: \")\n",
        "rows"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3PSBZxAAsK4",
        "outputId": "8bb4e43f-25b1-4e0b-d395-89a1cb9a44f9"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "jumlah duplikasi baris: \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Menangani duplikasi data\n",
        "\n",
        "drop_duplicates_admission = df_admission.drop_duplicates(subset=None, keep='first', inplace=False, ignore_index=False)\n",
        "\n",
        "drop_duplicates_admission"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "eJnmRBurBEQT",
        "outputId": "6f4cb3d0-9003-4b3f-c629-1b75ccf3dbea"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Unnamed: 0  Serial No.  GRE Score  TOEFL Score  University Rating  SOP  \\\n",
              "0             5           6        330          115                  5  4.5   \n",
              "1           116         117        299          102                  3  4.0   \n",
              "2            45          46        322          110                  5  5.0   \n",
              "3            16          17        317          107                  3  4.0   \n",
              "4           462         463        307          105                  4  3.0   \n",
              "..          ...         ...        ...          ...                ...  ...   \n",
              "345         106         107        329          111                  4  4.5   \n",
              "346         270         271        306          105                  2  2.5   \n",
              "347         348         349        302           99                  1  2.0   \n",
              "348         435         436        309          105                  2  2.5   \n",
              "349         102         103        314          106                  2  4.0   \n",
              "\n",
              "     LOR   CGPA  Research  Chance of Admit  \n",
              "0     3.0  9.34         1             0.90  \n",
              "1     3.5  8.62         0             0.56  \n",
              "2     4.0  9.10         1             0.88  \n",
              "3     3.0  8.70         0             0.66  \n",
              "4     3.0  7.94         0             0.62  \n",
              "..    ...   ...       ...              ...  \n",
              "345   4.5  9.18         1             0.87  \n",
              "346   3.0  8.22         1             0.72  \n",
              "347   2.0  7.25         0             0.57  \n",
              "348   4.0  7.68         0             0.55  \n",
              "349   3.5  8.25         0             0.62  \n",
              "\n",
              "[350 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fd50c5e6-cfac-45b9-b22d-6501f0305307\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Serial No.</th>\n",
              "      <th>GRE Score</th>\n",
              "      <th>TOEFL Score</th>\n",
              "      <th>University Rating</th>\n",
              "      <th>SOP</th>\n",
              "      <th>LOR</th>\n",
              "      <th>CGPA</th>\n",
              "      <th>Research</th>\n",
              "      <th>Chance of Admit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>330</td>\n",
              "      <td>115</td>\n",
              "      <td>5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>9.34</td>\n",
              "      <td>1</td>\n",
              "      <td>0.90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>116</td>\n",
              "      <td>117</td>\n",
              "      <td>299</td>\n",
              "      <td>102</td>\n",
              "      <td>3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>8.62</td>\n",
              "      <td>0</td>\n",
              "      <td>0.56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>45</td>\n",
              "      <td>46</td>\n",
              "      <td>322</td>\n",
              "      <td>110</td>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>9.10</td>\n",
              "      <td>1</td>\n",
              "      <td>0.88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>16</td>\n",
              "      <td>17</td>\n",
              "      <td>317</td>\n",
              "      <td>107</td>\n",
              "      <td>3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>8.70</td>\n",
              "      <td>0</td>\n",
              "      <td>0.66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>462</td>\n",
              "      <td>463</td>\n",
              "      <td>307</td>\n",
              "      <td>105</td>\n",
              "      <td>4</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>7.94</td>\n",
              "      <td>0</td>\n",
              "      <td>0.62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>345</th>\n",
              "      <td>106</td>\n",
              "      <td>107</td>\n",
              "      <td>329</td>\n",
              "      <td>111</td>\n",
              "      <td>4</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>9.18</td>\n",
              "      <td>1</td>\n",
              "      <td>0.87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>346</th>\n",
              "      <td>270</td>\n",
              "      <td>271</td>\n",
              "      <td>306</td>\n",
              "      <td>105</td>\n",
              "      <td>2</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>8.22</td>\n",
              "      <td>1</td>\n",
              "      <td>0.72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>347</th>\n",
              "      <td>348</td>\n",
              "      <td>349</td>\n",
              "      <td>302</td>\n",
              "      <td>99</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>7.25</td>\n",
              "      <td>0</td>\n",
              "      <td>0.57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>348</th>\n",
              "      <td>435</td>\n",
              "      <td>436</td>\n",
              "      <td>309</td>\n",
              "      <td>105</td>\n",
              "      <td>2</td>\n",
              "      <td>2.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>7.68</td>\n",
              "      <td>0</td>\n",
              "      <td>0.55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>349</th>\n",
              "      <td>102</td>\n",
              "      <td>103</td>\n",
              "      <td>314</td>\n",
              "      <td>106</td>\n",
              "      <td>2</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>8.25</td>\n",
              "      <td>0</td>\n",
              "      <td>0.62</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>350 rows Ã— 10 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fd50c5e6-cfac-45b9-b22d-6501f0305307')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fd50c5e6-cfac-45b9-b22d-6501f0305307 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fd50c5e6-cfac-45b9-b22d-6501f0305307');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c9300580-c226-40f6-92bd-717ed9b524ca\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c9300580-c226-40f6-92bd-717ed9b524ca')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c9300580-c226-40f6-92bd-717ed9b524ca button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWBcCbHY5Suz"
      },
      "source": [
        "## CART (Classification and Regression Tree)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QA9DnAF5d6O"
      },
      "source": [
        "### Decision Tree\n",
        "\n",
        "Decision Tree merupakan model yang beroperasi dengan struktur berbentuk Binary Tree, di mana setiap node hanya dapat memiliki dua child node paling banyak. Dalam bidang data science, model ini diterapkan dalam konteks Supervised Learning, yaitu model dibentuk berdasarkan data training dan selanjutnya digunakan untuk membuat prediksi terhadap data yang disajikan. Data training yang digunakan akan diolah menjadi sebuah rangkaian aturan dalam bentuk Binary Tree. Aturan-aturan ini selanjutnya digunakan untuk proses prediksi pada dataset lain."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bircVGkQ6PJk"
      },
      "source": [
        "#### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function di bawah ini merupakan function yang dapat digunakan untuk menghitung metrics hasil testing, baik untuk kasus regresi, maupun kasus klasifikasi."
      ],
      "metadata": {
        "id": "xf4OnGAi2Aac"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "gilISJfn6TLq"
      },
      "outputs": [],
      "source": [
        "# https://medium.com/analytics-vidhya/evaluation-metrics-for-regression-models-c91c65d73af\n",
        "def regression_metrics(prediction, y_test):\n",
        "    MAE = mean_absolute_error(y_test, prediction)\n",
        "    MSE = mean_squared_error(y_test, prediction)\n",
        "    RMSE = np.sqrt(MSE)\n",
        "    R_squared = r2_score(y_test, prediction)\n",
        "\n",
        "    print('MAE: ' + str(MAE))\n",
        "    print('MSE: ' + str(MSE))\n",
        "    print('RMSE: ' + str(RMSE))\n",
        "    print('R_squared: ' + str(R_squared))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "e6kJCWmI6uQq"
      },
      "outputs": [],
      "source": [
        "def classification_metrics(prediction, y_test):\n",
        "  accuracy = accuracy_score(y_test, prediction)\n",
        "  f1 = f1_score(y_test, prediction, average=\"macro\")\n",
        "  recall = recall_score(y_test, prediction, average=\"macro\")\n",
        "  precision = precision_score(y_test, prediction, average=\"macro\")\n",
        "\n",
        "  print('Accuracy: ' + str(accuracy))\n",
        "  print('F1 Score: ' + str(f1))\n",
        "  print('Recall Score: ' + str(recall))\n",
        "  print('Precision Score: ' + str(precision))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1P2kd94H6aoZ"
      },
      "source": [
        "##### Dataset Red Wine"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Memisahkan fitur target pada DF yang berbeda\n",
        "X_data_wine = df_wine.drop('quality', axis=1)\n",
        "Y_predict_wine = df_wine['quality']"
      ],
      "metadata": {
        "id": "UYQjsJQTKjRG"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Membagi dataset menjadi 0.2 untuk testing, dan 0.8 untuk training\n",
        "X_train_red, X_test_red, Y_train_red, Y_test_red = train_test_split(\n",
        "    X_data_wine, Y_predict_wine, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "G61GZhGpKS9T"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "fjalBZHeDEjE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "outputId": "377e1386-4415-4d02-a26d-4680480a4dcc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(max_depth=3, random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=3, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=3, random_state=42)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "# Melakukan training pada model decision tree\n",
        "# Sesuaikan nama variable X_train dan y_train kamu\n",
        "dtc_red = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
        "dtc_red.fit(X_train_red, Y_train_red)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBrN45b4Dbsp"
      },
      "source": [
        "##### Dataset Admission Prediction"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Memisahkan fitur target pada DF yang berbeda\n",
        "X_data_admission = df_admission.drop('Chance of Admit', axis=1)\n",
        "Y_predict_admission = df_admission['Chance of Admit']"
      ],
      "metadata": {
        "id": "yfO2Kz4BwjAd"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Membagi dataset menjadi 0.2 untuk testing, dan 0.8 untuk training\n",
        "X_train_admission, X_test_admission, Y_train_admission, Y_test_admission = train_test_split(\n",
        "    X_data_admission, Y_predict_admission, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "B5HgD9Xiwm9U"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "6MykM4RdDeXq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "outputId": "dee641b3-e73d-4ce6-eb9f-dbad0ad6d007"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeRegressor(max_depth=3, random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeRegressor(max_depth=3, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor(max_depth=3, random_state=42)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "# Melakukan training pada model decision tree\n",
        "# Sesuaikan nama variable X_train dan y_train kamu\n",
        "dtr_admission = DecisionTreeRegressor(max_depth=3, random_state=42)\n",
        "dtr_admission.fit(X_train_admission, Y_train_admission)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGMm2HEoEOaj"
      },
      "source": [
        "#### Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sTzwrwcERjY"
      },
      "source": [
        "##### Dataset Red Wine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "Oq1t9t64ETvV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "765295ea-55f7-46a0-8f76-51fd1b01d775"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.46253602305475505\n",
            "F1 Score: 0.41269303349802705\n",
            "Recall Score: 0.46428947960153416\n",
            "Precision Score: 0.43321055013773213\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "# Memprediksi data testing\n",
        "prediction = dtc_red.predict(X_test_red)\n",
        "\n",
        "# Call the metrics function\n",
        "classification_metrics(prediction, Y_test_red)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Dataset Admission Prediction"
      ],
      "metadata": {
        "id": "l8-eO_8VGhPX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Memprediksi data testing\n",
        "prediction = dtr_admission.predict(X_test_admission)\n",
        "\n",
        "# Call the metrics function\n",
        "regression_metrics(prediction, Y_test_admission)"
      ],
      "metadata": {
        "id": "P5Yj_nKHGmlp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd3feb5e-a82b-47df-a525-4ada316a5bb9"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE: 0.05986515898240106\n",
            "MSE: 0.0058009215250149435\n",
            "RMSE: 0.07616378092646756\n",
            "R_squared: 0.6376365279751508\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Hyperparameter"
      ],
      "metadata": {
        "id": "FskPvlAHHXQF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Hyperparameter adalah parameter yang dapat kita sesuaikan atau konfigurasi sebelum memulai proses pembangunan model. Tujuan dari penyesuaian ini adalah untuk mengoptimalisasi performa model sehingga diharapkan dapat berfungsi lebih efektif.\n",
        "\n",
        "> Ada beberapa jenis hyperparameter yang terdapat dalam beragam algoritma machine learning, termasuk dalam algoritma Decision Tree. Beberapa hyperparameter yang ada dalam algoritma Decision Tree yang disediakan oleh modul sklearn.tree antara lain:\n",
        "\n",
        "- `criterion`: Metrik yang digunakan untuk mengevaluasi kualitas pemisahan node, contohnya:\n",
        "- `squared_error`: menggunakan reduksi varians sebagai kriteria seleksi fitur dan meminimalkan kerugian L2 dengan menggunakan mean dari setiap node terminal\n",
        "- `friedman_mse`: menghitung mean squared error dengan Friedman's improvement score untuk kemungkinan pemisahan (tidak perlu khawatir, ini tidak akan keluar di ujian)\n",
        "- `absolute_error`: meminimalkan kerugian L1 dengan menggunakan median dari setiap node terminal\n",
        "- `poisson`: memanfaatkan reduksi dalam Poisson deviance untuk menentukan pemisahan\n",
        "- `max_depth`: Membatasi kedalaman maksimum dari pohon\n",
        "- `min_samples_split`: Menentukan jumlah minimum sampel yang dibutuhkan untuk memecah sebuah node internal\n",
        "Untuk informasi lebih detail, Anda bisa merujuk pada dokumentasi berikut:\n",
        "[sklearn decision tree](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html)"
      ],
      "metadata": {
        "id": "lLf2D3znHPVX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Melakukan training pada model decision tree\n",
        "# Decision tree yang dibangun memiliki hyperparameter max_depth=3\n",
        "dtr_md6 = DecisionTreeRegressor(max_depth=6, random_state=42)\n",
        "dtr_md6.fit(X_train_admission, Y_train_admission)\n",
        "\n",
        "# Memprediksi data testing\n",
        "predicted6 = dtr_md6.predict(X_test_admission)\n",
        "\n",
        "# Menampilkan metrics evaluasi\n",
        "regression_metrics(predicted6, Y_test_admission)"
      ],
      "metadata": {
        "id": "R9Ixy6F4IOKF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdc85144-16f8-4ae9-bc94-9df78c3a9012"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE: 0.06726742339785817\n",
            "MSE: 0.00865787351889976\n",
            "RMSE: 0.09304769486075279\n",
            "R_squared: 0.45917263401482866\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perubahan *hyperparameter* dapat mempengaruhi performa dari model. Pada awalnya dengan `max_depth = 3` model menghasilkan *MAE* 0.04837917276086966 dan *RMSE* 0.06888923287937174. Setelah dilakukan perubahan *hyperparameter* dengan `max_depth = 6`, kita dapat melihat bahwa ada penurunan pada performa model dengan *MAE* 0.049144375215427846 dan *RMSE* 0.0704508435958617\n",
        "\n",
        "Bagaimana jika hyperparameter lain diubah? Silakan eksplorasi perubahan hyperparameter lain secara mandiri ya!ðŸ˜ƒ"
      ],
      "metadata": {
        "id": "ygdtRWi1ImNZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualisasi Decision Tree yang Dihasilkan"
      ],
      "metadata": {
        "id": "4vb8lRCBJCE-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Kita bisa melakukan visualisasi terhadap serangkaian aturan yang membentuk Decision Tree yang telah dibangun. Salah satu caranya adalah dengan menggunakan modul `sklearn.tree.plot_tree` dengan bantuan `matplotlib`.\n",
        "\n",
        "Berikut adalah contoh visualisasi decision tree pada dataset Admission Prediction tanpa max depth:"
      ],
      "metadata": {
        "id": "6azDWikvJBSi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Membangun model tree\n",
        "tree_model = DecisionTreeRegressor()\n",
        "tree_model.fit(X_train_admission, Y_train_admission)\n",
        "\n",
        "# Melakukan visualisasi pada decision tree yang sudah dibangun sebelumnya\n",
        "print(tree.export_text(tree_model, feature_names=pd.Series(X_train_admission.columns).array))"
      ],
      "metadata": {
        "id": "sKnfNs6jJLbk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36a1604d-3b38-4993-c58c-52aab56c71ee"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|--- CGPA <= 8.93\n",
            "|   |--- CGPA <= 8.03\n",
            "|   |   |--- GRE Score <= 305.50\n",
            "|   |   |   |--- CGPA <= 7.66\n",
            "|   |   |   |   |--- GRE Score <= 301.00\n",
            "|   |   |   |   |   |--- Serial No. <= 361.00\n",
            "|   |   |   |   |   |   |--- GRE Score <= 298.50\n",
            "|   |   |   |   |   |   |   |--- CGPA <= 7.64\n",
            "|   |   |   |   |   |   |   |   |--- Unnamed: 0 <= 139.50\n",
            "|   |   |   |   |   |   |   |   |   |--- Unnamed: 0 <= 27.50\n",
            "|   |   |   |   |   |   |   |   |   |   |--- value: [0.44]\n",
            "|   |   |   |   |   |   |   |   |   |--- Unnamed: 0 >  27.50\n",
            "|   |   |   |   |   |   |   |   |   |   |--- SOP <= 2.50\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- value: [0.46]\n",
            "|   |   |   |   |   |   |   |   |   |   |--- SOP >  2.50\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- value: [0.47]\n",
            "|   |   |   |   |   |   |   |   |--- Unnamed: 0 >  139.50\n",
            "|   |   |   |   |   |   |   |   |   |--- Serial No. <= 217.50\n",
            "|   |   |   |   |   |   |   |   |   |   |--- value: [0.53]\n",
            "|   |   |   |   |   |   |   |   |   |--- Serial No. >  217.50\n",
            "|   |   |   |   |   |   |   |   |   |   |--- University Rating <= 1.50\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- value: [0.49]\n",
            "|   |   |   |   |   |   |   |   |   |   |--- University Rating >  1.50\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- value: [0.47]\n",
            "|   |   |   |   |   |   |   |--- CGPA >  7.64\n",
            "|   |   |   |   |   |   |   |   |--- value: [0.57]\n",
            "|   |   |   |   |   |   |--- GRE Score >  298.50\n",
            "|   |   |   |   |   |   |   |--- University Rating <= 2.00\n",
            "|   |   |   |   |   |   |   |   |--- value: [0.36]\n",
            "|   |   |   |   |   |   |   |--- University Rating >  2.00\n",
            "|   |   |   |   |   |   |   |   |--- value: [0.38]\n",
            "|   |   |   |   |   |--- Serial No. >  361.00\n",
            "|   |   |   |   |   |   |--- University Rating <= 2.50\n",
            "|   |   |   |   |   |   |   |--- Serial No. <= 417.50\n",
            "|   |   |   |   |   |   |   |   |--- value: [0.34]\n",
            "|   |   |   |   |   |   |   |--- Serial No. >  417.50\n",
            "|   |   |   |   |   |   |   |   |--- value: [0.37]\n",
            "|   |   |   |   |   |   |--- University Rating >  2.50\n",
            "|   |   |   |   |   |   |   |--- value: [0.42]\n",
            "|   |   |   |   |--- GRE Score >  301.00\n",
            "|   |   |   |   |   |--- CGPA <= 7.65\n",
            "|   |   |   |   |   |   |--- SOP <= 1.75\n",
            "|   |   |   |   |   |   |   |--- value: [0.47]\n",
            "|   |   |   |   |   |   |--- SOP >  1.75\n",
            "|   |   |   |   |   |   |   |--- SOP <= 2.25\n",
            "|   |   |   |   |   |   |   |   |--- GRE Score <= 302.50\n",
            "|   |   |   |   |   |   |   |   |   |--- value: [0.57]\n",
            "|   |   |   |   |   |   |   |   |--- GRE Score >  302.50\n",
            "|   |   |   |   |   |   |   |   |   |--- value: [0.56]\n",
            "|   |   |   |   |   |   |   |--- SOP >  2.25\n",
            "|   |   |   |   |   |   |   |   |--- value: [0.52]\n",
            "|   |   |   |   |   |--- CGPA >  7.65\n",
            "|   |   |   |   |   |   |--- value: [0.38]\n",
            "|   |   |   |--- CGPA >  7.66\n",
            "|   |   |   |   |--- SOP <= 3.25\n",
            "|   |   |   |   |   |--- GRE Score <= 303.00\n",
            "|   |   |   |   |   |   |--- GRE Score <= 295.50\n",
            "|   |   |   |   |   |   |   |--- value: [0.69]\n",
            "|   |   |   |   |   |   |--- GRE Score >  295.50\n",
            "|   |   |   |   |   |   |   |--- CGPA <= 8.01\n",
            "|   |   |   |   |   |   |   |   |--- CGPA <= 7.68\n",
            "|   |   |   |   |   |   |   |   |   |--- CGPA <= 7.67\n",
            "|   |   |   |   |   |   |   |   |   |   |--- value: [0.59]\n",
            "|   |   |   |   |   |   |   |   |   |--- CGPA >  7.67\n",
            "|   |   |   |   |   |   |   |   |   |   |--- value: [0.60]\n",
            "|   |   |   |   |   |   |   |   |--- CGPA >  7.68\n",
            "|   |   |   |   |   |   |   |   |   |--- SOP <= 1.75\n",
            "|   |   |   |   |   |   |   |   |   |   |--- GRE Score <= 298.00\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- value: [0.52]\n",
            "|   |   |   |   |   |   |   |   |   |   |--- GRE Score >  298.00\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 3\n",
            "|   |   |   |   |   |   |   |   |   |--- SOP >  1.75\n",
            "|   |   |   |   |   |   |   |   |   |   |--- University Rating <= 2.50\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 2\n",
            "|   |   |   |   |   |   |   |   |   |   |--- University Rating >  2.50\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- value: [0.53]\n",
            "|   |   |   |   |   |   |   |--- CGPA >  8.01\n",
            "|   |   |   |   |   |   |   |   |--- University Rating <= 1.50\n",
            "|   |   |   |   |   |   |   |   |   |--- value: [0.67]\n",
            "|   |   |   |   |   |   |   |   |--- University Rating >  1.50\n",
            "|   |   |   |   |   |   |   |   |   |--- value: [0.61]\n",
            "|   |   |   |   |   |--- GRE Score >  303.00\n",
            "|   |   |   |   |   |   |--- value: [0.42]\n",
            "|   |   |   |   |--- SOP >  3.25\n",
            "|   |   |   |   |   |--- value: [0.34]\n",
            "|   |   |--- GRE Score >  305.50\n",
            "|   |   |   |--- GRE Score <= 319.50\n",
            "|   |   |   |   |--- Unnamed: 0 <= 445.50\n",
            "|   |   |   |   |   |--- Research <= 0.50\n",
            "|   |   |   |   |   |   |--- SOP <= 2.25\n",
            "|   |   |   |   |   |   |   |--- University Rating <= 1.50\n",
            "|   |   |   |   |   |   |   |   |--- CGPA <= 7.90\n",
            "|   |   |   |   |   |   |   |   |   |--- value: [0.57]\n",
            "|   |   |   |   |   |   |   |   |--- CGPA >  7.90\n",
            "|   |   |   |   |   |   |   |   |   |--- value: [0.58]\n",
            "|   |   |   |   |   |   |   |--- University Rating >  1.50\n",
            "|   |   |   |   |   |   |   |   |--- value: [0.54]\n",
            "|   |   |   |   |   |   |--- SOP >  2.25\n",
            "|   |   |   |   |   |   |   |--- Unnamed: 0 <= 388.00\n",
            "|   |   |   |   |   |   |   |   |--- Serial No. <= 330.00\n",
            "|   |   |   |   |   |   |   |   |   |--- Serial No. <= 89.00\n",
            "|   |   |   |   |   |   |   |   |   |   |--- value: [0.68]\n",
            "|   |   |   |   |   |   |   |   |   |--- Serial No. >  89.00\n",
            "|   |   |   |   |   |   |   |   |   |   |--- Serial No. <= 188.50\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- value: [0.65]\n",
            "|   |   |   |   |   |   |   |   |   |   |--- Serial No. >  188.50\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 2\n",
            "|   |   |   |   |   |   |   |   |--- Serial No. >  330.00\n",
            "|   |   |   |   |   |   |   |   |   |--- value: [0.70]\n",
            "|   |   |   |   |   |   |   |--- Unnamed: 0 >  388.00\n",
            "|   |   |   |   |   |   |   |   |--- CGPA <= 7.85\n",
            "|   |   |   |   |   |   |   |   |   |--- value: [0.55]\n",
            "|   |   |   |   |   |   |   |   |--- CGPA >  7.85\n",
            "|   |   |   |   |   |   |   |   |   |--- value: [0.60]\n",
            "|   |   |   |   |   |--- Research >  0.50\n",
            "|   |   |   |   |   |   |--- CGPA <= 7.92\n",
            "|   |   |   |   |   |   |   |--- TOEFL Score <= 100.50\n",
            "|   |   |   |   |   |   |   |   |--- value: [0.56]\n",
            "|   |   |   |   |   |   |   |--- TOEFL Score >  100.50\n",
            "|   |   |   |   |   |   |   |   |--- GRE Score <= 313.00\n",
            "|   |   |   |   |   |   |   |   |   |--- GRE Score <= 311.50\n",
            "|   |   |   |   |   |   |   |   |   |   |--- value: [0.62]\n",
            "|   |   |   |   |   |   |   |   |   |--- GRE Score >  311.50\n",
            "|   |   |   |   |   |   |   |   |   |   |--- value: [0.64]\n",
            "|   |   |   |   |   |   |   |   |--- GRE Score >  313.00\n",
            "|   |   |   |   |   |   |   |   |   |--- CGPA <= 7.77\n",
            "|   |   |   |   |   |   |   |   |   |   |--- value: [0.61]\n",
            "|   |   |   |   |   |   |   |   |   |--- CGPA >  7.77\n",
            "|   |   |   |   |   |   |   |   |   |   |--- value: [0.59]\n",
            "|   |   |   |   |   |   |--- CGPA >  7.92\n",
            "|   |   |   |   |   |   |   |--- SOP <= 3.25\n",
            "|   |   |   |   |   |   |   |   |--- SOP <= 1.50\n",
            "|   |   |   |   |   |   |   |   |   |--- value: [0.52]\n",
            "|   |   |   |   |   |   |   |   |--- SOP >  1.50\n",
            "|   |   |   |   |   |   |   |   |   |--- GRE Score <= 314.50\n",
            "|   |   |   |   |   |   |   |   |   |   |--- value: [0.50]\n",
            "|   |   |   |   |   |   |   |   |   |--- GRE Score >  314.50\n",
            "|   |   |   |   |   |   |   |   |   |   |--- value: [0.49]\n",
            "|   |   |   |   |   |   |   |--- SOP >  3.25\n",
            "|   |   |   |   |   |   |   |   |--- value: [0.46]\n",
            "|   |   |   |   |--- Unnamed: 0 >  445.50\n",
            "|   |   |   |   |   |--- GRE Score <= 309.00\n",
            "|   |   |   |   |   |   |--- GRE Score <= 307.50\n",
            "|   |   |   |   |   |   |   |--- value: [0.62]\n",
            "|   |   |   |   |   |   |--- GRE Score >  307.50\n",
            "|   |   |   |   |   |   |   |--- value: [0.67]\n",
            "|   |   |   |   |   |--- GRE Score >  309.00\n",
            "|   |   |   |   |   |   |--- University Rating <= 2.50\n",
            "|   |   |   |   |   |   |   |--- value: [0.71]\n",
            "|   |   |   |   |   |   |--- University Rating >  2.50\n",
            "|   |   |   |   |   |   |   |--- value: [0.73]\n",
            "|   |   |   |--- GRE Score >  319.50\n",
            "|   |   |   |   |--- SOP <= 3.50\n",
            "|   |   |   |   |   |--- value: [0.70]\n",
            "|   |   |   |   |--- SOP >  3.50\n",
            "|   |   |   |   |   |--- value: [0.78]\n",
            "|   |--- CGPA >  8.03\n",
            "|   |   |--- CGPA <= 8.34\n",
            "|   |   |   |--- Research <= 0.50\n",
            "|   |   |   |   |--- Unnamed: 0 <= 74.00\n",
            "|   |   |   |   |   |--- Unnamed: 0 <= 31.50\n",
            "|   |   |   |   |   |   |--- value: [0.65]\n",
            "|   |   |   |   |   |--- Unnamed: 0 >  31.50\n",
            "|   |   |   |   |   |   |--- GRE Score <= 309.00\n",
            "|   |   |   |   |   |   |   |--- value: [0.47]\n",
            "|   |   |   |   |   |   |--- GRE Score >  309.00\n",
            "|   |   |   |   |   |   |   |--- value: [0.42]\n",
            "|   |   |   |   |--- Unnamed: 0 >  74.00\n",
            "|   |   |   |   |   |--- GRE Score <= 315.50\n",
            "|   |   |   |   |   |   |--- Serial No. <= 329.50\n",
            "|   |   |   |   |   |   |   |--- Serial No. <= 173.50\n",
            "|   |   |   |   |   |   |   |   |--- CGPA <= 8.26\n",
            "|   |   |   |   |   |   |   |   |   |--- SOP <= 4.25\n",
            "|   |   |   |   |   |   |   |   |   |   |--- Serial No. <= 113.50\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- value: [0.62]\n",
            "|   |   |   |   |   |   |   |   |   |   |--- Serial No. >  113.50\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- value: [0.61]\n",
            "|   |   |   |   |   |   |   |   |   |--- SOP >  4.25\n",
            "|   |   |   |   |   |   |   |   |   |   |--- value: [0.64]\n",
            "|   |   |   |   |   |   |   |   |--- CGPA >  8.26\n",
            "|   |   |   |   |   |   |   |   |   |--- Serial No. <= 167.50\n",
            "|   |   |   |   |   |   |   |   |   |   |--- value: [0.65]\n",
            "|   |   |   |   |   |   |   |   |   |--- Serial No. >  167.50\n",
            "|   |   |   |   |   |   |   |   |   |   |--- value: [0.64]\n",
            "|   |   |   |   |   |   |   |--- Serial No. >  173.50\n",
            "|   |   |   |   |   |   |   |   |--- Unnamed: 0 <= 201.50\n",
            "|   |   |   |   |   |   |   |   |   |--- GRE Score <= 308.00\n",
            "|   |   |   |   |   |   |   |   |   |   |--- value: [0.73]\n",
            "|   |   |   |   |   |   |   |   |   |--- GRE Score >  308.00\n",
            "|   |   |   |   |   |   |   |   |   |   |--- value: [0.72]\n",
            "|   |   |   |   |   |   |   |   |--- Unnamed: 0 >  201.50\n",
            "|   |   |   |   |   |   |   |   |   |--- SOP <= 2.75\n",
            "|   |   |   |   |   |   |   |   |   |   |--- GRE Score <= 306.00\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- value: [0.64]\n",
            "|   |   |   |   |   |   |   |   |   |   |--- GRE Score >  306.00\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- value: [0.65]\n",
            "|   |   |   |   |   |   |   |   |   |--- SOP >  2.75\n",
            "|   |   |   |   |   |   |   |   |   |   |--- Unnamed: 0 <= 313.50\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- value: [0.67]\n",
            "|   |   |   |   |   |   |   |   |   |   |--- Unnamed: 0 >  313.50\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- value: [0.66]\n",
            "|   |   |   |   |   |   |--- Serial No. >  329.50\n",
            "|   |   |   |   |   |   |   |--- University Rating <= 2.50\n",
            "|   |   |   |   |   |   |   |   |--- SOP <= 2.25\n",
            "|   |   |   |   |   |   |   |   |   |--- value: [0.53]\n",
            "|   |   |   |   |   |   |   |   |--- SOP >  2.25\n",
            "|   |   |   |   |   |   |   |   |   |--- value: [0.56]\n",
            "|   |   |   |   |   |   |   |--- University Rating >  2.50\n",
            "|   |   |   |   |   |   |   |   |--- TOEFL Score <= 105.00\n",
            "|   |   |   |   |   |   |   |   |   |--- GRE Score <= 314.00\n",
            "|   |   |   |   |   |   |   |   |   |   |--- TOEFL Score <= 101.50\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- value: [0.62]\n",
            "|   |   |   |   |   |   |   |   |   |   |--- TOEFL Score >  101.50\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 3\n",
            "|   |   |   |   |   |   |   |   |   |--- GRE Score >  314.00\n",
            "|   |   |   |   |   |   |   |   |   |   |--- value: [0.65]\n",
            "|   |   |   |   |   |   |   |   |--- TOEFL Score >  105.00\n",
            "|   |   |   |   |   |   |   |   |   |--- value: [0.58]\n",
            "|   |   |   |   |   |--- GRE Score >  315.50\n",
            "|   |   |   |   |   |   |--- LOR  <= 3.25\n",
            "|   |   |   |   |   |   |   |--- CGPA <= 8.21\n",
            "|   |   |   |   |   |   |   |   |--- value: [0.65]\n",
            "|   |   |   |   |   |   |   |--- CGPA >  8.21\n",
            "|   |   |   |   |   |   |   |   |--- value: [0.66]\n",
            "|   |   |   |   |   |   |--- LOR  >  3.25\n",
            "|   |   |   |   |   |   |   |--- TOEFL Score <= 104.00\n",
            "|   |   |   |   |   |   |   |   |--- value: [0.67]\n",
            "|   |   |   |   |   |   |   |--- TOEFL Score >  104.00\n",
            "|   |   |   |   |   |   |   |   |--- LOR  <= 3.75\n",
            "|   |   |   |   |   |   |   |   |   |--- value: [0.73]\n",
            "|   |   |   |   |   |   |   |   |--- LOR  >  3.75\n",
            "|   |   |   |   |   |   |   |   |   |--- value: [0.72]\n",
            "|   |   |   |--- Research >  0.50\n",
            "|   |   |   |   |--- GRE Score <= 305.00\n",
            "|   |   |   |   |   |--- Serial No. <= 278.50\n",
            "|   |   |   |   |   |   |--- value: [0.54]\n",
            "|   |   |   |   |   |--- Serial No. >  278.50\n",
            "|   |   |   |   |   |   |--- value: [0.62]\n",
            "|   |   |   |   |--- GRE Score >  305.00\n",
            "|   |   |   |   |   |--- LOR  <= 2.25\n",
            "|   |   |   |   |   |   |--- value: [0.61]\n",
            "|   |   |   |   |   |--- LOR  >  2.25\n",
            "|   |   |   |   |   |   |--- University Rating <= 1.50\n",
            "|   |   |   |   |   |   |   |--- value: [0.64]\n",
            "|   |   |   |   |   |   |--- University Rating >  1.50\n",
            "|   |   |   |   |   |   |   |--- CGPA <= 8.07\n",
            "|   |   |   |   |   |   |   |   |--- value: [0.68]\n",
            "|   |   |   |   |   |   |   |--- CGPA >  8.07\n",
            "|   |   |   |   |   |   |   |   |--- CGPA <= 8.24\n",
            "|   |   |   |   |   |   |   |   |   |--- LOR  <= 3.25\n",
            "|   |   |   |   |   |   |   |   |   |   |--- value: [0.72]\n",
            "|   |   |   |   |   |   |   |   |   |--- LOR  >  3.25\n",
            "|   |   |   |   |   |   |   |   |   |   |--- Serial No. <= 137.50\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- value: [0.75]\n",
            "|   |   |   |   |   |   |   |   |   |   |--- Serial No. >  137.50\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 2\n",
            "|   |   |   |   |   |   |   |   |--- CGPA >  8.24\n",
            "|   |   |   |   |   |   |   |   |   |--- LOR  <= 3.25\n",
            "|   |   |   |   |   |   |   |   |   |   |--- value: [0.79]\n",
            "|   |   |   |   |   |   |   |   |   |--- LOR  >  3.25\n",
            "|   |   |   |   |   |   |   |   |   |   |--- Serial No. <= 201.00\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- value: [0.76]\n",
            "|   |   |   |   |   |   |   |   |   |   |--- Serial No. >  201.00\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- value: [0.74]\n",
            "|   |   |--- CGPA >  8.34\n",
            "|   |   |   |--- Serial No. <= 127.00\n",
            "|   |   |   |   |--- Unnamed: 0 <= 56.50\n",
            "|   |   |   |   |   |--- TOEFL Score <= 112.50\n",
            "|   |   |   |   |   |   |--- University Rating <= 3.50\n",
            "|   |   |   |   |   |   |   |--- LOR  <= 3.75\n",
            "|   |   |   |   |   |   |   |   |--- value: [0.80]\n",
            "|   |   |   |   |   |   |   |--- LOR  >  3.75\n",
            "|   |   |   |   |   |   |   |   |--- value: [0.82]\n",
            "|   |   |   |   |   |   |--- University Rating >  3.50\n",
            "|   |   |   |   |   |   |   |--- CGPA <= 8.60\n",
            "|   |   |   |   |   |   |   |   |--- value: [0.78]\n",
            "|   |   |   |   |   |   |   |--- CGPA >  8.60\n",
            "|   |   |   |   |   |   |   |   |--- value: [0.76]\n",
            "|   |   |   |   |   |--- TOEFL Score >  112.50\n",
            "|   |   |   |   |   |   |--- value: [0.70]\n",
            "|   |   |   |   |--- Unnamed: 0 >  56.50\n",
            "|   |   |   |   |   |--- Research <= 0.50\n",
            "|   |   |   |   |   |   |--- University Rating <= 4.50\n",
            "|   |   |   |   |   |   |   |--- SOP <= 3.25\n",
            "|   |   |   |   |   |   |   |   |--- value: [0.52]\n",
            "|   |   |   |   |   |   |   |--- SOP >  3.25\n",
            "|   |   |   |   |   |   |   |   |--- SOP <= 3.75\n",
            "|   |   |   |   |   |   |   |   |   |--- value: [0.55]\n",
            "|   |   |   |   |   |   |   |   |--- SOP >  3.75\n",
            "|   |   |   |   |   |   |   |   |   |--- Serial No. <= 110.50\n",
            "|   |   |   |   |   |   |   |   |   |   |--- value: [0.57]\n",
            "|   |   |   |   |   |   |   |   |   |--- Serial No. >  110.50\n",
            "|   |   |   |   |   |   |   |   |   |   |--- value: [0.56]\n",
            "|   |   |   |   |   |   |--- University Rating >  4.50\n",
            "|   |   |   |   |   |   |   |--- SOP <= 4.00\n",
            "|   |   |   |   |   |   |   |   |--- value: [0.61]\n",
            "|   |   |   |   |   |   |   |--- SOP >  4.00\n",
            "|   |   |   |   |   |   |   |   |--- value: [0.68]\n",
            "|   |   |   |   |   |--- Research >  0.50\n",
            "|   |   |   |   |   |   |--- CGPA <= 8.67\n",
            "|   |   |   |   |   |   |   |--- GRE Score <= 319.00\n",
            "|   |   |   |   |   |   |   |   |--- GRE Score <= 306.00\n",
            "|   |   |   |   |   |   |   |   |   |--- GRE Score <= 300.50\n",
            "|   |   |   |   |   |   |   |   |   |   |--- value: [0.64]\n",
            "|   |   |   |   |   |   |   |   |   |--- GRE Score >  300.50\n",
            "|   |   |   |   |   |   |   |   |   |   |--- value: [0.62]\n",
            "|   |   |   |   |   |   |   |   |--- GRE Score >  306.00\n",
            "|   |   |   |   |   |   |   |   |   |--- TOEFL Score <= 106.00\n",
            "|   |   |   |   |   |   |   |   |   |   |--- value: [0.59]\n",
            "|   |   |   |   |   |   |   |   |   |--- TOEFL Score >  106.00\n",
            "|   |   |   |   |   |   |   |   |   |   |--- value: [0.57]\n",
            "|   |   |   |   |   |   |   |--- GRE Score >  319.00\n",
            "|   |   |   |   |   |   |   |   |--- value: [0.71]\n",
            "|   |   |   |   |   |   |--- CGPA >  8.67\n",
            "|   |   |   |   |   |   |   |--- Serial No. <= 103.00\n",
            "|   |   |   |   |   |   |   |   |--- LOR  <= 3.75\n",
            "|   |   |   |   |   |   |   |   |   |--- value: [0.74]\n",
            "|   |   |   |   |   |   |   |   |--- LOR  >  3.75\n",
            "|   |   |   |   |   |   |   |   |   |--- value: [0.79]\n",
            "|   |   |   |   |   |   |   |--- Serial No. >  103.00\n",
            "|   |   |   |   |   |   |   |   |--- LOR  <= 3.75\n",
            "|   |   |   |   |   |   |   |   |   |--- value: [0.71]\n",
            "|   |   |   |   |   |   |   |   |--- LOR  >  3.75\n",
            "|   |   |   |   |   |   |   |   |   |--- value: [0.69]\n",
            "|   |   |   |--- Serial No. >  127.00\n",
            "|   |   |   |   |--- TOEFL Score <= 106.00\n",
            "|   |   |   |   |   |--- University Rating <= 2.50\n",
            "|   |   |   |   |   |   |--- CGPA <= 8.75\n",
            "|   |   |   |   |   |   |   |--- TOEFL Score <= 104.00\n",
            "|   |   |   |   |   |   |   |   |--- Unnamed: 0 <= 329.00\n",
            "|   |   |   |   |   |   |   |   |   |--- GRE Score <= 310.50\n",
            "|   |   |   |   |   |   |   |   |   |   |--- value: [0.67]\n",
            "|   |   |   |   |   |   |   |   |   |--- GRE Score >  310.50\n",
            "|   |   |   |   |   |   |   |   |   |   |--- value: [0.68]\n",
            "|   |   |   |   |   |   |   |   |--- Unnamed: 0 >  329.00\n",
            "|   |   |   |   |   |   |   |   |   |--- value: [0.69]\n",
            "|   |   |   |   |   |   |   |--- TOEFL Score >  104.00\n",
            "|   |   |   |   |   |   |   |   |--- CGPA <= 8.39\n",
            "|   |   |   |   |   |   |   |   |   |--- value: [0.66]\n",
            "|   |   |   |   |   |   |   |   |--- CGPA >  8.39\n",
            "|   |   |   |   |   |   |   |   |   |--- value: [0.65]\n",
            "|   |   |   |   |   |   |--- CGPA >  8.75\n",
            "|   |   |   |   |   |   |   |--- value: [0.77]\n",
            "|   |   |   |   |   |--- University Rating >  2.50\n",
            "|   |   |   |   |   |   |--- GRE Score <= 319.50\n",
            "|   |   |   |   |   |   |   |--- University Rating <= 4.50\n",
            "|   |   |   |   |   |   |   |   |--- Serial No. <= 155.50\n",
            "|   |   |   |   |   |   |   |   |   |--- GRE Score <= 313.50\n",
            "|   |   |   |   |   |   |   |   |   |   |--- value: [0.76]\n",
            "|   |   |   |   |   |   |   |   |   |--- GRE Score >  313.50\n",
            "|   |   |   |   |   |   |   |   |   |   |--- value: [0.75]\n",
            "|   |   |   |   |   |   |   |   |--- Serial No. >  155.50\n",
            "|   |   |   |   |   |   |   |   |   |--- CGPA <= 8.77\n",
            "|   |   |   |   |   |   |   |   |   |   |--- Serial No. <= 200.00\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 2\n",
            "|   |   |   |   |   |   |   |   |   |   |--- Serial No. >  200.00\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 6\n",
            "|   |   |   |   |   |   |   |   |   |--- CGPA >  8.77\n",
            "|   |   |   |   |   |   |   |   |   |   |--- value: [0.67]\n",
            "|   |   |   |   |   |   |   |--- University Rating >  4.50\n",
            "|   |   |   |   |   |   |   |   |--- value: [0.78]\n",
            "|   |   |   |   |   |   |--- GRE Score >  319.50\n",
            "|   |   |   |   |   |   |   |--- CGPA <= 8.61\n",
            "|   |   |   |   |   |   |   |   |--- value: [0.74]\n",
            "|   |   |   |   |   |   |   |--- CGPA >  8.61\n",
            "|   |   |   |   |   |   |   |   |--- GRE Score <= 322.00\n",
            "|   |   |   |   |   |   |   |   |   |--- value: [0.76]\n",
            "|   |   |   |   |   |   |   |   |--- GRE Score >  322.00\n",
            "|   |   |   |   |   |   |   |   |   |--- CGPA <= 8.70\n",
            "|   |   |   |   |   |   |   |   |   |   |--- value: [0.78]\n",
            "|   |   |   |   |   |   |   |   |   |--- CGPA >  8.70\n",
            "|   |   |   |   |   |   |   |   |   |   |--- value: [0.77]\n",
            "|   |   |   |   |--- TOEFL Score >  106.00\n",
            "|   |   |   |   |   |--- CGPA <= 8.68\n",
            "|   |   |   |   |   |   |--- Unnamed: 0 <= 355.00\n",
            "|   |   |   |   |   |   |   |--- GRE Score <= 306.50\n",
            "|   |   |   |   |   |   |   |   |--- GRE Score <= 305.50\n",
            "|   |   |   |   |   |   |   |   |   |--- value: [0.71]\n",
            "|   |   |   |   |   |   |   |   |--- GRE Score >  305.50\n",
            "|   |   |   |   |   |   |   |   |   |--- value: [0.63]\n",
            "|   |   |   |   |   |   |   |--- GRE Score >  306.50\n",
            "|   |   |   |   |   |   |   |   |--- LOR  <= 3.25\n",
            "|   |   |   |   |   |   |   |   |   |--- CGPA <= 8.48\n",
            "|   |   |   |   |   |   |   |   |   |   |--- Serial No. <= 271.50\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- value: [0.72]\n",
            "|   |   |   |   |   |   |   |   |   |   |--- Serial No. >  271.50\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- value: [0.75]\n",
            "|   |   |   |   |   |   |   |   |   |--- CGPA >  8.48\n",
            "|   |   |   |   |   |   |   |   |   |   |--- Unnamed: 0 <= 235.00\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- value: [0.67]\n",
            "|   |   |   |   |   |   |   |   |   |   |--- Unnamed: 0 >  235.00\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 2\n",
            "|   |   |   |   |   |   |   |   |--- LOR  >  3.25\n",
            "|   |   |   |   |   |   |   |   |   |--- GRE Score <= 307.50\n",
            "|   |   |   |   |   |   |   |   |   |   |--- CGPA <= 8.45\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- value: [0.79]\n",
            "|   |   |   |   |   |   |   |   |   |   |--- CGPA >  8.45\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- value: [0.78]\n",
            "|   |   |   |   |   |   |   |   |   |--- GRE Score >  307.50\n",
            "|   |   |   |   |   |   |   |   |   |   |--- SOP <= 3.25\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- value: [0.71]\n",
            "|   |   |   |   |   |   |   |   |   |   |--- SOP >  3.25\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 4\n",
            "|   |   |   |   |   |   |--- Unnamed: 0 >  355.00\n",
            "|   |   |   |   |   |   |   |--- LOR  <= 3.50\n",
            "|   |   |   |   |   |   |   |   |--- Research <= 0.50\n",
            "|   |   |   |   |   |   |   |   |   |--- value: [0.81]\n",
            "|   |   |   |   |   |   |   |   |--- Research >  0.50\n",
            "|   |   |   |   |   |   |   |   |   |--- Unnamed: 0 <= 461.00\n",
            "|   |   |   |   |   |   |   |   |   |   |--- value: [0.79]\n",
            "|   |   |   |   |   |   |   |   |   |--- Unnamed: 0 >  461.00\n",
            "|   |   |   |   |   |   |   |   |   |   |--- value: [0.78]\n",
            "|   |   |   |   |   |   |   |--- LOR  >  3.50\n",
            "|   |   |   |   |   |   |   |   |--- value: [0.76]\n",
            "|   |   |   |   |   |--- CGPA >  8.68\n",
            "|   |   |   |   |   |   |--- TOEFL Score <= 108.50\n",
            "|   |   |   |   |   |   |   |--- GRE Score <= 320.00\n",
            "|   |   |   |   |   |   |   |   |--- value: [0.84]\n",
            "|   |   |   |   |   |   |   |--- GRE Score >  320.00\n",
            "|   |   |   |   |   |   |   |   |--- value: [0.81]\n",
            "|   |   |   |   |   |   |--- TOEFL Score >  108.50\n",
            "|   |   |   |   |   |   |   |--- University Rating <= 3.50\n",
            "|   |   |   |   |   |   |   |   |--- TOEFL Score <= 110.50\n",
            "|   |   |   |   |   |   |   |   |   |--- TOEFL Score <= 109.50\n",
            "|   |   |   |   |   |   |   |   |   |   |--- value: [0.74]\n",
            "|   |   |   |   |   |   |   |   |   |--- TOEFL Score >  109.50\n",
            "|   |   |   |   |   |   |   |   |   |   |--- value: [0.75]\n",
            "|   |   |   |   |   |   |   |   |--- TOEFL Score >  110.50\n",
            "|   |   |   |   |   |   |   |   |   |--- GRE Score <= 320.00\n",
            "|   |   |   |   |   |   |   |   |   |   |--- value: [0.78]\n",
            "|   |   |   |   |   |   |   |   |   |--- GRE Score >  320.00\n",
            "|   |   |   |   |   |   |   |   |   |   |--- LOR  <= 2.50\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- value: [0.79]\n",
            "|   |   |   |   |   |   |   |   |   |   |--- LOR  >  2.50\n",
            "|   |   |   |   |   |   |   |   |   |   |   |--- value: [0.80]\n",
            "|   |   |   |   |   |   |   |--- University Rating >  3.50\n",
            "|   |   |   |   |   |   |   |   |--- TOEFL Score <= 111.00\n",
            "|   |   |   |   |   |   |   |   |   |--- TOEFL Score <= 109.50\n",
            "|   |   |   |   |   |   |   |   |   |   |--- value: [0.82]\n",
            "|   |   |   |   |   |   |   |   |   |--- TOEFL Score >  109.50\n",
            "|   |   |   |   |   |   |   |   |   |   |--- value: [0.81]\n",
            "|   |   |   |   |   |   |   |   |--- TOEFL Score >  111.00\n",
            "|   |   |   |   |   |   |   |   |   |--- GRE Score <= 325.00\n",
            "|   |   |   |   |   |   |   |   |   |   |--- value: [0.79]\n",
            "|   |   |   |   |   |   |   |   |   |--- GRE Score >  325.00\n",
            "|   |   |   |   |   |   |   |   |   |   |--- value: [0.80]\n",
            "|--- CGPA >  8.93\n",
            "|   |--- CGPA <= 9.18\n",
            "|   |   |--- CGPA <= 9.05\n",
            "|   |   |   |--- GRE Score <= 311.00\n",
            "|   |   |   |   |--- value: [0.66]\n",
            "|   |   |   |--- GRE Score >  311.00\n",
            "|   |   |   |   |--- LOR  <= 3.25\n",
            "|   |   |   |   |   |--- GRE Score <= 323.00\n",
            "|   |   |   |   |   |   |--- Unnamed: 0 <= 336.50\n",
            "|   |   |   |   |   |   |   |--- value: [0.70]\n",
            "|   |   |   |   |   |   |--- Unnamed: 0 >  336.50\n",
            "|   |   |   |   |   |   |   |--- value: [0.73]\n",
            "|   |   |   |   |   |--- GRE Score >  323.00\n",
            "|   |   |   |   |   |   |--- LOR  <= 2.75\n",
            "|   |   |   |   |   |   |   |--- value: [0.81]\n",
            "|   |   |   |   |   |   |--- LOR  >  2.75\n",
            "|   |   |   |   |   |   |   |--- Serial No. <= 323.50\n",
            "|   |   |   |   |   |   |   |   |--- value: [0.76]\n",
            "|   |   |   |   |   |   |   |--- Serial No. >  323.50\n",
            "|   |   |   |   |   |   |   |   |--- value: [0.78]\n",
            "|   |   |   |   |--- LOR  >  3.25\n",
            "|   |   |   |   |   |--- Unnamed: 0 <= 288.50\n",
            "|   |   |   |   |   |   |--- SOP <= 4.25\n",
            "|   |   |   |   |   |   |   |--- LOR  <= 3.75\n",
            "|   |   |   |   |   |   |   |   |--- TOEFL Score <= 111.00\n",
            "|   |   |   |   |   |   |   |   |   |--- Serial No. <= 198.50\n",
            "|   |   |   |   |   |   |   |   |   |   |--- value: [0.82]\n",
            "|   |   |   |   |   |   |   |   |   |--- Serial No. >  198.50\n",
            "|   |   |   |   |   |   |   |   |   |   |--- value: [0.84]\n",
            "|   |   |   |   |   |   |   |   |--- TOEFL Score >  111.00\n",
            "|   |   |   |   |   |   |   |   |   |--- value: [0.80]\n",
            "|   |   |   |   |   |   |   |--- LOR  >  3.75\n",
            "|   |   |   |   |   |   |   |   |--- CGPA <= 8.97\n",
            "|   |   |   |   |   |   |   |   |   |--- value: [0.86]\n",
            "|   |   |   |   |   |   |   |   |--- CGPA >  8.97\n",
            "|   |   |   |   |   |   |   |   |   |--- value: [0.87]\n",
            "|   |   |   |   |   |   |--- SOP >  4.25\n",
            "|   |   |   |   |   |   |   |--- CGPA <= 8.99\n",
            "|   |   |   |   |   |   |   |   |--- value: [0.78]\n",
            "|   |   |   |   |   |   |   |--- CGPA >  8.99\n",
            "|   |   |   |   |   |   |   |   |--- LOR  <= 4.50\n",
            "|   |   |   |   |   |   |   |   |   |--- value: [0.81]\n",
            "|   |   |   |   |   |   |   |   |--- LOR  >  4.50\n",
            "|   |   |   |   |   |   |   |   |   |--- value: [0.82]\n",
            "|   |   |   |   |   |--- Unnamed: 0 >  288.50\n",
            "|   |   |   |   |   |   |--- CGPA <= 8.97\n",
            "|   |   |   |   |   |   |   |--- value: [0.77]\n",
            "|   |   |   |   |   |   |--- CGPA >  8.97\n",
            "|   |   |   |   |   |   |   |--- CGPA <= 9.03\n",
            "|   |   |   |   |   |   |   |   |--- Serial No. <= 299.00\n",
            "|   |   |   |   |   |   |   |   |   |--- value: [0.79]\n",
            "|   |   |   |   |   |   |   |   |--- Serial No. >  299.00\n",
            "|   |   |   |   |   |   |   |   |   |--- value: [0.80]\n",
            "|   |   |   |   |   |   |   |--- CGPA >  9.03\n",
            "|   |   |   |   |   |   |   |   |--- value: [0.82]\n",
            "|   |   |--- CGPA >  9.05\n",
            "|   |   |   |--- University Rating <= 4.50\n",
            "|   |   |   |   |--- SOP <= 3.75\n",
            "|   |   |   |   |   |--- CGPA <= 9.11\n",
            "|   |   |   |   |   |   |--- value: [0.84]\n",
            "|   |   |   |   |   |--- CGPA >  9.11\n",
            "|   |   |   |   |   |   |--- Research <= 0.50\n",
            "|   |   |   |   |   |   |   |--- Serial No. <= 295.00\n",
            "|   |   |   |   |   |   |   |   |--- value: [0.78]\n",
            "|   |   |   |   |   |   |   |--- Serial No. >  295.00\n",
            "|   |   |   |   |   |   |   |   |--- value: [0.79]\n",
            "|   |   |   |   |   |   |--- Research >  0.50\n",
            "|   |   |   |   |   |   |   |--- value: [0.81]\n",
            "|   |   |   |   |--- SOP >  3.75\n",
            "|   |   |   |   |   |--- TOEFL Score <= 108.50\n",
            "|   |   |   |   |   |   |--- value: [0.79]\n",
            "|   |   |   |   |   |--- TOEFL Score >  108.50\n",
            "|   |   |   |   |   |   |--- TOEFL Score <= 110.50\n",
            "|   |   |   |   |   |   |   |--- Serial No. <= 300.50\n",
            "|   |   |   |   |   |   |   |   |--- value: [0.85]\n",
            "|   |   |   |   |   |   |   |--- Serial No. >  300.50\n",
            "|   |   |   |   |   |   |   |   |--- value: [0.82]\n",
            "|   |   |   |   |   |   |--- TOEFL Score >  110.50\n",
            "|   |   |   |   |   |   |   |--- Serial No. <= 172.00\n",
            "|   |   |   |   |   |   |   |   |--- value: [0.87]\n",
            "|   |   |   |   |   |   |   |--- Serial No. >  172.00\n",
            "|   |   |   |   |   |   |   |   |--- TOEFL Score <= 113.00\n",
            "|   |   |   |   |   |   |   |   |   |--- CGPA <= 9.14\n",
            "|   |   |   |   |   |   |   |   |   |   |--- value: [0.84]\n",
            "|   |   |   |   |   |   |   |   |   |--- CGPA >  9.14\n",
            "|   |   |   |   |   |   |   |   |   |   |--- value: [0.85]\n",
            "|   |   |   |   |   |   |   |   |--- TOEFL Score >  113.00\n",
            "|   |   |   |   |   |   |   |   |   |--- LOR  <= 4.75\n",
            "|   |   |   |   |   |   |   |   |   |   |--- value: [0.86]\n",
            "|   |   |   |   |   |   |   |   |   |--- LOR  >  4.75\n",
            "|   |   |   |   |   |   |   |   |   |   |--- value: [0.85]\n",
            "|   |   |   |--- University Rating >  4.50\n",
            "|   |   |   |   |--- GRE Score <= 337.00\n",
            "|   |   |   |   |   |--- GRE Score <= 321.50\n",
            "|   |   |   |   |   |   |--- TOEFL Score <= 113.00\n",
            "|   |   |   |   |   |   |   |--- value: [0.86]\n",
            "|   |   |   |   |   |   |--- TOEFL Score >  113.00\n",
            "|   |   |   |   |   |   |   |--- value: [0.87]\n",
            "|   |   |   |   |   |--- GRE Score >  321.50\n",
            "|   |   |   |   |   |   |--- SOP <= 4.75\n",
            "|   |   |   |   |   |   |   |--- LOR  <= 4.75\n",
            "|   |   |   |   |   |   |   |   |--- LOR  <= 4.25\n",
            "|   |   |   |   |   |   |   |   |   |--- value: [0.90]\n",
            "|   |   |   |   |   |   |   |   |--- LOR  >  4.25\n",
            "|   |   |   |   |   |   |   |   |   |--- value: [0.89]\n",
            "|   |   |   |   |   |   |   |--- LOR  >  4.75\n",
            "|   |   |   |   |   |   |   |   |--- value: [0.91]\n",
            "|   |   |   |   |   |   |--- SOP >  4.75\n",
            "|   |   |   |   |   |   |   |--- CGPA <= 9.12\n",
            "|   |   |   |   |   |   |   |   |--- Unnamed: 0 <= 238.00\n",
            "|   |   |   |   |   |   |   |   |   |--- value: [0.88]\n",
            "|   |   |   |   |   |   |   |   |--- Unnamed: 0 >  238.00\n",
            "|   |   |   |   |   |   |   |   |   |--- value: [0.89]\n",
            "|   |   |   |   |   |   |   |--- CGPA >  9.12\n",
            "|   |   |   |   |   |   |   |   |--- value: [0.87]\n",
            "|   |   |   |   |--- GRE Score >  337.00\n",
            "|   |   |   |   |   |--- value: [0.95]\n",
            "|   |--- CGPA >  9.18\n",
            "|   |   |--- CGPA <= 9.47\n",
            "|   |   |   |--- TOEFL Score <= 113.50\n",
            "|   |   |   |   |--- CGPA <= 9.24\n",
            "|   |   |   |   |   |--- Unnamed: 0 <= 333.50\n",
            "|   |   |   |   |   |   |--- value: [0.88]\n",
            "|   |   |   |   |   |--- Unnamed: 0 >  333.50\n",
            "|   |   |   |   |   |   |--- value: [0.86]\n",
            "|   |   |   |   |--- CGPA >  9.24\n",
            "|   |   |   |   |   |--- GRE Score <= 327.50\n",
            "|   |   |   |   |   |   |--- CGPA <= 9.26\n",
            "|   |   |   |   |   |   |   |--- value: [0.92]\n",
            "|   |   |   |   |   |   |--- CGPA >  9.26\n",
            "|   |   |   |   |   |   |   |--- value: [0.91]\n",
            "|   |   |   |   |   |--- GRE Score >  327.50\n",
            "|   |   |   |   |   |   |--- CGPA <= 9.34\n",
            "|   |   |   |   |   |   |   |--- CGPA <= 9.30\n",
            "|   |   |   |   |   |   |   |   |--- value: [0.89]\n",
            "|   |   |   |   |   |   |   |--- CGPA >  9.30\n",
            "|   |   |   |   |   |   |   |   |--- value: [0.91]\n",
            "|   |   |   |   |   |   |--- CGPA >  9.34\n",
            "|   |   |   |   |   |   |   |--- value: [0.89]\n",
            "|   |   |   |--- TOEFL Score >  113.50\n",
            "|   |   |   |   |--- University Rating <= 4.50\n",
            "|   |   |   |   |   |--- TOEFL Score <= 115.00\n",
            "|   |   |   |   |   |   |--- value: [0.93]\n",
            "|   |   |   |   |   |--- TOEFL Score >  115.00\n",
            "|   |   |   |   |   |   |--- CGPA <= 9.38\n",
            "|   |   |   |   |   |   |   |--- Serial No. <= 332.00\n",
            "|   |   |   |   |   |   |   |   |--- value: [0.90]\n",
            "|   |   |   |   |   |   |   |--- Serial No. >  332.00\n",
            "|   |   |   |   |   |   |   |   |--- value: [0.91]\n",
            "|   |   |   |   |   |   |--- CGPA >  9.38\n",
            "|   |   |   |   |   |   |   |--- Unnamed: 0 <= 419.50\n",
            "|   |   |   |   |   |   |   |   |--- value: [0.91]\n",
            "|   |   |   |   |   |   |   |--- Unnamed: 0 >  419.50\n",
            "|   |   |   |   |   |   |   |   |--- value: [0.92]\n",
            "|   |   |   |   |--- University Rating >  4.50\n",
            "|   |   |   |   |   |--- Serial No. <= 45.00\n",
            "|   |   |   |   |   |   |--- value: [0.90]\n",
            "|   |   |   |   |   |--- Serial No. >  45.00\n",
            "|   |   |   |   |   |   |--- GRE Score <= 327.50\n",
            "|   |   |   |   |   |   |   |--- Serial No. <= 254.50\n",
            "|   |   |   |   |   |   |   |   |--- value: [0.92]\n",
            "|   |   |   |   |   |   |   |--- Serial No. >  254.50\n",
            "|   |   |   |   |   |   |   |   |--- value: [0.91]\n",
            "|   |   |   |   |   |   |--- GRE Score >  327.50\n",
            "|   |   |   |   |   |   |   |--- GRE Score <= 332.50\n",
            "|   |   |   |   |   |   |   |   |--- GRE Score <= 331.50\n",
            "|   |   |   |   |   |   |   |   |   |--- value: [0.93]\n",
            "|   |   |   |   |   |   |   |   |--- GRE Score >  331.50\n",
            "|   |   |   |   |   |   |   |   |   |--- value: [0.94]\n",
            "|   |   |   |   |   |   |   |--- GRE Score >  332.50\n",
            "|   |   |   |   |   |   |   |   |--- value: [0.92]\n",
            "|   |   |--- CGPA >  9.47\n",
            "|   |   |   |--- Research <= 0.50\n",
            "|   |   |   |   |--- value: [0.89]\n",
            "|   |   |   |--- Research >  0.50\n",
            "|   |   |   |   |--- GRE Score <= 335.50\n",
            "|   |   |   |   |   |--- GRE Score <= 329.50\n",
            "|   |   |   |   |   |   |--- TOEFL Score <= 113.50\n",
            "|   |   |   |   |   |   |   |--- value: [0.92]\n",
            "|   |   |   |   |   |   |--- TOEFL Score >  113.50\n",
            "|   |   |   |   |   |   |   |--- value: [0.93]\n",
            "|   |   |   |   |   |--- GRE Score >  329.50\n",
            "|   |   |   |   |   |   |--- Serial No. <= 369.00\n",
            "|   |   |   |   |   |   |   |--- value: [0.94]\n",
            "|   |   |   |   |   |   |--- Serial No. >  369.00\n",
            "|   |   |   |   |   |   |   |--- value: [0.95]\n",
            "|   |   |   |   |--- GRE Score >  335.50\n",
            "|   |   |   |   |   |--- CGPA <= 9.71\n",
            "|   |   |   |   |   |   |--- CGPA <= 9.56\n",
            "|   |   |   |   |   |   |   |--- value: [0.96]\n",
            "|   |   |   |   |   |   |--- CGPA >  9.56\n",
            "|   |   |   |   |   |   |   |--- GRE Score <= 339.00\n",
            "|   |   |   |   |   |   |   |   |--- value: [0.95]\n",
            "|   |   |   |   |   |   |   |--- GRE Score >  339.00\n",
            "|   |   |   |   |   |   |   |   |--- value: [0.94]\n",
            "|   |   |   |   |   |--- CGPA >  9.71\n",
            "|   |   |   |   |   |   |--- CGPA <= 9.89\n",
            "|   |   |   |   |   |   |   |--- value: [0.96]\n",
            "|   |   |   |   |   |   |--- CGPA >  9.89\n",
            "|   |   |   |   |   |   |   |--- value: [0.97]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dapat dilihat bahwa *decision tree* yang dihasilkan terlihat sangat kompleks. Hal tersebut beresiko untuk terjadi *overfitting* dan juga sulit untuk divisualisasikan. Oleh karena itu, akan perubahan *hyperparameter* pada model decision tree bisa membuat model yang dihasilkan tidak terlalu kompleks."
      ],
      "metadata": {
        "id": "cWvugkPIJiq0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Membangun model tree\n",
        "dt_md4 = DecisionTreeRegressor(max_depth=4)\n",
        "dt_md4.fit(X_train_admission, Y_train_admission)\n",
        "\n",
        "# Melakukan visualisasi pada decision tree yang sudah dibangun sebelumnya\n",
        "print(tree.export_text(dt_md4, feature_names=pd.Series(X_train_admission.columns).array))"
      ],
      "metadata": {
        "id": "tIwjOiVGJk4_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "772cf052-4f2f-459f-cdcc-2d17e66e8cd4"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|--- CGPA <= 8.93\n",
            "|   |--- CGPA <= 8.03\n",
            "|   |   |--- GRE Score <= 305.50\n",
            "|   |   |   |--- CGPA <= 7.66\n",
            "|   |   |   |   |--- value: [0.46]\n",
            "|   |   |   |--- CGPA >  7.66\n",
            "|   |   |   |   |--- value: [0.55]\n",
            "|   |   |--- GRE Score >  305.50\n",
            "|   |   |   |--- GRE Score <= 319.50\n",
            "|   |   |   |   |--- value: [0.60]\n",
            "|   |   |   |--- GRE Score >  319.50\n",
            "|   |   |   |   |--- value: [0.74]\n",
            "|   |--- CGPA >  8.03\n",
            "|   |   |--- CGPA <= 8.34\n",
            "|   |   |   |--- Research <= 0.50\n",
            "|   |   |   |   |--- value: [0.63]\n",
            "|   |   |   |--- Research >  0.50\n",
            "|   |   |   |   |--- value: [0.69]\n",
            "|   |   |--- CGPA >  8.34\n",
            "|   |   |   |--- Unnamed: 0 <= 126.00\n",
            "|   |   |   |   |--- value: [0.68]\n",
            "|   |   |   |--- Unnamed: 0 >  126.00\n",
            "|   |   |   |   |--- value: [0.74]\n",
            "|--- CGPA >  8.93\n",
            "|   |--- CGPA <= 9.18\n",
            "|   |   |--- CGPA <= 9.05\n",
            "|   |   |   |--- GRE Score <= 311.00\n",
            "|   |   |   |   |--- value: [0.66]\n",
            "|   |   |   |--- GRE Score >  311.00\n",
            "|   |   |   |   |--- value: [0.80]\n",
            "|   |   |--- CGPA >  9.05\n",
            "|   |   |   |--- University Rating <= 4.50\n",
            "|   |   |   |   |--- value: [0.83]\n",
            "|   |   |   |--- University Rating >  4.50\n",
            "|   |   |   |   |--- value: [0.89]\n",
            "|   |--- CGPA >  9.18\n",
            "|   |   |--- CGPA <= 9.47\n",
            "|   |   |   |--- TOEFL Score <= 113.50\n",
            "|   |   |   |   |--- value: [0.90]\n",
            "|   |   |   |--- TOEFL Score >  113.50\n",
            "|   |   |   |   |--- value: [0.92]\n",
            "|   |   |--- CGPA >  9.47\n",
            "|   |   |   |--- Research <= 0.50\n",
            "|   |   |   |   |--- value: [0.89]\n",
            "|   |   |   |--- Research >  0.50\n",
            "|   |   |   |   |--- value: [0.95]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pada model decision tree di atas, dilakukan pembatasan pada kedalaman maksimal dengan mengatur nilai dari `max_depth`. Perubahan *hyperparameter* ini dilakukan untuk mendapatkan model dengan jenis yang sama namun atribut yang berbeda. Untuk pemilihan *hyperparameter* apa yang tepat, biasanya memperhatikan persebaran data pada dataset yang diberikan dan dibantu oleh pengalaman dalam melakukan serangkaian kegiatan data science.  \n",
        "\n",
        "Pemilihan dari *hyperparameter* biasanya disebut sebagai *Hyperparameter Tuning* dan ada metode yang dinamakan Grid Search Cross Validation yang bisa digunakan untuk memilih *hyperparameter* terbaik dari beberapa *hyperparameter* yang disediakan berdasarkan kriteria tertentu. Jika kalian tertarik terkait dengan penerapan Grid Search Cross Validation, silakan mencari dan mempraktikannya sebagai latihan mandiri.\n",
        "\n",
        "Informasi lebih lanjut dapat diakses pada dokumentasi berikut: [link text](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)"
      ],
      "metadata": {
        "id": "5Bbv0LQgJ0yj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ensemble Learning"
      ],
      "metadata": {
        "id": "LolRO4JNK7uq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Ensemble Learning* adalah proses di mana kita menggunakan banyak model untuk mendapatkan hasil yang lebih baik dibandingkan dengan menggunakan satu model saja. Salah satu jenis *ensemble learning* adalah *bagging* (*bootstrap aggregating*).\n",
        "\n",
        "Pada metode *bagging*, setiap model akan dilatih menggunakan subhimpunan dari data *training* (tidak keseluruhan data latih digunakan dalam setiap proses *training*). Pada subhimpunan data yang satu dengan yang lainnya bisa mengandung data yang sama (tidak harus beda semua), hal inilah yang disebut dengan *bootstrap sampling*. Nantinya, setiap model yang telah dilatih akan melakukan proses prediksi terhadap data yang baru. Hasil prediksi akhir didapatkan melalui sistem *majority voting* di mana hasil akhirnya akan menggunakan hasil prediksi yang paling banyak muncul pada model-model yang telah dibuat.\n",
        "\n",
        "![randforest.png](data:image/png;base64,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)\n",
        "\n",
        "Sumber: Lab 4 KASDD Gasal 2023"
      ],
      "metadata": {
        "id": "OaWIwQdRK0vo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### *Random Forest*"
      ],
      "metadata": {
        "id": "zvnbE7z4LMBc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Random Forest* merupakan salah satu variasi dari konsep *bagging* pada *ensemble learning* yang menggunakan Decision Tree sebagai basis modelnya. Setiap model yang dibangun berupa Decision Tree dan nantinya model tersebut dilatih dan digunakan untuk melakukan prediksi. Output dari Random Forest itu sendiri merupakan hasil prediksi yang paling banyak muncul di antara model-model Decision Tree."
      ],
      "metadata": {
        "id": "Bif73eNkLKrV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Melakukan training pada model random forest\n",
        "rf_md = RandomForestRegressor()\n",
        "rf_md.fit(X_train_admission, Y_train_admission)\n",
        "\n",
        "# Memprediksi data testing\n",
        "predicted = rf_md.predict(X_test_admission)\n",
        "\n",
        "# Menampilkan metrics\n",
        "regression_metrics(predicted, Y_test_admission)"
      ],
      "metadata": {
        "id": "XlcLUKTrLlMx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7de1a8a2-2c83-4e02-9a4d-ea39022870f3"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE: 0.043478571428571464\n",
            "MSE: 0.0032981152857142885\n",
            "RMSE: 0.05742921979022777\n",
            "R_squared: 0.7939781634838479\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rf_red_paramless = RandomForestClassifier()\n",
        "rf_red_paramless.fit(X_train_red, Y_train_red)\n",
        "\n",
        "predicted = rf_red_paramless.predict(X_test_red)\n",
        "\n",
        "classification_metrics(predicted, Y_test_red)"
      ],
      "metadata": {
        "id": "Klwhkf0b5hCK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb9fa98a-92bf-4484-902d-8be873cadfa0"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8544668587896254\n",
            "F1 Score: 0.845478576223799\n",
            "Recall Score: 0.8488248679134281\n",
            "Precision Score: 0.8444223547653493\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Terlihat bahwa terdapat perubahan pada metriknya.\n",
        "\n",
        "Diharapkan untuk mempelajari kelebihan dan kekurangan dari setiap jenis model yang dipelajari agar kita bisa mengetahui pada dataset seperti apa suatu jenis model cocok untuk digunakan. Agar model yang dihasilkan lebih baik, kita juga harus bisa memilih *hyperparameter* yang sesuai dengan permasalahan yang ingin diselesaikan.\n",
        "\n",
        "Adapun beberapa *hyperparameter* yang dapat kita eksplorasi pada Random Forest:\n",
        "* `n_estimators`: Berapa banyak decision tree yang akan membentuk random forest\n",
        "* `max_depth`: Kedalaman maksimal dari masing-masing Decision Tree\n",
        "* `min_samples_split`: Jumlah sample minimal yang diperlukan untuk memecah suatu internal node pada setiap Decision Tree\n",
        "\n",
        "Informasi lebih lanjut dapat diakses pada dokumentasi berikut: [dokumentasi Random Forest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html)"
      ],
      "metadata": {
        "id": "I7R0q1-KL4bE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "Tf9jZOQLMB1M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameter tuning dapat digunakan untuk mendapatkan hasil evaluasi yang terbaik untuk suatu model. Misalkan kita ingin mendapatkan parameter terbaik untuk model Decision Tree, maka kita harus mencoba berbagai kombinasi hyperparameter yang diinginkan. Untuk mempermudah mencari hyperparameter yang tepat, kita dapat menggunakan modul GridSearchCV dari library Scikit-Learn. Informasi lebih lanjut mengenai GridSearchCV dapat diakses [di sini](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)\n",
        "\n",
        "Beberapa parameter yang sering digunakan, yaitu:\n",
        "- `estimator`: model yang akan digunakan\n",
        "- `param_grid`: kombinasi berbagai hyperparameter yang akan digunakan.\n",
        "- `cv`: jumlah cross-validation yang ingin digunakan"
      ],
      "metadata": {
        "id": "PVCTf7zOMFVL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {'criterion': ['squared_error', 'friedman_mse', 'absolute_error'],\n",
        "               'min_samples_split': [10, 20, 50],\n",
        "               'max_depth' : [5, 10, 12, None]}\n",
        "\n",
        "dt = DecisionTreeRegressor()\n",
        "clf = GridSearchCV(estimator= dt,\n",
        "                   param_grid=param_grid, cv= 5)\n",
        "\n",
        "clf.fit(X_train_admission, Y_train_admission)"
      ],
      "metadata": {
        "id": "NNt7RotIMXqF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "71b58ed6-660d-4e0d-b072-3c2f5c74293e"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, estimator=DecisionTreeRegressor(),\n",
              "             param_grid={'criterion': ['squared_error', 'friedman_mse',\n",
              "                                       'absolute_error'],\n",
              "                         'max_depth': [5, 10, 12, None],\n",
              "                         'min_samples_split': [10, 20, 50]})"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=DecisionTreeRegressor(),\n",
              "             param_grid={&#x27;criterion&#x27;: [&#x27;squared_error&#x27;, &#x27;friedman_mse&#x27;,\n",
              "                                       &#x27;absolute_error&#x27;],\n",
              "                         &#x27;max_depth&#x27;: [5, 10, 12, None],\n",
              "                         &#x27;min_samples_split&#x27;: [10, 20, 50]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=DecisionTreeRegressor(),\n",
              "             param_grid={&#x27;criterion&#x27;: [&#x27;squared_error&#x27;, &#x27;friedman_mse&#x27;,\n",
              "                                       &#x27;absolute_error&#x27;],\n",
              "                         &#x27;max_depth&#x27;: [5, 10, 12, None],\n",
              "                         &#x27;min_samples_split&#x27;: [10, 20, 50]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf.best_params_"
      ],
      "metadata": {
        "id": "stZtyNMFN6Hw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d80b953-6c52-4818-d33c-e904c634e4af"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'criterion': 'absolute_error', 'max_depth': 10, 'min_samples_split': 50}"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_hp = DecisionTreeRegressor(**clf.best_params_)\n",
        "best_hp.fit(X_train_admission, Y_train_admission)\n",
        "predicted = best_hp.predict(X_test_admission)\n",
        "regression_metrics(predicted, Y_test_admission)"
      ],
      "metadata": {
        "id": "NDLLTNExOAHj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d9eb754-5cfa-4d94-a0f4-1baa19def63d"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE: 0.05342857142857143\n",
            "MSE: 0.005398571428571428\n",
            "RMSE: 0.07347497144314809\n",
            "R_squared: 0.6627699446724971\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sekarang kita mendapatkan kombinasi terbaik dari berbagai kombinasi hyperparameter yang telah kita coba."
      ],
      "metadata": {
        "id": "C87fQw5oOXug"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BONUS ROUND: Kaggle Competition!"
      ],
      "metadata": {
        "id": "9qkXvepLO_qr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dalam rangka menerapkan pemahaman kalian pada materi CART dan sebagai sarana untuk **mendapatkan nilai tambahan**, kalian **diwajibkan** untuk mengikuti Kaggle Competition yang akan diadakan bersamaan dengan Lab 4 ini.\n",
        "\n",
        "**Bagaimana Cara Mengikuti?**\n",
        "*   Kalian akan menemukan tautan ke kompetisi di bagian bawah section ini. Klik tautan tersebut untuk mengakses halaman kompetisi.\n",
        "*   Kerjakan solusi Anda menggunakan notebook ini.\n",
        "*   Unggah hasil prediksi Anda ke dalam kompetisi Kaggle yang telah disediakan. Format dari submission telah dispesifikasikan pada bagian **Submission File** di laman Kaggle.\n",
        "\n",
        "**Tautan Kaggle Competition**\n",
        "*   [Kaggle Competition Regression Case](https://www.kaggle.com/competitions/lab-4-regression-case?rvi=1)\n",
        "*   [Kaggle Competition Classification Case](https://www.kaggle.com/competitions/lab-4-klasifikasi-kualitas-wine)\n",
        "\n",
        "**Nilai Bonus**\n",
        "\n",
        "Penentuan peserta yang mendapatkan nilai bonus akan ditentukan sesuai dengan peringkat dari masing-masing peserta di leaderboard, semakin tinggi peringkat kalian, semakin besar nilai bonus yang akan kalian dapatkan.\n"
      ],
      "metadata": {
        "id": "CitGye_APDEI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Latihan Soal"
      ],
      "metadata": {
        "id": "3q5-6UoFPI78"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SOAL 2 [10]"
      ],
      "metadata": {
        "id": "_PbYq6kjPYsp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SOAL 2a\n",
        "[2.5] Bangun dan latih 2 model decision tree (decision tree regressor untuk admission dan decision tree classifier untuk red wine) dengan memberikan nilai pada *hyperparameter*:\n",
        "- `max_depth = 4`\n",
        "- `random_state = 2023`."
      ],
      "metadata": {
        "id": "oPsSi2YxRxIV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dtc_red_2 = DecisionTreeClassifier(max_depth=4, random_state=2023)\n",
        "dtc_red_2.fit(X_train_red, Y_train_red)"
      ],
      "metadata": {
        "id": "_ubYa3xhNIPM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "outputId": "f403c04f-1be7-4096-dc60-bef217e6b75e"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(max_depth=4, random_state=2023)"
            ],
            "text/html": [
              "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=4, random_state=2023)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=4, random_state=2023)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classification_metrics(dtc_red_2.predict(X_test_red), Y_test_red)\n",
        "dtr_adm_2 = DecisionTreeRegressor(max_depth=4, random_state=2023)\n",
        "dtr_adm_2.fit(X_train_admission, Y_train_admission)\n",
        "regression_metrics(dtr_adm_2.predict(X_test_admission), Y_test_admission)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qb0FHIS30X8t",
        "outputId": "1ed4b0da-eb37-499b-a7b9-d86cdc238618"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5043227665706052\n",
            "F1 Score: 0.49890891932476866\n",
            "Recall Score: 0.5079135448132686\n",
            "Precision Score: 0.534874684750168\n",
            "MAE: 0.05423554072938112\n",
            "MSE: 0.004651897304452626\n",
            "RMSE: 0.06820481877736079\n",
            "R_squared: 0.7094120905660506\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SOAL 2b\n",
        "[2.5]  Visualisasikan 2 model decision tree (decision tree regressor untuk admission dan decision tree classifier untuk red wine) yang didapat pada soal 1a!"
      ],
      "metadata": {
        "id": "T4XW0l4yR_2T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(tree.export_text(dtc_red_2))"
      ],
      "metadata": {
        "id": "t1nWXE9LNJeH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec1e8644-42b9-4fcc-ab50-b18d595b354c"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|--- feature_9 <= 0.64\n",
            "|   |--- feature_1 <= 0.75\n",
            "|   |   |--- feature_10 <= 9.00\n",
            "|   |   |   |--- class: 3\n",
            "|   |   |--- feature_10 >  9.00\n",
            "|   |   |   |--- feature_10 <= 10.30\n",
            "|   |   |   |   |--- class: 5\n",
            "|   |   |   |--- feature_10 >  10.30\n",
            "|   |   |   |   |--- class: 6\n",
            "|   |--- feature_1 >  0.75\n",
            "|   |   |--- feature_4 <= 0.09\n",
            "|   |   |   |--- feature_7 <= 1.00\n",
            "|   |   |   |   |--- class: 4\n",
            "|   |   |   |--- feature_7 >  1.00\n",
            "|   |   |   |   |--- class: 3\n",
            "|   |   |--- feature_4 >  0.09\n",
            "|   |   |   |--- feature_10 <= 10.99\n",
            "|   |   |   |   |--- class: 3\n",
            "|   |   |   |--- feature_10 >  10.99\n",
            "|   |   |   |   |--- class: 4\n",
            "|--- feature_9 >  0.64\n",
            "|   |--- feature_10 <= 10.90\n",
            "|   |   |--- feature_10 <= 9.90\n",
            "|   |   |   |--- feature_10 <= 9.82\n",
            "|   |   |   |   |--- class: 5\n",
            "|   |   |   |--- feature_10 >  9.82\n",
            "|   |   |   |   |--- class: 3\n",
            "|   |   |--- feature_10 >  9.90\n",
            "|   |   |   |--- feature_5 <= 6.14\n",
            "|   |   |   |   |--- class: 8\n",
            "|   |   |   |--- feature_5 >  6.14\n",
            "|   |   |   |   |--- class: 7\n",
            "|   |--- feature_10 >  10.90\n",
            "|   |   |--- feature_4 <= 0.09\n",
            "|   |   |   |--- feature_8 <= 3.25\n",
            "|   |   |   |   |--- class: 8\n",
            "|   |   |   |--- feature_8 >  3.25\n",
            "|   |   |   |   |--- class: 7\n",
            "|   |   |--- feature_4 >  0.09\n",
            "|   |   |   |--- feature_1 <= 0.57\n",
            "|   |   |   |   |--- class: 7\n",
            "|   |   |   |--- feature_1 >  0.57\n",
            "|   |   |   |   |--- class: 6\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dot_data = tree.export_graphviz(dtc_red_2, out_file=None,\n",
        "                                feature_names=pd.Series(X_train_red\n",
        "                                                        .columns).array,\n",
        "                                filled=True, rounded=True,\n",
        "                                special_characters=True)\n",
        "\n",
        "# Membuat dan menampilkan visualisasi\n",
        "graph = graphviz.Source(dot_data)\n",
        "graph.render(filename=\"decision_tree_visualization 2\", format=\"pdf\")\n",
        "graph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "id": "2_uqWsA32PBq",
        "outputId": "3ba96531-205b-420e-ed7e-b594ff92480f"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: Tree Pages: 1 -->\n<svg width=\"2772pt\" height=\"477pt\"\n viewBox=\"0.00 0.00 2772.00 477.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 473)\">\n<title>Tree</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-473 2768,-473 2768,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<path fill=\"#feffff\" stroke=\"black\" d=\"M1320,-469C1320,-469 1099,-469 1099,-469 1093,-469 1087,-463 1087,-457 1087,-457 1087,-413 1087,-413 1087,-407 1093,-401 1099,-401 1099,-401 1320,-401 1320,-401 1326,-401 1332,-407 1332,-413 1332,-413 1332,-457 1332,-457 1332,-463 1326,-469 1320,-469\"/>\n<text text-anchor=\"start\" x=\"1156\" y=\"-453.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">sulphates â‰¤ 0.642</text>\n<text text-anchor=\"start\" x=\"1174\" y=\"-438.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.833</text>\n<text text-anchor=\"start\" x=\"1161\" y=\"-423.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2772</text>\n<text text-anchor=\"start\" x=\"1095\" y=\"-408.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [460, 451, 474, 467, 463, 457]</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<path fill=\"#fffdfc\" stroke=\"black\" d=\"M938.5,-365C938.5,-365 740.5,-365 740.5,-365 734.5,-365 728.5,-359 728.5,-353 728.5,-353 728.5,-309 728.5,-309 728.5,-303 734.5,-297 740.5,-297 740.5,-297 938.5,-297 938.5,-297 944.5,-297 950.5,-303 950.5,-309 950.5,-309 950.5,-353 950.5,-353 950.5,-359 944.5,-365 938.5,-365\"/>\n<text text-anchor=\"start\" x=\"773\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">volatile acidity â‰¤ 0.745</text>\n<text text-anchor=\"start\" x=\"804\" y=\"-334.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.769</text>\n<text text-anchor=\"start\" x=\"791\" y=\"-319.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1479</text>\n<text text-anchor=\"start\" x=\"736.5\" y=\"-304.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [408, 393, 345, 241, 87, 5]</text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1089.63,-400.95C1048.3,-389.56 1002,-376.8 960.57,-365.38\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"961.28,-361.94 950.71,-362.66 959.42,-368.69 961.28,-361.94\"/>\n<text text-anchor=\"middle\" x=\"963.06\" y=\"-380.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\n</g>\n<!-- 14 -->\n<g id=\"node15\" class=\"node\">\n<title>14</title>\n<path fill=\"#fdeff7\" stroke=\"black\" d=\"M1697.5,-365C1697.5,-365 1491.5,-365 1491.5,-365 1485.5,-365 1479.5,-359 1479.5,-353 1479.5,-353 1479.5,-309 1479.5,-309 1479.5,-303 1485.5,-297 1491.5,-297 1491.5,-297 1697.5,-297 1697.5,-297 1703.5,-297 1709.5,-303 1709.5,-309 1709.5,-309 1709.5,-353 1709.5,-353 1709.5,-359 1703.5,-365 1697.5,-365\"/>\n<text text-anchor=\"start\" x=\"1544.5\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">alcohol â‰¤ 10.901</text>\n<text text-anchor=\"start\" x=\"1559\" y=\"-334.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.749</text>\n<text text-anchor=\"start\" x=\"1546\" y=\"-319.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1293</text>\n<text text-anchor=\"start\" x=\"1487.5\" y=\"-304.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [52, 58, 129, 226, 376, 452]</text>\n</g>\n<!-- 0&#45;&gt;14 -->\n<g id=\"edge14\" class=\"edge\">\n<title>0&#45;&gt;14</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1332.11,-401.52C1375.9,-389.91 1425.28,-376.83 1469.29,-365.17\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1470.41,-368.5 1479.18,-362.55 1468.62,-361.73 1470.41,-368.5\"/>\n<text text-anchor=\"middle\" x=\"1466.62\" y=\"-380.47\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\">\n<title>2</title>\n<path fill=\"#e9fcf1\" stroke=\"black\" d=\"M421,-261C421,-261 230,-261 230,-261 224,-261 218,-255 218,-249 218,-249 218,-205 218,-205 218,-199 224,-193 230,-193 230,-193 421,-193 421,-193 427,-193 433,-199 433,-205 433,-205 433,-249 433,-249 433,-255 427,-261 421,-261\"/>\n<text text-anchor=\"start\" x=\"279.5\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">alcohol â‰¤ 8.999</text>\n<text text-anchor=\"start\" x=\"290\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.756</text>\n<text text-anchor=\"start\" x=\"280.5\" y=\"-215.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 891</text>\n<text text-anchor=\"start\" x=\"226\" y=\"-200.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [73, 211, 297, 221, 84, 5]</text>\n</g>\n<!-- 1&#45;&gt;2 -->\n<g id=\"edge2\" class=\"edge\">\n<title>1&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M728.29,-307.93C644.24,-291.25 529.11,-268.4 443.45,-251.41\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"443.91,-247.93 433.42,-249.42 442.55,-254.8 443.91,-247.93\"/>\n</g>\n<!-- 7 -->\n<g id=\"node8\" class=\"node\">\n<title>7</title>\n<path fill=\"#f5d0b4\" stroke=\"black\" d=\"M927.5,-261C927.5,-261 751.5,-261 751.5,-261 745.5,-261 739.5,-255 739.5,-249 739.5,-249 739.5,-205 739.5,-205 739.5,-199 745.5,-193 751.5,-193 751.5,-193 927.5,-193 927.5,-193 933.5,-193 939.5,-199 939.5,-205 939.5,-205 939.5,-249 939.5,-249 939.5,-255 933.5,-261 927.5,-261\"/>\n<text text-anchor=\"start\" x=\"788\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">chlorides â‰¤ 0.092</text>\n<text text-anchor=\"start\" x=\"804\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.572</text>\n<text text-anchor=\"start\" x=\"794.5\" y=\"-215.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 588</text>\n<text text-anchor=\"start\" x=\"747.5\" y=\"-200.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [335, 182, 48, 20, 3, 0]</text>\n</g>\n<!-- 1&#45;&gt;7 -->\n<g id=\"edge7\" class=\"edge\">\n<title>1&#45;&gt;7</title>\n<path fill=\"none\" stroke=\"black\" d=\"M839.5,-296.88C839.5,-288.78 839.5,-279.98 839.5,-271.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"843,-271.3 839.5,-261.3 836,-271.3 843,-271.3\"/>\n</g>\n<!-- 3 -->\n<g id=\"node4\" class=\"node\">\n<title>3</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M187.5,-149.5C187.5,-149.5 49.5,-149.5 49.5,-149.5 43.5,-149.5 37.5,-143.5 37.5,-137.5 37.5,-137.5 37.5,-108.5 37.5,-108.5 37.5,-102.5 43.5,-96.5 49.5,-96.5 49.5,-96.5 187.5,-96.5 187.5,-96.5 193.5,-96.5 199.5,-102.5 199.5,-108.5 199.5,-108.5 199.5,-137.5 199.5,-137.5 199.5,-143.5 193.5,-149.5 187.5,-149.5\"/>\n<text text-anchor=\"start\" x=\"90.5\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"77.5\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 39</text>\n<text text-anchor=\"start\" x=\"45.5\" y=\"-104.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [39, 0, 0, 0, 0, 0]</text>\n</g>\n<!-- 2&#45;&gt;3 -->\n<g id=\"edge3\" class=\"edge\">\n<title>2&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M258.29,-192.88C232.96,-180.4 204.31,-166.28 179.57,-154.09\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"180.81,-150.8 170.29,-149.52 177.71,-157.08 180.81,-150.8\"/>\n</g>\n<!-- 4 -->\n<g id=\"node5\" class=\"node\">\n<title>4</title>\n<path fill=\"#e7fcf0\" stroke=\"black\" d=\"M421,-157C421,-157 230,-157 230,-157 224,-157 218,-151 218,-145 218,-145 218,-101 218,-101 218,-95 224,-89 230,-89 230,-89 421,-89 421,-89 427,-89 433,-95 433,-101 433,-101 433,-145 433,-145 433,-151 427,-157 421,-157\"/>\n<text text-anchor=\"start\" x=\"283\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">alcohol â‰¤ 10.3</text>\n<text text-anchor=\"start\" x=\"290\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.739</text>\n<text text-anchor=\"start\" x=\"280.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 852</text>\n<text text-anchor=\"start\" x=\"226\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [34, 211, 297, 221, 84, 5]</text>\n</g>\n<!-- 2&#45;&gt;4 -->\n<g id=\"edge4\" class=\"edge\">\n<title>2&#45;&gt;4</title>\n<path fill=\"none\" stroke=\"black\" d=\"M325.5,-192.88C325.5,-184.78 325.5,-175.98 325.5,-167.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"329,-167.3 325.5,-157.3 322,-167.3 329,-167.3\"/>\n</g>\n<!-- 5 -->\n<g id=\"node6\" class=\"node\">\n<title>5</title>\n<path fill=\"#b8f6d2\" stroke=\"black\" d=\"M195,-53C195,-53 12,-53 12,-53 6,-53 0,-47 0,-41 0,-41 0,-12 0,-12 0,-6 6,0 12,0 12,0 195,0 195,0 201,0 207,-6 207,-12 207,-12 207,-41 207,-41 207,-47 201,-53 195,-53\"/>\n<text text-anchor=\"start\" x=\"68\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.664</text>\n<text text-anchor=\"start\" x=\"58.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 497</text>\n<text text-anchor=\"start\" x=\"8\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [34, 105, 245, 104, 9, 0]</text>\n</g>\n<!-- 4&#45;&gt;5 -->\n<g id=\"edge5\" class=\"edge\">\n<title>4&#45;&gt;5</title>\n<path fill=\"none\" stroke=\"black\" d=\"M247.86,-88.95C223.46,-78.56 196.7,-67.17 172.91,-57.05\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"174.18,-53.78 163.61,-53.09 171.44,-60.22 174.18,-53.78\"/>\n</g>\n<!-- 6 -->\n<g id=\"node7\" class=\"node\">\n<title>6</title>\n<path fill=\"#f6fbfe\" stroke=\"black\" d=\"M413.5,-53C413.5,-53 237.5,-53 237.5,-53 231.5,-53 225.5,-47 225.5,-41 225.5,-41 225.5,-12 225.5,-12 225.5,-6 231.5,0 237.5,0 237.5,0 413.5,0 413.5,0 419.5,0 425.5,-6 425.5,-12 425.5,-12 425.5,-41 425.5,-41 425.5,-47 419.5,-53 413.5,-53\"/>\n<text text-anchor=\"start\" x=\"290\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.736</text>\n<text text-anchor=\"start\" x=\"280.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 355</text>\n<text text-anchor=\"start\" x=\"233.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 106, 52, 117, 75, 5]</text>\n</g>\n<!-- 4&#45;&gt;6 -->\n<g id=\"edge6\" class=\"edge\">\n<title>4&#45;&gt;6</title>\n<path fill=\"none\" stroke=\"black\" d=\"M325.5,-88.95C325.5,-80.72 325.5,-71.85 325.5,-63.48\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"329,-63.24 325.5,-53.24 322,-63.24 329,-63.24\"/>\n</g>\n<!-- 8 -->\n<g id=\"node9\" class=\"node\">\n<title>8</title>\n<path fill=\"#f2fbe4\" stroke=\"black\" d=\"M822.5,-157C822.5,-157 646.5,-157 646.5,-157 640.5,-157 634.5,-151 634.5,-145 634.5,-145 634.5,-101 634.5,-101 634.5,-95 640.5,-89 646.5,-89 646.5,-89 822.5,-89 822.5,-89 828.5,-89 834.5,-95 834.5,-101 834.5,-101 834.5,-145 834.5,-145 834.5,-151 828.5,-157 822.5,-157\"/>\n<text text-anchor=\"start\" x=\"688.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">density â‰¤ 0.997</text>\n<text text-anchor=\"start\" x=\"699\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.625</text>\n<text text-anchor=\"start\" x=\"689.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 354</text>\n<text text-anchor=\"start\" x=\"642.5\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [135, 165, 35, 16, 3, 0]</text>\n</g>\n<!-- 7&#45;&gt;8 -->\n<g id=\"edge8\" class=\"edge\">\n<title>7&#45;&gt;8</title>\n<path fill=\"none\" stroke=\"black\" d=\"M805.41,-192.88C796.06,-183.8 785.81,-173.85 776.09,-164.4\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"778.39,-161.76 768.78,-157.3 773.51,-166.78 778.39,-161.76\"/>\n</g>\n<!-- 11 -->\n<g id=\"node12\" class=\"node\">\n<title>11</title>\n<path fill=\"#e99558\" stroke=\"black\" d=\"M1026,-157C1026,-157 865,-157 865,-157 859,-157 853,-151 853,-145 853,-145 853,-101 853,-101 853,-95 859,-89 865,-89 865,-89 1026,-89 1026,-89 1032,-89 1038,-95 1038,-101 1038,-101 1038,-145 1038,-145 1038,-151 1032,-157 1026,-157\"/>\n<text text-anchor=\"start\" x=\"895.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">alcohol â‰¤ 10.991</text>\n<text text-anchor=\"start\" x=\"910\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.261</text>\n<text text-anchor=\"start\" x=\"900.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 234</text>\n<text text-anchor=\"start\" x=\"861\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [200, 17, 13, 4, 0, 0]</text>\n</g>\n<!-- 7&#45;&gt;11 -->\n<g id=\"edge11\" class=\"edge\">\n<title>7&#45;&gt;11</title>\n<path fill=\"none\" stroke=\"black\" d=\"M873.92,-192.88C883.36,-183.8 893.7,-173.85 903.52,-164.4\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"906.12,-166.76 910.89,-157.3 901.26,-161.71 906.12,-166.76\"/>\n</g>\n<!-- 9 -->\n<g id=\"node10\" class=\"node\">\n<title>9</title>\n<path fill=\"#cdf299\" stroke=\"black\" d=\"M623.5,-53C623.5,-53 455.5,-53 455.5,-53 449.5,-53 443.5,-47 443.5,-41 443.5,-41 443.5,-12 443.5,-12 443.5,-6 449.5,0 455.5,0 455.5,0 623.5,0 623.5,0 629.5,0 635.5,-6 635.5,-12 635.5,-12 635.5,-41 635.5,-41 635.5,-47 629.5,-53 623.5,-53\"/>\n<text text-anchor=\"start\" x=\"504\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.554</text>\n<text text-anchor=\"start\" x=\"494.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 248</text>\n<text text-anchor=\"start\" x=\"451.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [55, 154, 22, 14, 3, 0]</text>\n</g>\n<!-- 8&#45;&gt;9 -->\n<g id=\"edge9\" class=\"edge\">\n<title>8&#45;&gt;9</title>\n<path fill=\"none\" stroke=\"black\" d=\"M666.3,-88.95C645.16,-78.7 621.99,-67.47 601.3,-57.45\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"602.82,-54.3 592.3,-53.09 599.77,-60.6 602.82,-54.3\"/>\n</g>\n<!-- 10 -->\n<g id=\"node11\" class=\"node\">\n<title>10</title>\n<path fill=\"#eca470\" stroke=\"black\" d=\"M819,-53C819,-53 666,-53 666,-53 660,-53 654,-47 654,-41 654,-41 654,-12 654,-12 654,-6 660,0 666,0 666,0 819,0 819,0 825,0 831,-6 831,-12 831,-12 831,-41 831,-41 831,-47 825,-53 819,-53\"/>\n<text text-anchor=\"start\" x=\"707\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.404</text>\n<text text-anchor=\"start\" x=\"697.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 106</text>\n<text text-anchor=\"start\" x=\"662\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [80, 11, 13, 2, 0, 0]</text>\n</g>\n<!-- 8&#45;&gt;10 -->\n<g id=\"edge10\" class=\"edge\">\n<title>8&#45;&gt;10</title>\n<path fill=\"none\" stroke=\"black\" d=\"M737.3,-88.95C738,-80.62 738.76,-71.65 739.48,-63.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"742.97,-63.5 740.32,-53.24 735.99,-62.91 742.97,-63.5\"/>\n</g>\n<!-- 12 -->\n<g id=\"node13\" class=\"node\">\n<title>12</title>\n<path fill=\"#e89050\" stroke=\"black\" d=\"M1014,-53C1014,-53 861,-53 861,-53 855,-53 849,-47 849,-41 849,-41 849,-12 849,-12 849,-6 855,0 861,0 861,0 1014,0 1014,0 1020,0 1026,-6 1026,-12 1026,-12 1026,-41 1026,-41 1026,-47 1020,-53 1014,-53\"/>\n<text text-anchor=\"start\" x=\"902\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.205</text>\n<text text-anchor=\"start\" x=\"892.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 225</text>\n<text text-anchor=\"start\" x=\"857\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [200, 8, 13, 4, 0, 0]</text>\n</g>\n<!-- 11&#45;&gt;12 -->\n<g id=\"edge12\" class=\"edge\">\n<title>11&#45;&gt;12</title>\n<path fill=\"none\" stroke=\"black\" d=\"M942.7,-88.95C942,-80.62 941.24,-71.65 940.52,-63.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"944.01,-62.91 939.68,-53.24 937.03,-63.5 944.01,-62.91\"/>\n</g>\n<!-- 13 -->\n<g id=\"node14\" class=\"node\">\n<title>13</title>\n<path fill=\"#9de539\" stroke=\"black\" d=\"M1187,-53C1187,-53 1056,-53 1056,-53 1050,-53 1044,-47 1044,-41 1044,-41 1044,-12 1044,-12 1044,-6 1050,0 1056,0 1056,0 1187,0 1187,0 1193,0 1199,-6 1199,-12 1199,-12 1199,-41 1199,-41 1199,-47 1193,-53 1187,-53\"/>\n<text text-anchor=\"start\" x=\"1093.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1084\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 9</text>\n<text text-anchor=\"start\" x=\"1052\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 9, 0, 0, 0, 0]</text>\n</g>\n<!-- 11&#45;&gt;13 -->\n<g id=\"edge13\" class=\"edge\">\n<title>11&#45;&gt;13</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1007.06,-88.95C1025.88,-78.84 1046.49,-67.78 1064.96,-57.86\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1066.69,-60.9 1073.85,-53.09 1063.38,-54.73 1066.69,-60.9\"/>\n</g>\n<!-- 15 -->\n<g id=\"node16\" class=\"node\">\n<title>15</title>\n<path fill=\"#f5fafe\" stroke=\"black\" d=\"M1693.5,-261C1693.5,-261 1495.5,-261 1495.5,-261 1489.5,-261 1483.5,-255 1483.5,-249 1483.5,-249 1483.5,-205 1483.5,-205 1483.5,-199 1489.5,-193 1495.5,-193 1495.5,-193 1693.5,-193 1693.5,-193 1699.5,-193 1705.5,-199 1705.5,-205 1705.5,-205 1705.5,-249 1705.5,-249 1705.5,-255 1699.5,-261 1693.5,-261\"/>\n<text text-anchor=\"start\" x=\"1548.5\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">alcohol â‰¤ 9.897</text>\n<text text-anchor=\"start\" x=\"1559\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.804</text>\n<text text-anchor=\"start\" x=\"1549.5\" y=\"-215.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 510</text>\n<text text-anchor=\"start\" x=\"1491.5\" y=\"-200.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [52, 57, 118, 137, 101, 45]</text>\n</g>\n<!-- 14&#45;&gt;15 -->\n<g id=\"edge15\" class=\"edge\">\n<title>14&#45;&gt;15</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1594.5,-296.88C1594.5,-288.78 1594.5,-279.98 1594.5,-271.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1598,-271.3 1594.5,-261.3 1591,-271.3 1598,-271.3\"/>\n</g>\n<!-- 22 -->\n<g id=\"node23\" class=\"node\">\n<title>22</title>\n<path fill=\"#f8cce6\" stroke=\"black\" d=\"M2290.5,-261C2290.5,-261 2114.5,-261 2114.5,-261 2108.5,-261 2102.5,-255 2102.5,-249 2102.5,-249 2102.5,-205 2102.5,-205 2102.5,-199 2108.5,-193 2114.5,-193 2114.5,-193 2290.5,-193 2290.5,-193 2296.5,-193 2302.5,-199 2302.5,-205 2302.5,-205 2302.5,-249 2302.5,-249 2302.5,-255 2296.5,-261 2290.5,-261\"/>\n<text text-anchor=\"start\" x=\"2151\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">chlorides â‰¤ 0.086</text>\n<text text-anchor=\"start\" x=\"2167\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.593</text>\n<text text-anchor=\"start\" x=\"2157.5\" y=\"-215.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 783</text>\n<text text-anchor=\"start\" x=\"2110.5\" y=\"-200.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1, 11, 89, 275, 407]</text>\n</g>\n<!-- 14&#45;&gt;22 -->\n<g id=\"edge22\" class=\"edge\">\n<title>14&#45;&gt;22</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1709.57,-310.69C1819.41,-292.27 1983.76,-264.7 2092.04,-246.53\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2092.73,-249.96 2102.01,-244.86 2091.57,-243.06 2092.73,-249.96\"/>\n</g>\n<!-- 16 -->\n<g id=\"node17\" class=\"node\">\n<title>16</title>\n<path fill=\"#e5fcef\" stroke=\"black\" d=\"M1572,-157C1572,-157 1411,-157 1411,-157 1405,-157 1399,-151 1399,-145 1399,-145 1399,-101 1399,-101 1399,-95 1405,-89 1411,-89 1411,-89 1572,-89 1572,-89 1578,-89 1584,-95 1584,-101 1584,-101 1584,-145 1584,-145 1584,-151 1578,-157 1572,-157\"/>\n<text text-anchor=\"start\" x=\"1445.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">alcohol â‰¤ 9.819</text>\n<text text-anchor=\"start\" x=\"1456\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.753</text>\n<text text-anchor=\"start\" x=\"1446.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 223</text>\n<text text-anchor=\"start\" x=\"1407\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [46, 41, 75, 53, 4, 4]</text>\n</g>\n<!-- 15&#45;&gt;16 -->\n<g id=\"edge16\" class=\"edge\">\n<title>15&#45;&gt;16</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1561.06,-192.88C1551.88,-183.8 1541.83,-173.85 1532.3,-164.4\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1534.69,-161.85 1525.13,-157.3 1529.77,-166.82 1534.69,-161.85\"/>\n</g>\n<!-- 19 -->\n<g id=\"node20\" class=\"node\">\n<title>19</title>\n<path fill=\"#f7f2fd\" stroke=\"black\" d=\"M1782.5,-157C1782.5,-157 1614.5,-157 1614.5,-157 1608.5,-157 1602.5,-151 1602.5,-145 1602.5,-145 1602.5,-101 1602.5,-101 1602.5,-95 1608.5,-89 1614.5,-89 1614.5,-89 1782.5,-89 1782.5,-89 1788.5,-89 1794.5,-95 1794.5,-101 1794.5,-101 1794.5,-145 1794.5,-145 1794.5,-151 1788.5,-157 1782.5,-157\"/>\n<text text-anchor=\"start\" x=\"1620.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">free sulfur dioxide â‰¤ 6.144</text>\n<text text-anchor=\"start\" x=\"1663\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.754</text>\n<text text-anchor=\"start\" x=\"1653.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 287</text>\n<text text-anchor=\"start\" x=\"1610.5\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [6, 16, 43, 84, 97, 41]</text>\n</g>\n<!-- 15&#45;&gt;19 -->\n<g id=\"edge19\" class=\"edge\">\n<title>15&#45;&gt;19</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1628.27,-192.88C1637.53,-183.8 1647.68,-173.85 1657.31,-164.4\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1659.86,-166.8 1664.55,-157.3 1654.96,-161.8 1659.86,-166.8\"/>\n</g>\n<!-- 17 -->\n<g id=\"node18\" class=\"node\">\n<title>17</title>\n<path fill=\"#e1fbec\" stroke=\"black\" d=\"M1390,-53C1390,-53 1229,-53 1229,-53 1223,-53 1217,-47 1217,-41 1217,-41 1217,-12 1217,-12 1217,-6 1223,0 1229,0 1229,0 1390,0 1390,0 1396,0 1402,-6 1402,-12 1402,-12 1402,-41 1402,-41 1402,-47 1396,-53 1390,-53\"/>\n<text text-anchor=\"start\" x=\"1277.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.73</text>\n<text text-anchor=\"start\" x=\"1264.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 198</text>\n<text text-anchor=\"start\" x=\"1225\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [25, 39, 75, 53, 4, 2]</text>\n</g>\n<!-- 16&#45;&gt;17 -->\n<g id=\"edge17\" class=\"edge\">\n<title>16&#45;&gt;17</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1427.85,-88.95C1408.29,-78.79 1386.87,-67.67 1367.7,-57.72\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1369.27,-54.59 1358.78,-53.09 1366.04,-60.8 1369.27,-54.59\"/>\n</g>\n<!-- 18 -->\n<g id=\"node19\" class=\"node\">\n<title>18</title>\n<path fill=\"#ea975b\" stroke=\"black\" d=\"M1570.5,-53C1570.5,-53 1432.5,-53 1432.5,-53 1426.5,-53 1420.5,-47 1420.5,-41 1420.5,-41 1420.5,-12 1420.5,-12 1420.5,-6 1426.5,0 1432.5,0 1432.5,0 1570.5,0 1570.5,0 1576.5,0 1582.5,-6 1582.5,-12 1582.5,-12 1582.5,-41 1582.5,-41 1582.5,-47 1576.5,-53 1570.5,-53\"/>\n<text text-anchor=\"start\" x=\"1466\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.282</text>\n<text text-anchor=\"start\" x=\"1460.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 25</text>\n<text text-anchor=\"start\" x=\"1428.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [21, 2, 0, 0, 0, 2]</text>\n</g>\n<!-- 16&#45;&gt;18 -->\n<g id=\"edge18\" class=\"edge\">\n<title>16&#45;&gt;18</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1495,-88.95C1495.88,-80.62 1496.83,-71.65 1497.72,-63.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1501.2,-63.55 1498.78,-53.24 1494.24,-62.81 1501.2,-63.55\"/>\n</g>\n<!-- 20 -->\n<g id=\"node21\" class=\"node\">\n<title>20</title>\n<path fill=\"#fbe1f0\" stroke=\"black\" d=\"M1766,-53C1766,-53 1613,-53 1613,-53 1607,-53 1601,-47 1601,-41 1601,-41 1601,-12 1601,-12 1601,-6 1607,0 1613,0 1613,0 1766,0 1766,0 1772,0 1778,-6 1778,-12 1778,-12 1778,-41 1778,-41 1778,-47 1772,-53 1766,-53\"/>\n<text text-anchor=\"start\" x=\"1654\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.658</text>\n<text text-anchor=\"start\" x=\"1648.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 70</text>\n<text text-anchor=\"start\" x=\"1609\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 0, 4, 24, 11, 31]</text>\n</g>\n<!-- 19&#45;&gt;20 -->\n<g id=\"edge20\" class=\"edge\">\n<title>19&#45;&gt;20</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1695.35,-88.95C1694.56,-80.62 1693.7,-71.65 1692.9,-63.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1696.38,-62.86 1691.95,-53.24 1689.42,-63.52 1696.38,-62.86\"/>\n</g>\n<!-- 21 -->\n<g id=\"node22\" class=\"node\">\n<title>21</title>\n<path fill=\"#eadefb\" stroke=\"black\" d=\"M1976.5,-53C1976.5,-53 1808.5,-53 1808.5,-53 1802.5,-53 1796.5,-47 1796.5,-41 1796.5,-41 1796.5,-12 1796.5,-12 1796.5,-6 1802.5,0 1808.5,0 1808.5,0 1976.5,0 1976.5,0 1982.5,0 1988.5,-6 1988.5,-12 1988.5,-12 1988.5,-41 1988.5,-41 1988.5,-47 1982.5,-53 1976.5,-53\"/>\n<text text-anchor=\"start\" x=\"1857\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.726</text>\n<text text-anchor=\"start\" x=\"1847.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 217</text>\n<text text-anchor=\"start\" x=\"1804.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [6, 16, 39, 60, 86, 10]</text>\n</g>\n<!-- 19&#45;&gt;21 -->\n<g id=\"edge21\" class=\"edge\">\n<title>19&#45;&gt;21</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1766.35,-88.95C1787.29,-78.75 1810.23,-67.57 1830.74,-57.59\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1832.52,-60.61 1839.97,-53.09 1829.45,-54.32 1832.52,-60.61\"/>\n</g>\n<!-- 23 -->\n<g id=\"node24\" class=\"node\">\n<title>23</title>\n<path fill=\"#f5b1d8\" stroke=\"black\" d=\"M2286.5,-157C2286.5,-157 2118.5,-157 2118.5,-157 2112.5,-157 2106.5,-151 2106.5,-145 2106.5,-145 2106.5,-101 2106.5,-101 2106.5,-95 2112.5,-89 2118.5,-89 2118.5,-89 2286.5,-89 2286.5,-89 2292.5,-89 2298.5,-95 2298.5,-101 2298.5,-101 2298.5,-145 2298.5,-145 2298.5,-151 2292.5,-157 2286.5,-157\"/>\n<text text-anchor=\"start\" x=\"2169\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">pH â‰¤ 3.249</text>\n<text text-anchor=\"start\" x=\"2167\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.553</text>\n<text text-anchor=\"start\" x=\"2157.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 698</text>\n<text text-anchor=\"start\" x=\"2114.5\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 0, 5, 68, 218, 407]</text>\n</g>\n<!-- 22&#45;&gt;23 -->\n<g id=\"edge23\" class=\"edge\">\n<title>22&#45;&gt;23</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2202.5,-192.88C2202.5,-184.78 2202.5,-175.98 2202.5,-167.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2206,-167.3 2202.5,-157.3 2199,-167.3 2206,-167.3\"/>\n</g>\n<!-- 26 -->\n<g id=\"node27\" class=\"node\">\n<title>26</title>\n<path fill=\"#b890f0\" stroke=\"black\" d=\"M2578.5,-157C2578.5,-157 2432.5,-157 2432.5,-157 2426.5,-157 2420.5,-151 2420.5,-145 2420.5,-145 2420.5,-101 2420.5,-101 2420.5,-95 2426.5,-89 2432.5,-89 2432.5,-89 2578.5,-89 2578.5,-89 2584.5,-89 2590.5,-95 2590.5,-101 2590.5,-101 2590.5,-145 2590.5,-145 2590.5,-151 2584.5,-157 2578.5,-157\"/>\n<text text-anchor=\"start\" x=\"2439\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">volatile acidity â‰¤ 0.575</text>\n<text text-anchor=\"start\" x=\"2470\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.484</text>\n<text text-anchor=\"start\" x=\"2464.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 85</text>\n<text text-anchor=\"start\" x=\"2428.5\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1, 6, 21, 57, 0]</text>\n</g>\n<!-- 22&#45;&gt;26 -->\n<g id=\"edge26\" class=\"edge\">\n<title>22&#45;&gt;26</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2300.88,-192.88C2336.1,-181.03 2375.71,-167.69 2410.63,-155.94\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2411.99,-159.17 2420.35,-152.67 2409.75,-152.54 2411.99,-159.17\"/>\n</g>\n<!-- 24 -->\n<g id=\"node25\" class=\"node\">\n<title>24</title>\n<path fill=\"#eb66b3\" stroke=\"black\" d=\"M2180,-53C2180,-53 2019,-53 2019,-53 2013,-53 2007,-47 2007,-41 2007,-41 2007,-12 2007,-12 2007,-6 2013,0 2019,0 2019,0 2180,0 2180,0 2186,0 2192,-6 2192,-12 2192,-12 2192,-41 2192,-41 2192,-47 2186,-53 2180,-53\"/>\n<text text-anchor=\"start\" x=\"2064\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.326</text>\n<text text-anchor=\"start\" x=\"2054.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 299</text>\n<text text-anchor=\"start\" x=\"2015\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 0, 1, 12, 45, 241]</text>\n</g>\n<!-- 23&#45;&gt;24 -->\n<g id=\"edge24\" class=\"edge\">\n<title>23&#45;&gt;24</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2166.48,-88.95C2156.31,-79.62 2145.25,-69.47 2135.1,-60.16\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2137.29,-57.42 2127.55,-53.24 2132.55,-62.58 2137.29,-57.42\"/>\n</g>\n<!-- 25 -->\n<g id=\"node26\" class=\"node\">\n<title>25</title>\n<path fill=\"#fbf9fe\" stroke=\"black\" d=\"M2390.5,-53C2390.5,-53 2222.5,-53 2222.5,-53 2216.5,-53 2210.5,-47 2210.5,-41 2210.5,-41 2210.5,-12 2210.5,-12 2210.5,-6 2216.5,0 2222.5,0 2222.5,0 2390.5,0 2390.5,0 2396.5,0 2402.5,-6 2402.5,-12 2402.5,-12 2402.5,-41 2402.5,-41 2402.5,-47 2396.5,-53 2390.5,-53\"/>\n<text text-anchor=\"start\" x=\"2271\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.619</text>\n<text text-anchor=\"start\" x=\"2261.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 399</text>\n<text text-anchor=\"start\" x=\"2218.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 0, 4, 56, 173, 166]</text>\n</g>\n<!-- 23&#45;&gt;25 -->\n<g id=\"edge25\" class=\"edge\">\n<title>23&#45;&gt;25</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2238.87,-88.95C2249.14,-79.62 2260.31,-69.47 2270.55,-60.16\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2273.13,-62.55 2278.18,-53.24 2268.42,-57.37 2273.13,-62.55\"/>\n</g>\n<!-- 27 -->\n<g id=\"node28\" class=\"node\">\n<title>27</title>\n<path fill=\"#a876ed\" stroke=\"black\" d=\"M2578.5,-53C2578.5,-53 2432.5,-53 2432.5,-53 2426.5,-53 2420.5,-47 2420.5,-41 2420.5,-41 2420.5,-12 2420.5,-12 2420.5,-6 2426.5,0 2432.5,0 2432.5,0 2578.5,0 2578.5,0 2584.5,0 2590.5,-6 2590.5,-12 2590.5,-12 2590.5,-41 2590.5,-41 2590.5,-47 2584.5,-53 2578.5,-53\"/>\n<text text-anchor=\"start\" x=\"2470\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.398</text>\n<text text-anchor=\"start\" x=\"2464.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 72</text>\n<text text-anchor=\"start\" x=\"2428.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1, 3, 14, 54, 0]</text>\n</g>\n<!-- 26&#45;&gt;27 -->\n<g id=\"edge27\" class=\"edge\">\n<title>26&#45;&gt;27</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2505.5,-88.95C2505.5,-80.72 2505.5,-71.85 2505.5,-63.48\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2509,-63.24 2505.5,-53.24 2502,-63.24 2509,-63.24\"/>\n</g>\n<!-- 28 -->\n<g id=\"node29\" class=\"node\">\n<title>28</title>\n<path fill=\"#b0d8f5\" stroke=\"black\" d=\"M2752,-53C2752,-53 2621,-53 2621,-53 2615,-53 2609,-47 2609,-41 2609,-41 2609,-12 2609,-12 2609,-6 2615,0 2621,0 2621,0 2752,0 2752,0 2758,0 2764,-6 2764,-12 2764,-12 2764,-41 2764,-41 2764,-47 2758,-53 2752,-53\"/>\n<text text-anchor=\"start\" x=\"2651\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.604</text>\n<text text-anchor=\"start\" x=\"2645.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 13</text>\n<text text-anchor=\"start\" x=\"2617\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 0, 3, 7, 3, 0]</text>\n</g>\n<!-- 26&#45;&gt;28 -->\n<g id=\"edge28\" class=\"edge\">\n<title>26&#45;&gt;28</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2568.81,-88.95C2588.25,-78.79 2609.55,-67.67 2628.62,-57.72\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2630.25,-60.82 2637.49,-53.09 2627.01,-54.61 2630.25,-60.82\"/>\n</g>\n</g>\n</svg>\n",
            "text/plain": [
              "<graphviz.sources.Source at 0x7d130ffc8f40>"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tree.export_text(dtr_adm_2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7A7AwkRt3L6l",
        "outputId": "74cabcb9-04a7-4627-d221-78186a06ae1e"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|--- feature_7 <= 8.93\n",
            "|   |--- feature_7 <= 8.03\n",
            "|   |   |--- feature_2 <= 305.50\n",
            "|   |   |   |--- feature_7 <= 7.66\n",
            "|   |   |   |   |--- value: [0.46]\n",
            "|   |   |   |--- feature_7 >  7.66\n",
            "|   |   |   |   |--- value: [0.55]\n",
            "|   |   |--- feature_2 >  305.50\n",
            "|   |   |   |--- feature_2 <= 319.50\n",
            "|   |   |   |   |--- value: [0.60]\n",
            "|   |   |   |--- feature_2 >  319.50\n",
            "|   |   |   |   |--- value: [0.74]\n",
            "|   |--- feature_7 >  8.03\n",
            "|   |   |--- feature_7 <= 8.34\n",
            "|   |   |   |--- feature_8 <= 0.50\n",
            "|   |   |   |   |--- value: [0.63]\n",
            "|   |   |   |--- feature_8 >  0.50\n",
            "|   |   |   |   |--- value: [0.69]\n",
            "|   |   |--- feature_7 >  8.34\n",
            "|   |   |   |--- feature_0 <= 126.00\n",
            "|   |   |   |   |--- value: [0.68]\n",
            "|   |   |   |--- feature_0 >  126.00\n",
            "|   |   |   |   |--- value: [0.74]\n",
            "|--- feature_7 >  8.93\n",
            "|   |--- feature_7 <= 9.18\n",
            "|   |   |--- feature_7 <= 9.05\n",
            "|   |   |   |--- feature_2 <= 311.00\n",
            "|   |   |   |   |--- value: [0.66]\n",
            "|   |   |   |--- feature_2 >  311.00\n",
            "|   |   |   |   |--- value: [0.80]\n",
            "|   |   |--- feature_7 >  9.05\n",
            "|   |   |   |--- feature_4 <= 4.50\n",
            "|   |   |   |   |--- value: [0.83]\n",
            "|   |   |   |--- feature_4 >  4.50\n",
            "|   |   |   |   |--- value: [0.89]\n",
            "|   |--- feature_7 >  9.18\n",
            "|   |   |--- feature_7 <= 9.47\n",
            "|   |   |   |--- feature_3 <= 113.50\n",
            "|   |   |   |   |--- value: [0.90]\n",
            "|   |   |   |--- feature_3 >  113.50\n",
            "|   |   |   |   |--- value: [0.92]\n",
            "|   |   |--- feature_7 >  9.47\n",
            "|   |   |   |--- feature_8 <= 0.50\n",
            "|   |   |   |   |--- value: [0.89]\n",
            "|   |   |   |--- feature_8 >  0.50\n",
            "|   |   |   |   |--- value: [0.95]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dot_data = tree.export_graphviz(dtr_adm_2, out_file=None,\n",
        "                                feature_names=pd.Series(X_train_admission.columns).array,\n",
        "                                filled=True, rounded=True,\n",
        "                                special_characters=True)\n",
        "\n",
        "# Membuat visualisasi\n",
        "graph = graphviz.Source(dot_data)\n",
        "\n",
        "# Menyimpan visualisasi ke file PDF\n",
        "graph.render(filename=\"dtr_adm_2_visualization\", format=\"pdf\")\n",
        "graph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "id": "u54zuh0V3NCa",
        "outputId": "35792822-bfcd-4993-c5dd-88c6d14abdb3"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: Tree Pages: 1 -->\n<svg width=\"2621pt\" height=\"477pt\"\n viewBox=\"0.00 0.00 2620.50 477.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 473)\">\n<title>Tree</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-473 2616.5,-473 2616.5,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<path fill=\"#f1bb93\" stroke=\"black\" d=\"M1394,-469C1394,-469 1275,-469 1275,-469 1269,-469 1263,-463 1263,-457 1263,-457 1263,-413 1263,-413 1263,-407 1269,-401 1275,-401 1275,-401 1394,-401 1394,-401 1400,-401 1406,-407 1406,-413 1406,-413 1406,-457 1406,-457 1406,-463 1400,-469 1394,-469\"/>\n<text text-anchor=\"start\" x=\"1295\" y=\"-453.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">CGPA â‰¤ 8.93</text>\n<text text-anchor=\"start\" x=\"1271\" y=\"-438.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.02</text>\n<text text-anchor=\"start\" x=\"1289.5\" y=\"-423.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 280</text>\n<text text-anchor=\"start\" x=\"1293.5\" y=\"-408.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.725</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<path fill=\"#f5ceb2\" stroke=\"black\" d=\"M1068,-365C1068,-365 941,-365 941,-365 935,-365 929,-359 929,-353 929,-353 929,-309 929,-309 929,-303 935,-297 941,-297 941,-297 1068,-297 1068,-297 1074,-297 1080,-303 1080,-309 1080,-309 1080,-353 1080,-353 1080,-359 1074,-365 1068,-365\"/>\n<text text-anchor=\"start\" x=\"961\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">CGPA â‰¤ 8.035</text>\n<text text-anchor=\"start\" x=\"937\" y=\"-334.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.012</text>\n<text text-anchor=\"start\" x=\"959.5\" y=\"-319.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 187</text>\n<text text-anchor=\"start\" x=\"963.5\" y=\"-304.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.651</text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1262.89,-411.87C1212.12,-396.17 1143.76,-375.05 1090.11,-358.46\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1090.86,-355.03 1080.27,-355.42 1088.79,-361.72 1090.86,-355.03\"/>\n<text text-anchor=\"middle\" x=\"1091.94\" y=\"-373.83\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\n</g>\n<!-- 16 -->\n<g id=\"node17\" class=\"node\">\n<title>16</title>\n<path fill=\"#e99457\" stroke=\"black\" d=\"M1730,-365C1730,-365 1603,-365 1603,-365 1597,-365 1591,-359 1591,-353 1591,-353 1591,-309 1591,-309 1591,-303 1597,-297 1603,-297 1603,-297 1730,-297 1730,-297 1736,-297 1742,-303 1742,-309 1742,-309 1742,-353 1742,-353 1742,-359 1736,-365 1730,-365\"/>\n<text text-anchor=\"start\" x=\"1623\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">CGPA â‰¤ 9.185</text>\n<text text-anchor=\"start\" x=\"1599\" y=\"-334.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.004</text>\n<text text-anchor=\"start\" x=\"1625.5\" y=\"-319.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 93</text>\n<text text-anchor=\"start\" x=\"1625.5\" y=\"-304.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.874</text>\n</g>\n<!-- 0&#45;&gt;16 -->\n<g id=\"edge16\" class=\"edge\">\n<title>0&#45;&gt;16</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1406.13,-411.99C1457.56,-396.19 1527.09,-374.83 1581.36,-358.16\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1582.43,-361.49 1590.96,-355.21 1580.37,-354.8 1582.43,-361.49\"/>\n<text text-anchor=\"middle\" x=\"1579.25\" y=\"-373.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\">\n<title>2</title>\n<path fill=\"#fae8db\" stroke=\"black\" d=\"M558,-261C558,-261 439,-261 439,-261 433,-261 427,-255 427,-249 427,-249 427,-205 427,-205 427,-199 433,-193 439,-193 439,-193 558,-193 558,-193 564,-193 570,-199 570,-205 570,-205 570,-249 570,-249 570,-255 564,-261 558,-261\"/>\n<text text-anchor=\"start\" x=\"439.5\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">GRE Score â‰¤ 305.5</text>\n<text text-anchor=\"start\" x=\"435\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.01</text>\n<text text-anchor=\"start\" x=\"457.5\" y=\"-215.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 59</text>\n<text text-anchor=\"start\" x=\"457.5\" y=\"-200.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.551</text>\n</g>\n<!-- 1&#45;&gt;2 -->\n<g id=\"edge2\" class=\"edge\">\n<title>1&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M928.75,-314.73C835.15,-295.86 676.52,-263.89 580.24,-244.48\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"580.76,-241.01 570.26,-242.47 579.37,-247.87 580.76,-241.01\"/>\n</g>\n<!-- 9 -->\n<g id=\"node10\" class=\"node\">\n<title>9</title>\n<path fill=\"#f2c29f\" stroke=\"black\" d=\"M1068,-261C1068,-261 941,-261 941,-261 935,-261 929,-255 929,-249 929,-249 929,-205 929,-205 929,-199 935,-193 941,-193 941,-193 1068,-193 1068,-193 1074,-193 1080,-199 1080,-205 1080,-205 1080,-249 1080,-249 1080,-255 1074,-261 1068,-261\"/>\n<text text-anchor=\"start\" x=\"961\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">CGPA â‰¤ 8.335</text>\n<text text-anchor=\"start\" x=\"937\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.006</text>\n<text text-anchor=\"start\" x=\"959.5\" y=\"-215.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 128</text>\n<text text-anchor=\"start\" x=\"963.5\" y=\"-200.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.698</text>\n</g>\n<!-- 1&#45;&gt;9 -->\n<g id=\"edge9\" class=\"edge\">\n<title>1&#45;&gt;9</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1004.5,-296.88C1004.5,-288.78 1004.5,-279.98 1004.5,-271.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1008,-271.3 1004.5,-261.3 1001,-271.3 1008,-271.3\"/>\n</g>\n<!-- 3 -->\n<g id=\"node4\" class=\"node\">\n<title>3</title>\n<path fill=\"#fdf4ee\" stroke=\"black\" d=\"M308,-157C308,-157 181,-157 181,-157 175,-157 169,-151 169,-145 169,-145 169,-101 169,-101 169,-95 175,-89 181,-89 181,-89 308,-89 308,-89 314,-89 320,-95 320,-101 320,-101 320,-145 320,-145 320,-151 314,-157 308,-157\"/>\n<text text-anchor=\"start\" x=\"201\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">CGPA â‰¤ 7.665</text>\n<text text-anchor=\"start\" x=\"177\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.008</text>\n<text text-anchor=\"start\" x=\"203.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 33</text>\n<text text-anchor=\"start\" x=\"203.5\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.503</text>\n</g>\n<!-- 2&#45;&gt;3 -->\n<g id=\"edge3\" class=\"edge\">\n<title>2&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M426.73,-197.18C396.55,-185.06 361.21,-170.87 329.72,-158.22\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"330.66,-154.83 320.08,-154.35 328.05,-161.32 330.66,-154.83\"/>\n</g>\n<!-- 6 -->\n<g id=\"node7\" class=\"node\">\n<title>6</title>\n<path fill=\"#f7d8c2\" stroke=\"black\" d=\"M562,-157C562,-157 435,-157 435,-157 429,-157 423,-151 423,-145 423,-145 423,-101 423,-101 423,-95 429,-89 435,-89 435,-89 562,-89 562,-89 568,-89 574,-95 574,-101 574,-101 574,-145 574,-145 574,-151 568,-157 562,-157\"/>\n<text text-anchor=\"start\" x=\"439.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">GRE Score â‰¤ 319.5</text>\n<text text-anchor=\"start\" x=\"431\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.006</text>\n<text text-anchor=\"start\" x=\"457.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 26</text>\n<text text-anchor=\"start\" x=\"457.5\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.611</text>\n</g>\n<!-- 2&#45;&gt;6 -->\n<g id=\"edge6\" class=\"edge\">\n<title>2&#45;&gt;6</title>\n<path fill=\"none\" stroke=\"black\" d=\"M498.5,-192.88C498.5,-184.78 498.5,-175.98 498.5,-167.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"502,-167.3 498.5,-157.3 495,-167.3 502,-167.3\"/>\n</g>\n<!-- 4 -->\n<g id=\"node5\" class=\"node\">\n<title>4</title>\n<path fill=\"#ffffff\" stroke=\"black\" d=\"M139,-53C139,-53 12,-53 12,-53 6,-53 0,-47 0,-41 0,-41 0,-12 0,-12 0,-6 6,0 12,0 12,0 139,0 139,0 145,0 151,-6 151,-12 151,-12 151,-41 151,-41 151,-47 145,-53 139,-53\"/>\n<text text-anchor=\"start\" x=\"8\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.005</text>\n<text text-anchor=\"start\" x=\"34.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 18</text>\n<text text-anchor=\"start\" x=\"34.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.462</text>\n</g>\n<!-- 3&#45;&gt;4 -->\n<g id=\"edge4\" class=\"edge\">\n<title>3&#45;&gt;4</title>\n<path fill=\"none\" stroke=\"black\" d=\"M185.39,-88.95C167.48,-78.93 147.89,-67.98 130.27,-58.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"131.69,-54.91 121.26,-53.09 128.28,-61.02 131.69,-54.91\"/>\n</g>\n<!-- 5 -->\n<g id=\"node6\" class=\"node\">\n<title>5</title>\n<path fill=\"#fae8db\" stroke=\"black\" d=\"M308,-53C308,-53 181,-53 181,-53 175,-53 169,-47 169,-41 169,-41 169,-12 169,-12 169,-6 175,0 181,0 181,0 308,0 308,0 314,0 320,-6 320,-12 320,-12 320,-41 320,-41 320,-47 314,-53 308,-53\"/>\n<text text-anchor=\"start\" x=\"177\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.007</text>\n<text text-anchor=\"start\" x=\"203.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 15</text>\n<text text-anchor=\"start\" x=\"203.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.551</text>\n</g>\n<!-- 3&#45;&gt;5 -->\n<g id=\"edge5\" class=\"edge\">\n<title>3&#45;&gt;5</title>\n<path fill=\"none\" stroke=\"black\" d=\"M244.5,-88.95C244.5,-80.72 244.5,-71.85 244.5,-63.48\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"248,-63.24 244.5,-53.24 241,-63.24 248,-63.24\"/>\n</g>\n<!-- 7 -->\n<g id=\"node8\" class=\"node\">\n<title>7</title>\n<path fill=\"#f8dbc6\" stroke=\"black\" d=\"M477,-53C477,-53 350,-53 350,-53 344,-53 338,-47 338,-41 338,-41 338,-12 338,-12 338,-6 344,0 350,0 350,0 477,0 477,0 483,0 489,-6 489,-12 489,-12 489,-41 489,-41 489,-47 483,-53 477,-53\"/>\n<text text-anchor=\"start\" x=\"346\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.005</text>\n<text text-anchor=\"start\" x=\"372.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 24</text>\n<text text-anchor=\"start\" x=\"380\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.6</text>\n</g>\n<!-- 6&#45;&gt;7 -->\n<g id=\"edge7\" class=\"edge\">\n<title>6&#45;&gt;7</title>\n<path fill=\"none\" stroke=\"black\" d=\"M468.77,-88.95C460.54,-79.8 451.61,-69.87 443.37,-60.71\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"445.94,-58.33 436.65,-53.24 440.73,-63.01 445.94,-58.33\"/>\n</g>\n<!-- 8 -->\n<g id=\"node9\" class=\"node\">\n<title>8</title>\n<path fill=\"#f0b78d\" stroke=\"black\" d=\"M646,-53C646,-53 519,-53 519,-53 513,-53 507,-47 507,-41 507,-41 507,-12 507,-12 507,-6 513,0 519,0 519,0 646,0 646,0 652,0 658,-6 658,-12 658,-12 658,-41 658,-41 658,-47 652,-53 646,-53\"/>\n<text text-anchor=\"start\" x=\"515\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.002</text>\n<text text-anchor=\"start\" x=\"545\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"545\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.74</text>\n</g>\n<!-- 6&#45;&gt;8 -->\n<g id=\"edge8\" class=\"edge\">\n<title>6&#45;&gt;8</title>\n<path fill=\"none\" stroke=\"black\" d=\"M527.88,-88.95C536.01,-79.8 544.84,-69.87 552.98,-60.71\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"555.6,-63.04 559.62,-53.24 550.36,-58.39 555.6,-63.04\"/>\n</g>\n<!-- 10 -->\n<g id=\"node11\" class=\"node\">\n<title>10</title>\n<path fill=\"#f5ceb2\" stroke=\"black\" d=\"M984,-157C984,-157 857,-157 857,-157 851,-157 845,-151 845,-145 845,-145 845,-101 845,-101 845,-95 851,-89 857,-89 857,-89 984,-89 984,-89 990,-89 996,-95 996,-101 996,-101 996,-145 996,-145 996,-151 990,-157 984,-157\"/>\n<text text-anchor=\"start\" x=\"874.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Research â‰¤ 0.5</text>\n<text text-anchor=\"start\" x=\"853\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.005</text>\n<text text-anchor=\"start\" x=\"879.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 45</text>\n<text text-anchor=\"start\" x=\"883\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.65</text>\n</g>\n<!-- 9&#45;&gt;10 -->\n<g id=\"edge10\" class=\"edge\">\n<title>9&#45;&gt;10</title>\n<path fill=\"none\" stroke=\"black\" d=\"M977.23,-192.88C969.97,-184.07 962.03,-174.43 954.46,-165.24\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"956.98,-162.79 947.92,-157.3 951.58,-167.24 956.98,-162.79\"/>\n</g>\n<!-- 13 -->\n<g id=\"node14\" class=\"node\">\n<title>13</title>\n<path fill=\"#f1bb94\" stroke=\"black\" d=\"M1153,-157C1153,-157 1026,-157 1026,-157 1020,-157 1014,-151 1014,-145 1014,-145 1014,-101 1014,-101 1014,-95 1020,-89 1026,-89 1026,-89 1153,-89 1153,-89 1159,-89 1165,-95 1165,-101 1165,-101 1165,-145 1165,-145 1165,-151 1159,-157 1153,-157\"/>\n<text text-anchor=\"start\" x=\"1027.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Unnamed: 0 â‰¤ 126.0</text>\n<text text-anchor=\"start\" x=\"1022\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.005</text>\n<text text-anchor=\"start\" x=\"1048.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 83</text>\n<text text-anchor=\"start\" x=\"1048.5\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.723</text>\n</g>\n<!-- 9&#45;&gt;13 -->\n<g id=\"edge13\" class=\"edge\">\n<title>9&#45;&gt;13</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1032.1,-192.88C1039.45,-184.07 1047.47,-174.43 1055.14,-165.24\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1058.04,-167.22 1061.75,-157.3 1052.66,-162.74 1058.04,-167.22\"/>\n</g>\n<!-- 11 -->\n<g id=\"node12\" class=\"node\">\n<title>11</title>\n<path fill=\"#f6d3b9\" stroke=\"black\" d=\"M815,-53C815,-53 688,-53 688,-53 682,-53 676,-47 676,-41 676,-41 676,-12 676,-12 676,-6 682,0 688,0 688,0 815,0 815,0 821,0 827,-6 827,-12 827,-12 827,-41 827,-41 827,-47 821,-53 815,-53\"/>\n<text text-anchor=\"start\" x=\"684\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.004</text>\n<text text-anchor=\"start\" x=\"710.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 31</text>\n<text text-anchor=\"start\" x=\"710.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.632</text>\n</g>\n<!-- 10&#45;&gt;11 -->\n<g id=\"edge11\" class=\"edge\">\n<title>10&#45;&gt;11</title>\n<path fill=\"none\" stroke=\"black\" d=\"M861.39,-88.95C843.48,-78.93 823.89,-67.98 806.27,-58.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"807.69,-54.91 797.26,-53.09 804.28,-61.02 807.69,-54.91\"/>\n</g>\n<!-- 12 -->\n<g id=\"node13\" class=\"node\">\n<title>12</title>\n<path fill=\"#f3c4a2\" stroke=\"black\" d=\"M984,-53C984,-53 857,-53 857,-53 851,-53 845,-47 845,-41 845,-41 845,-12 845,-12 845,-6 851,0 857,0 857,0 984,0 984,0 990,0 996,-6 996,-12 996,-12 996,-41 996,-41 996,-47 990,-53 984,-53\"/>\n<text text-anchor=\"start\" x=\"853\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.005</text>\n<text text-anchor=\"start\" x=\"879.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 14</text>\n<text text-anchor=\"start\" x=\"879.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.689</text>\n</g>\n<!-- 10&#45;&gt;12 -->\n<g id=\"edge12\" class=\"edge\">\n<title>10&#45;&gt;12</title>\n<path fill=\"none\" stroke=\"black\" d=\"M920.5,-88.95C920.5,-80.72 920.5,-71.85 920.5,-63.48\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"924,-63.24 920.5,-53.24 917,-63.24 924,-63.24\"/>\n</g>\n<!-- 14 -->\n<g id=\"node15\" class=\"node\">\n<title>14</title>\n<path fill=\"#f4c7a8\" stroke=\"black\" d=\"M1153,-53C1153,-53 1026,-53 1026,-53 1020,-53 1014,-47 1014,-41 1014,-41 1014,-12 1014,-12 1014,-6 1020,0 1026,0 1026,0 1153,0 1153,0 1159,0 1165,-6 1165,-12 1165,-12 1165,-41 1165,-41 1165,-47 1159,-53 1153,-53\"/>\n<text text-anchor=\"start\" x=\"1022\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.008</text>\n<text text-anchor=\"start\" x=\"1048.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 22</text>\n<text text-anchor=\"start\" x=\"1048.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.675</text>\n</g>\n<!-- 13&#45;&gt;14 -->\n<g id=\"edge14\" class=\"edge\">\n<title>13&#45;&gt;14</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1089.5,-88.95C1089.5,-80.72 1089.5,-71.85 1089.5,-63.48\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1093,-63.24 1089.5,-53.24 1086,-63.24 1093,-63.24\"/>\n</g>\n<!-- 15 -->\n<g id=\"node16\" class=\"node\">\n<title>15</title>\n<path fill=\"#f0b78d\" stroke=\"black\" d=\"M1322,-53C1322,-53 1195,-53 1195,-53 1189,-53 1183,-47 1183,-41 1183,-41 1183,-12 1183,-12 1183,-6 1189,0 1195,0 1195,0 1322,0 1322,0 1328,0 1334,-6 1334,-12 1334,-12 1334,-41 1334,-41 1334,-47 1328,-53 1322,-53\"/>\n<text text-anchor=\"start\" x=\"1191\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.002</text>\n<text text-anchor=\"start\" x=\"1217.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 61</text>\n<text text-anchor=\"start\" x=\"1221\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.74</text>\n</g>\n<!-- 13&#45;&gt;15 -->\n<g id=\"edge15\" class=\"edge\">\n<title>13&#45;&gt;15</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1148.61,-88.95C1166.52,-78.93 1186.11,-67.98 1203.73,-58.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1205.72,-61.02 1212.74,-53.09 1202.31,-54.91 1205.72,-61.02\"/>\n</g>\n<!-- 17 -->\n<g id=\"node18\" class=\"node\">\n<title>17</title>\n<path fill=\"#eba069\" stroke=\"black\" d=\"M1730,-261C1730,-261 1603,-261 1603,-261 1597,-261 1591,-255 1591,-249 1591,-249 1591,-205 1591,-205 1591,-199 1597,-193 1603,-193 1603,-193 1730,-193 1730,-193 1736,-193 1742,-199 1742,-205 1742,-205 1742,-249 1742,-249 1742,-255 1736,-261 1730,-261\"/>\n<text text-anchor=\"start\" x=\"1627\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">CGPA â‰¤ 9.05</text>\n<text text-anchor=\"start\" x=\"1599\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.003</text>\n<text text-anchor=\"start\" x=\"1625.5\" y=\"-215.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 48</text>\n<text text-anchor=\"start\" x=\"1625.5\" y=\"-200.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.828</text>\n</g>\n<!-- 16&#45;&gt;17 -->\n<g id=\"edge17\" class=\"edge\">\n<title>16&#45;&gt;17</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1666.5,-296.88C1666.5,-288.78 1666.5,-279.98 1666.5,-271.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1670,-271.3 1666.5,-261.3 1663,-271.3 1670,-271.3\"/>\n</g>\n<!-- 24 -->\n<g id=\"node25\" class=\"node\">\n<title>24</title>\n<path fill=\"#e68743\" stroke=\"black\" d=\"M2219,-261C2219,-261 2092,-261 2092,-261 2086,-261 2080,-255 2080,-249 2080,-249 2080,-205 2080,-205 2080,-199 2086,-193 2092,-193 2092,-193 2219,-193 2219,-193 2225,-193 2231,-199 2231,-205 2231,-205 2231,-249 2231,-249 2231,-255 2225,-261 2219,-261\"/>\n<text text-anchor=\"start\" x=\"2112\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">CGPA â‰¤ 9.465</text>\n<text text-anchor=\"start\" x=\"2088\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.001</text>\n<text text-anchor=\"start\" x=\"2114.5\" y=\"-215.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 45</text>\n<text text-anchor=\"start\" x=\"2114.5\" y=\"-200.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.922</text>\n</g>\n<!-- 16&#45;&gt;24 -->\n<g id=\"edge24\" class=\"edge\">\n<title>16&#45;&gt;24</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1742.1,-314.23C1830.69,-295.75 1977.14,-265.2 2069.85,-245.87\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2070.69,-249.27 2079.77,-243.8 2069.26,-242.41 2070.69,-249.27\"/>\n</g>\n<!-- 18 -->\n<g id=\"node19\" class=\"node\">\n<title>18</title>\n<path fill=\"#eda877\" stroke=\"black\" d=\"M1645,-157C1645,-157 1518,-157 1518,-157 1512,-157 1506,-151 1506,-145 1506,-145 1506,-101 1506,-101 1506,-95 1512,-89 1518,-89 1518,-89 1645,-89 1645,-89 1651,-89 1657,-95 1657,-101 1657,-101 1657,-145 1657,-145 1657,-151 1651,-157 1645,-157\"/>\n<text text-anchor=\"start\" x=\"1522.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">GRE Score â‰¤ 311.0</text>\n<text text-anchor=\"start\" x=\"1514\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.003</text>\n<text text-anchor=\"start\" x=\"1540.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 21</text>\n<text text-anchor=\"start\" x=\"1540.5\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.795</text>\n</g>\n<!-- 17&#45;&gt;18 -->\n<g id=\"edge18\" class=\"edge\">\n<title>17&#45;&gt;18</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1638.9,-192.88C1631.55,-184.07 1623.53,-174.43 1615.86,-165.24\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1618.34,-162.74 1609.25,-157.3 1612.96,-167.22 1618.34,-162.74\"/>\n</g>\n<!-- 21 -->\n<g id=\"node22\" class=\"node\">\n<title>21</title>\n<path fill=\"#ea995f\" stroke=\"black\" d=\"M1815.5,-157C1815.5,-157 1687.5,-157 1687.5,-157 1681.5,-157 1675.5,-151 1675.5,-145 1675.5,-145 1675.5,-101 1675.5,-101 1675.5,-95 1681.5,-89 1687.5,-89 1687.5,-89 1815.5,-89 1815.5,-89 1821.5,-89 1827.5,-95 1827.5,-101 1827.5,-101 1827.5,-145 1827.5,-145 1827.5,-151 1821.5,-157 1815.5,-157\"/>\n<text text-anchor=\"start\" x=\"1683.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">University Rating â‰¤ 4.5</text>\n<text text-anchor=\"start\" x=\"1684\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.002</text>\n<text text-anchor=\"start\" x=\"1710.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 27</text>\n<text text-anchor=\"start\" x=\"1710.5\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.854</text>\n</g>\n<!-- 17&#45;&gt;21 -->\n<g id=\"edge21\" class=\"edge\">\n<title>17&#45;&gt;21</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1694.1,-192.88C1701.45,-184.07 1709.47,-174.43 1717.14,-165.24\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1720.04,-167.22 1723.75,-157.3 1714.66,-162.74 1720.04,-167.22\"/>\n</g>\n<!-- 19 -->\n<g id=\"node20\" class=\"node\">\n<title>19</title>\n<path fill=\"#f4ccae\" stroke=\"black\" d=\"M1476.5,-53C1476.5,-53 1364.5,-53 1364.5,-53 1358.5,-53 1352.5,-47 1352.5,-41 1352.5,-41 1352.5,-12 1352.5,-12 1352.5,-6 1358.5,0 1364.5,0 1364.5,0 1476.5,0 1476.5,0 1482.5,0 1488.5,-6 1488.5,-12 1488.5,-12 1488.5,-41 1488.5,-41 1488.5,-47 1482.5,-53 1476.5,-53\"/>\n<text text-anchor=\"start\" x=\"1360.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.0</text>\n<text text-anchor=\"start\" x=\"1383\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"1383\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.66</text>\n</g>\n<!-- 18&#45;&gt;19 -->\n<g id=\"edge19\" class=\"edge\">\n<title>18&#45;&gt;19</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1525.19,-88.95C1508.28,-79.02 1489.8,-68.18 1473.14,-58.4\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1474.49,-55.13 1464.09,-53.09 1470.94,-61.17 1474.49,-55.13\"/>\n</g>\n<!-- 20 -->\n<g id=\"node21\" class=\"node\">\n<title>20</title>\n<path fill=\"#eda774\" stroke=\"black\" d=\"M1646,-53C1646,-53 1519,-53 1519,-53 1513,-53 1507,-47 1507,-41 1507,-41 1507,-12 1507,-12 1507,-6 1513,0 1519,0 1519,0 1646,0 1646,0 1652,0 1658,-6 1658,-12 1658,-12 1658,-41 1658,-41 1658,-47 1652,-53 1646,-53\"/>\n<text text-anchor=\"start\" x=\"1515\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.002</text>\n<text text-anchor=\"start\" x=\"1541.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 20</text>\n<text text-anchor=\"start\" x=\"1541.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.802</text>\n</g>\n<!-- 18&#45;&gt;20 -->\n<g id=\"edge20\" class=\"edge\">\n<title>18&#45;&gt;20</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1581.85,-88.95C1581.94,-80.72 1582.03,-71.85 1582.12,-63.48\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1585.62,-63.27 1582.23,-53.24 1578.62,-63.2 1585.62,-63.27\"/>\n</g>\n<!-- 22 -->\n<g id=\"node23\" class=\"node\">\n<title>22</title>\n<path fill=\"#eb9e67\" stroke=\"black\" d=\"M1815,-53C1815,-53 1688,-53 1688,-53 1682,-53 1676,-47 1676,-41 1676,-41 1676,-12 1676,-12 1676,-6 1682,0 1688,0 1688,0 1815,0 1815,0 1821,0 1827,-6 1827,-12 1827,-12 1827,-41 1827,-41 1827,-47 1821,-53 1815,-53\"/>\n<text text-anchor=\"start\" x=\"1684\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.001</text>\n<text text-anchor=\"start\" x=\"1710.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 17</text>\n<text text-anchor=\"start\" x=\"1710.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.834</text>\n</g>\n<!-- 21&#45;&gt;22 -->\n<g id=\"edge22\" class=\"edge\">\n<title>21&#45;&gt;22</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1751.5,-88.95C1751.5,-80.72 1751.5,-71.85 1751.5,-63.48\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1755,-63.24 1751.5,-53.24 1748,-63.24 1755,-63.24\"/>\n</g>\n<!-- 23 -->\n<g id=\"node24\" class=\"node\">\n<title>23</title>\n<path fill=\"#e89050\" stroke=\"black\" d=\"M1984,-53C1984,-53 1857,-53 1857,-53 1851,-53 1845,-47 1845,-41 1845,-41 1845,-12 1845,-12 1845,-6 1851,0 1857,0 1857,0 1984,0 1984,0 1990,0 1996,-6 1996,-12 1996,-12 1996,-41 1996,-41 1996,-47 1990,-53 1984,-53\"/>\n<text text-anchor=\"start\" x=\"1853\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.001</text>\n<text text-anchor=\"start\" x=\"1879.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 10</text>\n<text text-anchor=\"start\" x=\"1883\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.89</text>\n</g>\n<!-- 21&#45;&gt;23 -->\n<g id=\"edge23\" class=\"edge\">\n<title>21&#45;&gt;23</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1810.61,-88.95C1828.52,-78.93 1848.11,-67.98 1865.73,-58.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1867.72,-61.02 1874.74,-53.09 1864.31,-54.91 1867.72,-61.02\"/>\n</g>\n<!-- 25 -->\n<g id=\"node26\" class=\"node\">\n<title>25</title>\n<path fill=\"#e78a48\" stroke=\"black\" d=\"M2218,-157C2218,-157 2093,-157 2093,-157 2087,-157 2081,-151 2081,-145 2081,-145 2081,-101 2081,-101 2081,-95 2087,-89 2093,-89 2093,-89 2218,-89 2218,-89 2224,-89 2230,-95 2230,-101 2230,-101 2230,-145 2230,-145 2230,-151 2224,-157 2218,-157\"/>\n<text text-anchor=\"start\" x=\"2089\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">TOEFL Score â‰¤ 113.5</text>\n<text text-anchor=\"start\" x=\"2095.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.0</text>\n<text text-anchor=\"start\" x=\"2114.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 28</text>\n<text text-anchor=\"start\" x=\"2118\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.91</text>\n</g>\n<!-- 24&#45;&gt;25 -->\n<g id=\"edge25\" class=\"edge\">\n<title>24&#45;&gt;25</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2155.5,-192.88C2155.5,-184.78 2155.5,-175.98 2155.5,-167.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2159,-167.3 2155.5,-157.3 2152,-167.3 2159,-167.3\"/>\n</g>\n<!-- 28 -->\n<g id=\"node29\" class=\"node\">\n<title>28</title>\n<path fill=\"#e5823a\" stroke=\"black\" d=\"M2446.5,-157C2446.5,-157 2334.5,-157 2334.5,-157 2328.5,-157 2322.5,-151 2322.5,-145 2322.5,-145 2322.5,-101 2322.5,-101 2322.5,-95 2328.5,-89 2334.5,-89 2334.5,-89 2446.5,-89 2446.5,-89 2452.5,-89 2458.5,-95 2458.5,-101 2458.5,-101 2458.5,-145 2458.5,-145 2458.5,-151 2452.5,-157 2446.5,-157\"/>\n<text text-anchor=\"start\" x=\"2344.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Research â‰¤ 0.5</text>\n<text text-anchor=\"start\" x=\"2330.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.0</text>\n<text text-anchor=\"start\" x=\"2349.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 17</text>\n<text text-anchor=\"start\" x=\"2349.5\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.943</text>\n</g>\n<!-- 24&#45;&gt;28 -->\n<g id=\"edge28\" class=\"edge\">\n<title>24&#45;&gt;28</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2231.15,-193.17C2257.2,-181.86 2286.41,-169.18 2312.63,-157.8\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2314.37,-160.86 2322.15,-153.67 2311.58,-154.44 2314.37,-160.86\"/>\n</g>\n<!-- 26 -->\n<g id=\"node27\" class=\"node\">\n<title>26</title>\n<path fill=\"#e88e4e\" stroke=\"black\" d=\"M2138.5,-53C2138.5,-53 2026.5,-53 2026.5,-53 2020.5,-53 2014.5,-47 2014.5,-41 2014.5,-41 2014.5,-12 2014.5,-12 2014.5,-6 2020.5,0 2026.5,0 2026.5,0 2138.5,0 2138.5,0 2144.5,0 2150.5,-6 2150.5,-12 2150.5,-12 2150.5,-41 2150.5,-41 2150.5,-47 2144.5,-53 2138.5,-53\"/>\n<text text-anchor=\"start\" x=\"2022.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.0</text>\n<text text-anchor=\"start\" x=\"2045\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 9</text>\n<text text-anchor=\"start\" x=\"2041.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.896</text>\n</g>\n<!-- 25&#45;&gt;26 -->\n<g id=\"edge26\" class=\"edge\">\n<title>25&#45;&gt;26</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2129.97,-88.95C2123.04,-79.98 2115.54,-70.27 2108.58,-61.26\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2111.26,-59.01 2102.38,-53.24 2105.72,-63.29 2111.26,-59.01\"/>\n</g>\n<!-- 27 -->\n<g id=\"node28\" class=\"node\">\n<title>27</title>\n<path fill=\"#e78945\" stroke=\"black\" d=\"M2292.5,-53C2292.5,-53 2180.5,-53 2180.5,-53 2174.5,-53 2168.5,-47 2168.5,-41 2168.5,-41 2168.5,-12 2168.5,-12 2168.5,-6 2174.5,0 2180.5,0 2180.5,0 2292.5,0 2292.5,0 2298.5,0 2304.5,-6 2304.5,-12 2304.5,-12 2304.5,-41 2304.5,-41 2304.5,-47 2298.5,-53 2292.5,-53\"/>\n<text text-anchor=\"start\" x=\"2176.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.0</text>\n<text text-anchor=\"start\" x=\"2195.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 19</text>\n<text text-anchor=\"start\" x=\"2195.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.917</text>\n</g>\n<!-- 25&#45;&gt;27 -->\n<g id=\"edge27\" class=\"edge\">\n<title>25&#45;&gt;27</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2183.83,-88.95C2191.59,-79.89 2200.01,-70.07 2207.8,-60.99\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2210.59,-63.11 2214.44,-53.24 2205.27,-58.55 2210.59,-63.11\"/>\n</g>\n<!-- 29 -->\n<g id=\"node30\" class=\"node\">\n<title>29</title>\n<path fill=\"#e89050\" stroke=\"black\" d=\"M2446.5,-53C2446.5,-53 2334.5,-53 2334.5,-53 2328.5,-53 2322.5,-47 2322.5,-41 2322.5,-41 2322.5,-12 2322.5,-12 2322.5,-6 2328.5,0 2334.5,0 2334.5,0 2446.5,0 2446.5,0 2452.5,0 2458.5,-6 2458.5,-12 2458.5,-12 2458.5,-41 2458.5,-41 2458.5,-47 2452.5,-53 2446.5,-53\"/>\n<text text-anchor=\"start\" x=\"2330.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.0</text>\n<text text-anchor=\"start\" x=\"2353\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"2353\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.89</text>\n</g>\n<!-- 28&#45;&gt;29 -->\n<g id=\"edge29\" class=\"edge\">\n<title>28&#45;&gt;29</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2390.5,-88.95C2390.5,-80.72 2390.5,-71.85 2390.5,-63.48\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2394,-63.24 2390.5,-53.24 2387,-63.24 2394,-63.24\"/>\n</g>\n<!-- 30 -->\n<g id=\"node31\" class=\"node\">\n<title>30</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M2600.5,-53C2600.5,-53 2488.5,-53 2488.5,-53 2482.5,-53 2476.5,-47 2476.5,-41 2476.5,-41 2476.5,-12 2476.5,-12 2476.5,-6 2482.5,0 2488.5,0 2488.5,0 2600.5,0 2600.5,0 2606.5,0 2612.5,-6 2612.5,-12 2612.5,-12 2612.5,-41 2612.5,-41 2612.5,-47 2606.5,-53 2600.5,-53\"/>\n<text text-anchor=\"start\" x=\"2484.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.0</text>\n<text text-anchor=\"start\" x=\"2503.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 16</text>\n<text text-anchor=\"start\" x=\"2503.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.946</text>\n</g>\n<!-- 28&#45;&gt;30 -->\n<g id=\"edge30\" class=\"edge\">\n<title>28&#45;&gt;30</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2444.36,-88.95C2460.46,-79.07 2478.05,-68.28 2493.93,-58.53\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2495.87,-61.45 2502.56,-53.24 2492.2,-55.48 2495.87,-61.45\"/>\n</g>\n</g>\n</svg>\n",
            "text/plain": [
              "<graphviz.sources.Source at 0x7d1310162a40>"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SOAL 2c\n",
        "\n",
        "[2.5]  Jika model decision tree regressor diberikan data aktual Chance of Admit 0.96, tentukan attribut-attribut yang menghasilkan hasil prediksi terdekat dengan data aktual tersebut. Berikan juga Mean Absolute Error dari hasil prediksi dengan data aktual `Chance of Admit` dari data X?    \n",
        "\n",
        "**Catatan:** Tidak perlu dilakukan implementasi kode pada bagian ini"
      ],
      "metadata": {
        "id": "litt2_EwSOIU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import _tree, export_graphviz\n",
        "\n",
        "dot_data = export_graphviz(dtr_adm_2, out_file=None,\n",
        "                           feature_names=pd.Series(X_train_admission.columns).array,\n",
        "                           filled=True, rounded=True,\n",
        "                           special_characters=True)\n",
        "\n",
        "graph = graphviz.Source(dot_data)\n",
        "graph.render(filename=\"regression_tree_visualization\", format=\"pdf\")\n",
        "\n",
        "def extract_paths(tree, feature_names):\n",
        "    tree_ = tree.tree_\n",
        "    paths = []\n",
        "\n",
        "    def recurse(node, path, paths):\n",
        "        if tree_.feature[node] != _tree.TREE_UNDEFINED:\n",
        "            name = feature_names[tree_.feature[node]]\n",
        "            threshold = tree_.threshold[node]\n",
        "            recurse(tree_.children_left[node], path + [(name, '<=', threshold)], paths)\n",
        "            recurse(tree_.children_right[node], path + [(name, '>', threshold)], paths)\n",
        "        else:\n",
        "            paths.append((path, tree_.value[node]))\n",
        "\n",
        "    recurse(0, [], paths)\n",
        "    return paths\n",
        "\n",
        "paths = extract_paths(dtr_adm_2, pd.Series(X_train_admission.columns).array)\n",
        "\n",
        "nearest_prediction_path = min(paths, key=lambda x: abs(x[1] - 0.96))\n",
        "\n",
        "print(\"Jalur dengan prediksi paling mendekati 0.96:\")\n",
        "for feature, comparison, value in nearest_prediction_path[0]:\n",
        "    print(f\"{feature} {comparison} {value}\")\n",
        "print(\"-\" * 40)\n",
        "print(f\"Prediksi pada jalur ini: {nearest_prediction_path[1][0][0]}\")\n",
        "print(\"-\" * 40)\n",
        "y_pred = dtr_adm_2.predict(X_train_admission)\n",
        "\n",
        "# Menghitung MAE\n",
        "mae = mean_absolute_error(Y_train_admission, y_pred)\n",
        "\n",
        "print(f\"Mean Absolute Error: {mae:.4f}\")\n",
        "graph\n"
      ],
      "metadata": {
        "id": "ge-ugJdhNL_J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 838
        },
        "outputId": "c31dadc8-3117-4266-cecc-1763e9e402ec"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jalur dengan prediksi paling mendekati 0.96:\n",
            "CGPA > 8.929999828338623\n",
            "CGPA > 9.184999942779541\n",
            "CGPA > 9.46500015258789\n",
            "Research > 0.5\n",
            "----------------------------------------\n",
            "Prediksi pada jalur ini: 0.9462499999999997\n",
            "----------------------------------------\n",
            "Mean Absolute Error: 0.0413\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: Tree Pages: 1 -->\n<svg width=\"2621pt\" height=\"477pt\"\n viewBox=\"0.00 0.00 2620.50 477.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 473)\">\n<title>Tree</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-473 2616.5,-473 2616.5,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<path fill=\"#f1bb93\" stroke=\"black\" d=\"M1394,-469C1394,-469 1275,-469 1275,-469 1269,-469 1263,-463 1263,-457 1263,-457 1263,-413 1263,-413 1263,-407 1269,-401 1275,-401 1275,-401 1394,-401 1394,-401 1400,-401 1406,-407 1406,-413 1406,-413 1406,-457 1406,-457 1406,-463 1400,-469 1394,-469\"/>\n<text text-anchor=\"start\" x=\"1295\" y=\"-453.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">CGPA â‰¤ 8.93</text>\n<text text-anchor=\"start\" x=\"1271\" y=\"-438.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.02</text>\n<text text-anchor=\"start\" x=\"1289.5\" y=\"-423.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 280</text>\n<text text-anchor=\"start\" x=\"1293.5\" y=\"-408.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.725</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<path fill=\"#f5ceb2\" stroke=\"black\" d=\"M1068,-365C1068,-365 941,-365 941,-365 935,-365 929,-359 929,-353 929,-353 929,-309 929,-309 929,-303 935,-297 941,-297 941,-297 1068,-297 1068,-297 1074,-297 1080,-303 1080,-309 1080,-309 1080,-353 1080,-353 1080,-359 1074,-365 1068,-365\"/>\n<text text-anchor=\"start\" x=\"961\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">CGPA â‰¤ 8.035</text>\n<text text-anchor=\"start\" x=\"937\" y=\"-334.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.012</text>\n<text text-anchor=\"start\" x=\"959.5\" y=\"-319.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 187</text>\n<text text-anchor=\"start\" x=\"963.5\" y=\"-304.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.651</text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1262.89,-411.87C1212.12,-396.17 1143.76,-375.05 1090.11,-358.46\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1090.86,-355.03 1080.27,-355.42 1088.79,-361.72 1090.86,-355.03\"/>\n<text text-anchor=\"middle\" x=\"1091.94\" y=\"-373.83\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\n</g>\n<!-- 16 -->\n<g id=\"node17\" class=\"node\">\n<title>16</title>\n<path fill=\"#e99457\" stroke=\"black\" d=\"M1730,-365C1730,-365 1603,-365 1603,-365 1597,-365 1591,-359 1591,-353 1591,-353 1591,-309 1591,-309 1591,-303 1597,-297 1603,-297 1603,-297 1730,-297 1730,-297 1736,-297 1742,-303 1742,-309 1742,-309 1742,-353 1742,-353 1742,-359 1736,-365 1730,-365\"/>\n<text text-anchor=\"start\" x=\"1623\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">CGPA â‰¤ 9.185</text>\n<text text-anchor=\"start\" x=\"1599\" y=\"-334.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.004</text>\n<text text-anchor=\"start\" x=\"1625.5\" y=\"-319.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 93</text>\n<text text-anchor=\"start\" x=\"1625.5\" y=\"-304.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.874</text>\n</g>\n<!-- 0&#45;&gt;16 -->\n<g id=\"edge16\" class=\"edge\">\n<title>0&#45;&gt;16</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1406.13,-411.99C1457.56,-396.19 1527.09,-374.83 1581.36,-358.16\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1582.43,-361.49 1590.96,-355.21 1580.37,-354.8 1582.43,-361.49\"/>\n<text text-anchor=\"middle\" x=\"1579.25\" y=\"-373.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\">\n<title>2</title>\n<path fill=\"#fae8db\" stroke=\"black\" d=\"M558,-261C558,-261 439,-261 439,-261 433,-261 427,-255 427,-249 427,-249 427,-205 427,-205 427,-199 433,-193 439,-193 439,-193 558,-193 558,-193 564,-193 570,-199 570,-205 570,-205 570,-249 570,-249 570,-255 564,-261 558,-261\"/>\n<text text-anchor=\"start\" x=\"439.5\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">GRE Score â‰¤ 305.5</text>\n<text text-anchor=\"start\" x=\"435\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.01</text>\n<text text-anchor=\"start\" x=\"457.5\" y=\"-215.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 59</text>\n<text text-anchor=\"start\" x=\"457.5\" y=\"-200.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.551</text>\n</g>\n<!-- 1&#45;&gt;2 -->\n<g id=\"edge2\" class=\"edge\">\n<title>1&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M928.75,-314.73C835.15,-295.86 676.52,-263.89 580.24,-244.48\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"580.76,-241.01 570.26,-242.47 579.37,-247.87 580.76,-241.01\"/>\n</g>\n<!-- 9 -->\n<g id=\"node10\" class=\"node\">\n<title>9</title>\n<path fill=\"#f2c29f\" stroke=\"black\" d=\"M1068,-261C1068,-261 941,-261 941,-261 935,-261 929,-255 929,-249 929,-249 929,-205 929,-205 929,-199 935,-193 941,-193 941,-193 1068,-193 1068,-193 1074,-193 1080,-199 1080,-205 1080,-205 1080,-249 1080,-249 1080,-255 1074,-261 1068,-261\"/>\n<text text-anchor=\"start\" x=\"961\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">CGPA â‰¤ 8.335</text>\n<text text-anchor=\"start\" x=\"937\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.006</text>\n<text text-anchor=\"start\" x=\"959.5\" y=\"-215.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 128</text>\n<text text-anchor=\"start\" x=\"963.5\" y=\"-200.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.698</text>\n</g>\n<!-- 1&#45;&gt;9 -->\n<g id=\"edge9\" class=\"edge\">\n<title>1&#45;&gt;9</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1004.5,-296.88C1004.5,-288.78 1004.5,-279.98 1004.5,-271.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1008,-271.3 1004.5,-261.3 1001,-271.3 1008,-271.3\"/>\n</g>\n<!-- 3 -->\n<g id=\"node4\" class=\"node\">\n<title>3</title>\n<path fill=\"#fdf4ee\" stroke=\"black\" d=\"M308,-157C308,-157 181,-157 181,-157 175,-157 169,-151 169,-145 169,-145 169,-101 169,-101 169,-95 175,-89 181,-89 181,-89 308,-89 308,-89 314,-89 320,-95 320,-101 320,-101 320,-145 320,-145 320,-151 314,-157 308,-157\"/>\n<text text-anchor=\"start\" x=\"201\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">CGPA â‰¤ 7.665</text>\n<text text-anchor=\"start\" x=\"177\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.008</text>\n<text text-anchor=\"start\" x=\"203.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 33</text>\n<text text-anchor=\"start\" x=\"203.5\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.503</text>\n</g>\n<!-- 2&#45;&gt;3 -->\n<g id=\"edge3\" class=\"edge\">\n<title>2&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M426.73,-197.18C396.55,-185.06 361.21,-170.87 329.72,-158.22\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"330.66,-154.83 320.08,-154.35 328.05,-161.32 330.66,-154.83\"/>\n</g>\n<!-- 6 -->\n<g id=\"node7\" class=\"node\">\n<title>6</title>\n<path fill=\"#f7d8c2\" stroke=\"black\" d=\"M562,-157C562,-157 435,-157 435,-157 429,-157 423,-151 423,-145 423,-145 423,-101 423,-101 423,-95 429,-89 435,-89 435,-89 562,-89 562,-89 568,-89 574,-95 574,-101 574,-101 574,-145 574,-145 574,-151 568,-157 562,-157\"/>\n<text text-anchor=\"start\" x=\"439.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">GRE Score â‰¤ 319.5</text>\n<text text-anchor=\"start\" x=\"431\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.006</text>\n<text text-anchor=\"start\" x=\"457.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 26</text>\n<text text-anchor=\"start\" x=\"457.5\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.611</text>\n</g>\n<!-- 2&#45;&gt;6 -->\n<g id=\"edge6\" class=\"edge\">\n<title>2&#45;&gt;6</title>\n<path fill=\"none\" stroke=\"black\" d=\"M498.5,-192.88C498.5,-184.78 498.5,-175.98 498.5,-167.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"502,-167.3 498.5,-157.3 495,-167.3 502,-167.3\"/>\n</g>\n<!-- 4 -->\n<g id=\"node5\" class=\"node\">\n<title>4</title>\n<path fill=\"#ffffff\" stroke=\"black\" d=\"M139,-53C139,-53 12,-53 12,-53 6,-53 0,-47 0,-41 0,-41 0,-12 0,-12 0,-6 6,0 12,0 12,0 139,0 139,0 145,0 151,-6 151,-12 151,-12 151,-41 151,-41 151,-47 145,-53 139,-53\"/>\n<text text-anchor=\"start\" x=\"8\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.005</text>\n<text text-anchor=\"start\" x=\"34.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 18</text>\n<text text-anchor=\"start\" x=\"34.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.462</text>\n</g>\n<!-- 3&#45;&gt;4 -->\n<g id=\"edge4\" class=\"edge\">\n<title>3&#45;&gt;4</title>\n<path fill=\"none\" stroke=\"black\" d=\"M185.39,-88.95C167.48,-78.93 147.89,-67.98 130.27,-58.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"131.69,-54.91 121.26,-53.09 128.28,-61.02 131.69,-54.91\"/>\n</g>\n<!-- 5 -->\n<g id=\"node6\" class=\"node\">\n<title>5</title>\n<path fill=\"#fae8db\" stroke=\"black\" d=\"M308,-53C308,-53 181,-53 181,-53 175,-53 169,-47 169,-41 169,-41 169,-12 169,-12 169,-6 175,0 181,0 181,0 308,0 308,0 314,0 320,-6 320,-12 320,-12 320,-41 320,-41 320,-47 314,-53 308,-53\"/>\n<text text-anchor=\"start\" x=\"177\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.007</text>\n<text text-anchor=\"start\" x=\"203.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 15</text>\n<text text-anchor=\"start\" x=\"203.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.551</text>\n</g>\n<!-- 3&#45;&gt;5 -->\n<g id=\"edge5\" class=\"edge\">\n<title>3&#45;&gt;5</title>\n<path fill=\"none\" stroke=\"black\" d=\"M244.5,-88.95C244.5,-80.72 244.5,-71.85 244.5,-63.48\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"248,-63.24 244.5,-53.24 241,-63.24 248,-63.24\"/>\n</g>\n<!-- 7 -->\n<g id=\"node8\" class=\"node\">\n<title>7</title>\n<path fill=\"#f8dbc6\" stroke=\"black\" d=\"M477,-53C477,-53 350,-53 350,-53 344,-53 338,-47 338,-41 338,-41 338,-12 338,-12 338,-6 344,0 350,0 350,0 477,0 477,0 483,0 489,-6 489,-12 489,-12 489,-41 489,-41 489,-47 483,-53 477,-53\"/>\n<text text-anchor=\"start\" x=\"346\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.005</text>\n<text text-anchor=\"start\" x=\"372.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 24</text>\n<text text-anchor=\"start\" x=\"380\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.6</text>\n</g>\n<!-- 6&#45;&gt;7 -->\n<g id=\"edge7\" class=\"edge\">\n<title>6&#45;&gt;7</title>\n<path fill=\"none\" stroke=\"black\" d=\"M468.77,-88.95C460.54,-79.8 451.61,-69.87 443.37,-60.71\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"445.94,-58.33 436.65,-53.24 440.73,-63.01 445.94,-58.33\"/>\n</g>\n<!-- 8 -->\n<g id=\"node9\" class=\"node\">\n<title>8</title>\n<path fill=\"#f0b78d\" stroke=\"black\" d=\"M646,-53C646,-53 519,-53 519,-53 513,-53 507,-47 507,-41 507,-41 507,-12 507,-12 507,-6 513,0 519,0 519,0 646,0 646,0 652,0 658,-6 658,-12 658,-12 658,-41 658,-41 658,-47 652,-53 646,-53\"/>\n<text text-anchor=\"start\" x=\"515\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.002</text>\n<text text-anchor=\"start\" x=\"545\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"545\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.74</text>\n</g>\n<!-- 6&#45;&gt;8 -->\n<g id=\"edge8\" class=\"edge\">\n<title>6&#45;&gt;8</title>\n<path fill=\"none\" stroke=\"black\" d=\"M527.88,-88.95C536.01,-79.8 544.84,-69.87 552.98,-60.71\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"555.6,-63.04 559.62,-53.24 550.36,-58.39 555.6,-63.04\"/>\n</g>\n<!-- 10 -->\n<g id=\"node11\" class=\"node\">\n<title>10</title>\n<path fill=\"#f5ceb2\" stroke=\"black\" d=\"M984,-157C984,-157 857,-157 857,-157 851,-157 845,-151 845,-145 845,-145 845,-101 845,-101 845,-95 851,-89 857,-89 857,-89 984,-89 984,-89 990,-89 996,-95 996,-101 996,-101 996,-145 996,-145 996,-151 990,-157 984,-157\"/>\n<text text-anchor=\"start\" x=\"874.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Research â‰¤ 0.5</text>\n<text text-anchor=\"start\" x=\"853\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.005</text>\n<text text-anchor=\"start\" x=\"879.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 45</text>\n<text text-anchor=\"start\" x=\"883\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.65</text>\n</g>\n<!-- 9&#45;&gt;10 -->\n<g id=\"edge10\" class=\"edge\">\n<title>9&#45;&gt;10</title>\n<path fill=\"none\" stroke=\"black\" d=\"M977.23,-192.88C969.97,-184.07 962.03,-174.43 954.46,-165.24\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"956.98,-162.79 947.92,-157.3 951.58,-167.24 956.98,-162.79\"/>\n</g>\n<!-- 13 -->\n<g id=\"node14\" class=\"node\">\n<title>13</title>\n<path fill=\"#f1bb94\" stroke=\"black\" d=\"M1153,-157C1153,-157 1026,-157 1026,-157 1020,-157 1014,-151 1014,-145 1014,-145 1014,-101 1014,-101 1014,-95 1020,-89 1026,-89 1026,-89 1153,-89 1153,-89 1159,-89 1165,-95 1165,-101 1165,-101 1165,-145 1165,-145 1165,-151 1159,-157 1153,-157\"/>\n<text text-anchor=\"start\" x=\"1027.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Unnamed: 0 â‰¤ 126.0</text>\n<text text-anchor=\"start\" x=\"1022\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.005</text>\n<text text-anchor=\"start\" x=\"1048.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 83</text>\n<text text-anchor=\"start\" x=\"1048.5\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.723</text>\n</g>\n<!-- 9&#45;&gt;13 -->\n<g id=\"edge13\" class=\"edge\">\n<title>9&#45;&gt;13</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1032.1,-192.88C1039.45,-184.07 1047.47,-174.43 1055.14,-165.24\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1058.04,-167.22 1061.75,-157.3 1052.66,-162.74 1058.04,-167.22\"/>\n</g>\n<!-- 11 -->\n<g id=\"node12\" class=\"node\">\n<title>11</title>\n<path fill=\"#f6d3b9\" stroke=\"black\" d=\"M815,-53C815,-53 688,-53 688,-53 682,-53 676,-47 676,-41 676,-41 676,-12 676,-12 676,-6 682,0 688,0 688,0 815,0 815,0 821,0 827,-6 827,-12 827,-12 827,-41 827,-41 827,-47 821,-53 815,-53\"/>\n<text text-anchor=\"start\" x=\"684\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.004</text>\n<text text-anchor=\"start\" x=\"710.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 31</text>\n<text text-anchor=\"start\" x=\"710.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.632</text>\n</g>\n<!-- 10&#45;&gt;11 -->\n<g id=\"edge11\" class=\"edge\">\n<title>10&#45;&gt;11</title>\n<path fill=\"none\" stroke=\"black\" d=\"M861.39,-88.95C843.48,-78.93 823.89,-67.98 806.27,-58.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"807.69,-54.91 797.26,-53.09 804.28,-61.02 807.69,-54.91\"/>\n</g>\n<!-- 12 -->\n<g id=\"node13\" class=\"node\">\n<title>12</title>\n<path fill=\"#f3c4a2\" stroke=\"black\" d=\"M984,-53C984,-53 857,-53 857,-53 851,-53 845,-47 845,-41 845,-41 845,-12 845,-12 845,-6 851,0 857,0 857,0 984,0 984,0 990,0 996,-6 996,-12 996,-12 996,-41 996,-41 996,-47 990,-53 984,-53\"/>\n<text text-anchor=\"start\" x=\"853\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.005</text>\n<text text-anchor=\"start\" x=\"879.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 14</text>\n<text text-anchor=\"start\" x=\"879.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.689</text>\n</g>\n<!-- 10&#45;&gt;12 -->\n<g id=\"edge12\" class=\"edge\">\n<title>10&#45;&gt;12</title>\n<path fill=\"none\" stroke=\"black\" d=\"M920.5,-88.95C920.5,-80.72 920.5,-71.85 920.5,-63.48\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"924,-63.24 920.5,-53.24 917,-63.24 924,-63.24\"/>\n</g>\n<!-- 14 -->\n<g id=\"node15\" class=\"node\">\n<title>14</title>\n<path fill=\"#f4c7a8\" stroke=\"black\" d=\"M1153,-53C1153,-53 1026,-53 1026,-53 1020,-53 1014,-47 1014,-41 1014,-41 1014,-12 1014,-12 1014,-6 1020,0 1026,0 1026,0 1153,0 1153,0 1159,0 1165,-6 1165,-12 1165,-12 1165,-41 1165,-41 1165,-47 1159,-53 1153,-53\"/>\n<text text-anchor=\"start\" x=\"1022\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.008</text>\n<text text-anchor=\"start\" x=\"1048.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 22</text>\n<text text-anchor=\"start\" x=\"1048.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.675</text>\n</g>\n<!-- 13&#45;&gt;14 -->\n<g id=\"edge14\" class=\"edge\">\n<title>13&#45;&gt;14</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1089.5,-88.95C1089.5,-80.72 1089.5,-71.85 1089.5,-63.48\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1093,-63.24 1089.5,-53.24 1086,-63.24 1093,-63.24\"/>\n</g>\n<!-- 15 -->\n<g id=\"node16\" class=\"node\">\n<title>15</title>\n<path fill=\"#f0b78d\" stroke=\"black\" d=\"M1322,-53C1322,-53 1195,-53 1195,-53 1189,-53 1183,-47 1183,-41 1183,-41 1183,-12 1183,-12 1183,-6 1189,0 1195,0 1195,0 1322,0 1322,0 1328,0 1334,-6 1334,-12 1334,-12 1334,-41 1334,-41 1334,-47 1328,-53 1322,-53\"/>\n<text text-anchor=\"start\" x=\"1191\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.002</text>\n<text text-anchor=\"start\" x=\"1217.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 61</text>\n<text text-anchor=\"start\" x=\"1221\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.74</text>\n</g>\n<!-- 13&#45;&gt;15 -->\n<g id=\"edge15\" class=\"edge\">\n<title>13&#45;&gt;15</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1148.61,-88.95C1166.52,-78.93 1186.11,-67.98 1203.73,-58.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1205.72,-61.02 1212.74,-53.09 1202.31,-54.91 1205.72,-61.02\"/>\n</g>\n<!-- 17 -->\n<g id=\"node18\" class=\"node\">\n<title>17</title>\n<path fill=\"#eba069\" stroke=\"black\" d=\"M1730,-261C1730,-261 1603,-261 1603,-261 1597,-261 1591,-255 1591,-249 1591,-249 1591,-205 1591,-205 1591,-199 1597,-193 1603,-193 1603,-193 1730,-193 1730,-193 1736,-193 1742,-199 1742,-205 1742,-205 1742,-249 1742,-249 1742,-255 1736,-261 1730,-261\"/>\n<text text-anchor=\"start\" x=\"1627\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">CGPA â‰¤ 9.05</text>\n<text text-anchor=\"start\" x=\"1599\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.003</text>\n<text text-anchor=\"start\" x=\"1625.5\" y=\"-215.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 48</text>\n<text text-anchor=\"start\" x=\"1625.5\" y=\"-200.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.828</text>\n</g>\n<!-- 16&#45;&gt;17 -->\n<g id=\"edge17\" class=\"edge\">\n<title>16&#45;&gt;17</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1666.5,-296.88C1666.5,-288.78 1666.5,-279.98 1666.5,-271.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1670,-271.3 1666.5,-261.3 1663,-271.3 1670,-271.3\"/>\n</g>\n<!-- 24 -->\n<g id=\"node25\" class=\"node\">\n<title>24</title>\n<path fill=\"#e68743\" stroke=\"black\" d=\"M2219,-261C2219,-261 2092,-261 2092,-261 2086,-261 2080,-255 2080,-249 2080,-249 2080,-205 2080,-205 2080,-199 2086,-193 2092,-193 2092,-193 2219,-193 2219,-193 2225,-193 2231,-199 2231,-205 2231,-205 2231,-249 2231,-249 2231,-255 2225,-261 2219,-261\"/>\n<text text-anchor=\"start\" x=\"2112\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">CGPA â‰¤ 9.465</text>\n<text text-anchor=\"start\" x=\"2088\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.001</text>\n<text text-anchor=\"start\" x=\"2114.5\" y=\"-215.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 45</text>\n<text text-anchor=\"start\" x=\"2114.5\" y=\"-200.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.922</text>\n</g>\n<!-- 16&#45;&gt;24 -->\n<g id=\"edge24\" class=\"edge\">\n<title>16&#45;&gt;24</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1742.1,-314.23C1830.69,-295.75 1977.14,-265.2 2069.85,-245.87\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2070.69,-249.27 2079.77,-243.8 2069.26,-242.41 2070.69,-249.27\"/>\n</g>\n<!-- 18 -->\n<g id=\"node19\" class=\"node\">\n<title>18</title>\n<path fill=\"#eda877\" stroke=\"black\" d=\"M1645,-157C1645,-157 1518,-157 1518,-157 1512,-157 1506,-151 1506,-145 1506,-145 1506,-101 1506,-101 1506,-95 1512,-89 1518,-89 1518,-89 1645,-89 1645,-89 1651,-89 1657,-95 1657,-101 1657,-101 1657,-145 1657,-145 1657,-151 1651,-157 1645,-157\"/>\n<text text-anchor=\"start\" x=\"1522.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">GRE Score â‰¤ 311.0</text>\n<text text-anchor=\"start\" x=\"1514\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.003</text>\n<text text-anchor=\"start\" x=\"1540.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 21</text>\n<text text-anchor=\"start\" x=\"1540.5\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.795</text>\n</g>\n<!-- 17&#45;&gt;18 -->\n<g id=\"edge18\" class=\"edge\">\n<title>17&#45;&gt;18</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1638.9,-192.88C1631.55,-184.07 1623.53,-174.43 1615.86,-165.24\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1618.34,-162.74 1609.25,-157.3 1612.96,-167.22 1618.34,-162.74\"/>\n</g>\n<!-- 21 -->\n<g id=\"node22\" class=\"node\">\n<title>21</title>\n<path fill=\"#ea995f\" stroke=\"black\" d=\"M1815.5,-157C1815.5,-157 1687.5,-157 1687.5,-157 1681.5,-157 1675.5,-151 1675.5,-145 1675.5,-145 1675.5,-101 1675.5,-101 1675.5,-95 1681.5,-89 1687.5,-89 1687.5,-89 1815.5,-89 1815.5,-89 1821.5,-89 1827.5,-95 1827.5,-101 1827.5,-101 1827.5,-145 1827.5,-145 1827.5,-151 1821.5,-157 1815.5,-157\"/>\n<text text-anchor=\"start\" x=\"1683.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">University Rating â‰¤ 4.5</text>\n<text text-anchor=\"start\" x=\"1684\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.002</text>\n<text text-anchor=\"start\" x=\"1710.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 27</text>\n<text text-anchor=\"start\" x=\"1710.5\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.854</text>\n</g>\n<!-- 17&#45;&gt;21 -->\n<g id=\"edge21\" class=\"edge\">\n<title>17&#45;&gt;21</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1694.1,-192.88C1701.45,-184.07 1709.47,-174.43 1717.14,-165.24\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1720.04,-167.22 1723.75,-157.3 1714.66,-162.74 1720.04,-167.22\"/>\n</g>\n<!-- 19 -->\n<g id=\"node20\" class=\"node\">\n<title>19</title>\n<path fill=\"#f4ccae\" stroke=\"black\" d=\"M1476.5,-53C1476.5,-53 1364.5,-53 1364.5,-53 1358.5,-53 1352.5,-47 1352.5,-41 1352.5,-41 1352.5,-12 1352.5,-12 1352.5,-6 1358.5,0 1364.5,0 1364.5,0 1476.5,0 1476.5,0 1482.5,0 1488.5,-6 1488.5,-12 1488.5,-12 1488.5,-41 1488.5,-41 1488.5,-47 1482.5,-53 1476.5,-53\"/>\n<text text-anchor=\"start\" x=\"1360.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.0</text>\n<text text-anchor=\"start\" x=\"1383\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"1383\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.66</text>\n</g>\n<!-- 18&#45;&gt;19 -->\n<g id=\"edge19\" class=\"edge\">\n<title>18&#45;&gt;19</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1525.19,-88.95C1508.28,-79.02 1489.8,-68.18 1473.14,-58.4\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1474.49,-55.13 1464.09,-53.09 1470.94,-61.17 1474.49,-55.13\"/>\n</g>\n<!-- 20 -->\n<g id=\"node21\" class=\"node\">\n<title>20</title>\n<path fill=\"#eda774\" stroke=\"black\" d=\"M1646,-53C1646,-53 1519,-53 1519,-53 1513,-53 1507,-47 1507,-41 1507,-41 1507,-12 1507,-12 1507,-6 1513,0 1519,0 1519,0 1646,0 1646,0 1652,0 1658,-6 1658,-12 1658,-12 1658,-41 1658,-41 1658,-47 1652,-53 1646,-53\"/>\n<text text-anchor=\"start\" x=\"1515\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.002</text>\n<text text-anchor=\"start\" x=\"1541.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 20</text>\n<text text-anchor=\"start\" x=\"1541.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.802</text>\n</g>\n<!-- 18&#45;&gt;20 -->\n<g id=\"edge20\" class=\"edge\">\n<title>18&#45;&gt;20</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1581.85,-88.95C1581.94,-80.72 1582.03,-71.85 1582.12,-63.48\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1585.62,-63.27 1582.23,-53.24 1578.62,-63.2 1585.62,-63.27\"/>\n</g>\n<!-- 22 -->\n<g id=\"node23\" class=\"node\">\n<title>22</title>\n<path fill=\"#eb9e67\" stroke=\"black\" d=\"M1815,-53C1815,-53 1688,-53 1688,-53 1682,-53 1676,-47 1676,-41 1676,-41 1676,-12 1676,-12 1676,-6 1682,0 1688,0 1688,0 1815,0 1815,0 1821,0 1827,-6 1827,-12 1827,-12 1827,-41 1827,-41 1827,-47 1821,-53 1815,-53\"/>\n<text text-anchor=\"start\" x=\"1684\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.001</text>\n<text text-anchor=\"start\" x=\"1710.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 17</text>\n<text text-anchor=\"start\" x=\"1710.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.834</text>\n</g>\n<!-- 21&#45;&gt;22 -->\n<g id=\"edge22\" class=\"edge\">\n<title>21&#45;&gt;22</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1751.5,-88.95C1751.5,-80.72 1751.5,-71.85 1751.5,-63.48\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1755,-63.24 1751.5,-53.24 1748,-63.24 1755,-63.24\"/>\n</g>\n<!-- 23 -->\n<g id=\"node24\" class=\"node\">\n<title>23</title>\n<path fill=\"#e89050\" stroke=\"black\" d=\"M1984,-53C1984,-53 1857,-53 1857,-53 1851,-53 1845,-47 1845,-41 1845,-41 1845,-12 1845,-12 1845,-6 1851,0 1857,0 1857,0 1984,0 1984,0 1990,0 1996,-6 1996,-12 1996,-12 1996,-41 1996,-41 1996,-47 1990,-53 1984,-53\"/>\n<text text-anchor=\"start\" x=\"1853\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.001</text>\n<text text-anchor=\"start\" x=\"1879.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 10</text>\n<text text-anchor=\"start\" x=\"1883\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.89</text>\n</g>\n<!-- 21&#45;&gt;23 -->\n<g id=\"edge23\" class=\"edge\">\n<title>21&#45;&gt;23</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1810.61,-88.95C1828.52,-78.93 1848.11,-67.98 1865.73,-58.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1867.72,-61.02 1874.74,-53.09 1864.31,-54.91 1867.72,-61.02\"/>\n</g>\n<!-- 25 -->\n<g id=\"node26\" class=\"node\">\n<title>25</title>\n<path fill=\"#e78a48\" stroke=\"black\" d=\"M2218,-157C2218,-157 2093,-157 2093,-157 2087,-157 2081,-151 2081,-145 2081,-145 2081,-101 2081,-101 2081,-95 2087,-89 2093,-89 2093,-89 2218,-89 2218,-89 2224,-89 2230,-95 2230,-101 2230,-101 2230,-145 2230,-145 2230,-151 2224,-157 2218,-157\"/>\n<text text-anchor=\"start\" x=\"2089\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">TOEFL Score â‰¤ 113.5</text>\n<text text-anchor=\"start\" x=\"2095.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.0</text>\n<text text-anchor=\"start\" x=\"2114.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 28</text>\n<text text-anchor=\"start\" x=\"2118\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.91</text>\n</g>\n<!-- 24&#45;&gt;25 -->\n<g id=\"edge25\" class=\"edge\">\n<title>24&#45;&gt;25</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2155.5,-192.88C2155.5,-184.78 2155.5,-175.98 2155.5,-167.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2159,-167.3 2155.5,-157.3 2152,-167.3 2159,-167.3\"/>\n</g>\n<!-- 28 -->\n<g id=\"node29\" class=\"node\">\n<title>28</title>\n<path fill=\"#e5823a\" stroke=\"black\" d=\"M2446.5,-157C2446.5,-157 2334.5,-157 2334.5,-157 2328.5,-157 2322.5,-151 2322.5,-145 2322.5,-145 2322.5,-101 2322.5,-101 2322.5,-95 2328.5,-89 2334.5,-89 2334.5,-89 2446.5,-89 2446.5,-89 2452.5,-89 2458.5,-95 2458.5,-101 2458.5,-101 2458.5,-145 2458.5,-145 2458.5,-151 2452.5,-157 2446.5,-157\"/>\n<text text-anchor=\"start\" x=\"2344.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Research â‰¤ 0.5</text>\n<text text-anchor=\"start\" x=\"2330.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.0</text>\n<text text-anchor=\"start\" x=\"2349.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 17</text>\n<text text-anchor=\"start\" x=\"2349.5\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.943</text>\n</g>\n<!-- 24&#45;&gt;28 -->\n<g id=\"edge28\" class=\"edge\">\n<title>24&#45;&gt;28</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2231.15,-193.17C2257.2,-181.86 2286.41,-169.18 2312.63,-157.8\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2314.37,-160.86 2322.15,-153.67 2311.58,-154.44 2314.37,-160.86\"/>\n</g>\n<!-- 26 -->\n<g id=\"node27\" class=\"node\">\n<title>26</title>\n<path fill=\"#e88e4e\" stroke=\"black\" d=\"M2138.5,-53C2138.5,-53 2026.5,-53 2026.5,-53 2020.5,-53 2014.5,-47 2014.5,-41 2014.5,-41 2014.5,-12 2014.5,-12 2014.5,-6 2020.5,0 2026.5,0 2026.5,0 2138.5,0 2138.5,0 2144.5,0 2150.5,-6 2150.5,-12 2150.5,-12 2150.5,-41 2150.5,-41 2150.5,-47 2144.5,-53 2138.5,-53\"/>\n<text text-anchor=\"start\" x=\"2022.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.0</text>\n<text text-anchor=\"start\" x=\"2045\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 9</text>\n<text text-anchor=\"start\" x=\"2041.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.896</text>\n</g>\n<!-- 25&#45;&gt;26 -->\n<g id=\"edge26\" class=\"edge\">\n<title>25&#45;&gt;26</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2129.97,-88.95C2123.04,-79.98 2115.54,-70.27 2108.58,-61.26\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2111.26,-59.01 2102.38,-53.24 2105.72,-63.29 2111.26,-59.01\"/>\n</g>\n<!-- 27 -->\n<g id=\"node28\" class=\"node\">\n<title>27</title>\n<path fill=\"#e78945\" stroke=\"black\" d=\"M2292.5,-53C2292.5,-53 2180.5,-53 2180.5,-53 2174.5,-53 2168.5,-47 2168.5,-41 2168.5,-41 2168.5,-12 2168.5,-12 2168.5,-6 2174.5,0 2180.5,0 2180.5,0 2292.5,0 2292.5,0 2298.5,0 2304.5,-6 2304.5,-12 2304.5,-12 2304.5,-41 2304.5,-41 2304.5,-47 2298.5,-53 2292.5,-53\"/>\n<text text-anchor=\"start\" x=\"2176.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.0</text>\n<text text-anchor=\"start\" x=\"2195.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 19</text>\n<text text-anchor=\"start\" x=\"2195.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.917</text>\n</g>\n<!-- 25&#45;&gt;27 -->\n<g id=\"edge27\" class=\"edge\">\n<title>25&#45;&gt;27</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2183.83,-88.95C2191.59,-79.89 2200.01,-70.07 2207.8,-60.99\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2210.59,-63.11 2214.44,-53.24 2205.27,-58.55 2210.59,-63.11\"/>\n</g>\n<!-- 29 -->\n<g id=\"node30\" class=\"node\">\n<title>29</title>\n<path fill=\"#e89050\" stroke=\"black\" d=\"M2446.5,-53C2446.5,-53 2334.5,-53 2334.5,-53 2328.5,-53 2322.5,-47 2322.5,-41 2322.5,-41 2322.5,-12 2322.5,-12 2322.5,-6 2328.5,0 2334.5,0 2334.5,0 2446.5,0 2446.5,0 2452.5,0 2458.5,-6 2458.5,-12 2458.5,-12 2458.5,-41 2458.5,-41 2458.5,-47 2452.5,-53 2446.5,-53\"/>\n<text text-anchor=\"start\" x=\"2330.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.0</text>\n<text text-anchor=\"start\" x=\"2353\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"2353\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.89</text>\n</g>\n<!-- 28&#45;&gt;29 -->\n<g id=\"edge29\" class=\"edge\">\n<title>28&#45;&gt;29</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2390.5,-88.95C2390.5,-80.72 2390.5,-71.85 2390.5,-63.48\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2394,-63.24 2390.5,-53.24 2387,-63.24 2394,-63.24\"/>\n</g>\n<!-- 30 -->\n<g id=\"node31\" class=\"node\">\n<title>30</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M2600.5,-53C2600.5,-53 2488.5,-53 2488.5,-53 2482.5,-53 2476.5,-47 2476.5,-41 2476.5,-41 2476.5,-12 2476.5,-12 2476.5,-6 2482.5,0 2488.5,0 2488.5,0 2600.5,0 2600.5,0 2606.5,0 2612.5,-6 2612.5,-12 2612.5,-12 2612.5,-41 2612.5,-41 2612.5,-47 2606.5,-53 2600.5,-53\"/>\n<text text-anchor=\"start\" x=\"2484.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.0</text>\n<text text-anchor=\"start\" x=\"2503.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 16</text>\n<text text-anchor=\"start\" x=\"2503.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.946</text>\n</g>\n<!-- 28&#45;&gt;30 -->\n<g id=\"edge30\" class=\"edge\">\n<title>28&#45;&gt;30</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2444.36,-88.95C2460.46,-79.07 2478.05,-68.28 2493.93,-58.53\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2495.87,-61.45 2502.56,-53.24 2492.2,-55.48 2495.87,-61.45\"/>\n</g>\n</g>\n</svg>\n",
            "text/plain": [
              "<graphviz.sources.Source at 0x7d130fec7cd0>"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SOAL 2d\n",
        "\n",
        "[2.5]  Untuk decision tree classifier, tentukan atribut-atribut dari suatu red wine yang paling berpotensi untuk dikategorikan sebagai kelas 4. Jika terdapat berbagai kemungkinan pasangan atribut yang paling berpotensi, cantumkanlah semua kemungkinan pasangan atribut tersebut.\n",
        "\n",
        "**Catatan:** Tidak perlu dilakukan implementasi kode pada bagian ini"
      ],
      "metadata": {
        "id": "OxIT9p6YUMd-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import _tree, export_graphviz\n",
        "\n",
        "\n",
        "dot_data = export_graphviz(dtc_red_2, out_file=None,\n",
        "                           feature_names=pd.Series(X_train_red.columns).array,\n",
        "                           class_names=[str(i) for i in dtc_red_2.classes_],\n",
        "                           filled=True, rounded=True,\n",
        "                           special_characters=True)\n",
        "\n",
        "graph = graphviz.Source(dot_data)\n",
        "graph.render(filename=\"decision_tree_visualization_3\", format=\"pdf\")\n",
        "\n",
        "def extract_paths(tree, feature_names):\n",
        "    tree_ = tree.tree_\n",
        "    paths = []\n",
        "\n",
        "    def recurse(node, path, paths):\n",
        "        if tree_.feature[node] != _tree.TREE_UNDEFINED:\n",
        "            name = feature_names[tree_.feature[node]]\n",
        "            threshold = tree_.threshold[node]\n",
        "            recurse(tree_.children_left[node], path + [(name, '<=', threshold)], paths)\n",
        "            recurse(tree_.children_right[node], path + [(name, '>', threshold)], paths)\n",
        "        else:\n",
        "            paths.append((path, tree_.value[node]))\n",
        "\n",
        "    recurse(0, [], paths)\n",
        "    return paths\n",
        "\n",
        "paths = extract_paths(dtc_red_2, pd.Series(X_train_red.columns).array)\n",
        "\n",
        "class_index = list(dtc_red_2.classes_).index(4)\n",
        "class_4_paths = [path for path, value in paths if np.argmax(value) == class_index]\n",
        "\n",
        "for i, conditions in enumerate(class_4_paths, 1):\n",
        "    print(f\"Kondisi untuk klasifikasi sebagai kelas 4 (jalur {i}):\")\n",
        "    for feature, comparison, value in conditions:\n",
        "        print(f\"{feature} {comparison} {value}\")\n",
        "    print(\"-\" * 40)\n",
        "graph"
      ],
      "metadata": {
        "id": "p-qQkVWeNPja",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 991
        },
        "outputId": "3b2b6143-224f-43b7-fcf2-6e061e86fe82"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kondisi untuk klasifikasi sebagai kelas 4 (jalur 1):\n",
            "sulphates <= 0.6416678726673126\n",
            "volatile acidity > 0.7452250719070435\n",
            "chlorides <= 0.09206699952483177\n",
            "density <= 0.9972914457321167\n",
            "----------------------------------------\n",
            "Kondisi untuk klasifikasi sebagai kelas 4 (jalur 2):\n",
            "sulphates <= 0.6416678726673126\n",
            "volatile acidity > 0.7452250719070435\n",
            "chlorides > 0.09206699952483177\n",
            "alcohol > 10.990881443023682\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: Tree Pages: 1 -->\n<svg width=\"2772pt\" height=\"552pt\"\n viewBox=\"0.00 0.00 2772.00 552.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 548)\">\n<title>Tree</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-548 2768,-548 2768,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<path fill=\"#feffff\" stroke=\"black\" d=\"M1320,-544C1320,-544 1099,-544 1099,-544 1093,-544 1087,-538 1087,-532 1087,-532 1087,-473 1087,-473 1087,-467 1093,-461 1099,-461 1099,-461 1320,-461 1320,-461 1326,-461 1332,-467 1332,-473 1332,-473 1332,-532 1332,-532 1332,-538 1326,-544 1320,-544\"/>\n<text text-anchor=\"start\" x=\"1156\" y=\"-528.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">sulphates â‰¤ 0.642</text>\n<text text-anchor=\"start\" x=\"1174\" y=\"-513.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.833</text>\n<text text-anchor=\"start\" x=\"1161\" y=\"-498.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2772</text>\n<text text-anchor=\"start\" x=\"1095\" y=\"-483.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [460, 451, 474, 467, 463, 457]</text>\n<text text-anchor=\"start\" x=\"1182\" y=\"-468.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 5</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<path fill=\"#fffdfc\" stroke=\"black\" d=\"M938.5,-425C938.5,-425 740.5,-425 740.5,-425 734.5,-425 728.5,-419 728.5,-413 728.5,-413 728.5,-354 728.5,-354 728.5,-348 734.5,-342 740.5,-342 740.5,-342 938.5,-342 938.5,-342 944.5,-342 950.5,-348 950.5,-354 950.5,-354 950.5,-413 950.5,-413 950.5,-419 944.5,-425 938.5,-425\"/>\n<text text-anchor=\"start\" x=\"773\" y=\"-409.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">volatile acidity â‰¤ 0.745</text>\n<text text-anchor=\"start\" x=\"804\" y=\"-394.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.769</text>\n<text text-anchor=\"start\" x=\"791\" y=\"-379.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1479</text>\n<text text-anchor=\"start\" x=\"736.5\" y=\"-364.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [408, 393, 345, 241, 87, 5]</text>\n<text text-anchor=\"start\" x=\"812\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 3</text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1086.81,-462.7C1046.11,-449.83 1000.85,-435.52 960.29,-422.7\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"961.22,-419.32 950.63,-419.64 959.11,-425.99 961.22,-419.32\"/>\n<text text-anchor=\"middle\" x=\"962.16\" y=\"-438.13\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\n</g>\n<!-- 14 -->\n<g id=\"node15\" class=\"node\">\n<title>14</title>\n<path fill=\"#fdeff7\" stroke=\"black\" d=\"M1697.5,-425C1697.5,-425 1491.5,-425 1491.5,-425 1485.5,-425 1479.5,-419 1479.5,-413 1479.5,-413 1479.5,-354 1479.5,-354 1479.5,-348 1485.5,-342 1491.5,-342 1491.5,-342 1697.5,-342 1697.5,-342 1703.5,-342 1709.5,-348 1709.5,-354 1709.5,-354 1709.5,-413 1709.5,-413 1709.5,-419 1703.5,-425 1697.5,-425\"/>\n<text text-anchor=\"start\" x=\"1544.5\" y=\"-409.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">alcohol â‰¤ 10.901</text>\n<text text-anchor=\"start\" x=\"1559\" y=\"-394.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.749</text>\n<text text-anchor=\"start\" x=\"1546\" y=\"-379.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1293</text>\n<text text-anchor=\"start\" x=\"1487.5\" y=\"-364.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [52, 58, 129, 226, 376, 452]</text>\n<text text-anchor=\"start\" x=\"1567\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 8</text>\n</g>\n<!-- 0&#45;&gt;14 -->\n<g id=\"edge14\" class=\"edge\">\n<title>0&#45;&gt;14</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1332.11,-464.24C1376,-450.9 1425.49,-435.86 1469.57,-422.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1470.63,-425.8 1479.18,-419.54 1468.6,-419.1 1470.63,-425.8\"/>\n<text text-anchor=\"middle\" x=\"1467.41\" y=\"-437.9\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\">\n<title>2</title>\n<path fill=\"#e9fcf1\" stroke=\"black\" d=\"M421,-306C421,-306 230,-306 230,-306 224,-306 218,-300 218,-294 218,-294 218,-235 218,-235 218,-229 224,-223 230,-223 230,-223 421,-223 421,-223 427,-223 433,-229 433,-235 433,-235 433,-294 433,-294 433,-300 427,-306 421,-306\"/>\n<text text-anchor=\"start\" x=\"279.5\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">alcohol â‰¤ 8.999</text>\n<text text-anchor=\"start\" x=\"290\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.756</text>\n<text text-anchor=\"start\" x=\"280.5\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 891</text>\n<text text-anchor=\"start\" x=\"226\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [73, 211, 297, 221, 84, 5]</text>\n<text text-anchor=\"start\" x=\"298\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 5</text>\n</g>\n<!-- 1&#45;&gt;2 -->\n<g id=\"edge2\" class=\"edge\">\n<title>1&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M728.29,-357.18C644.15,-338.03 528.87,-311.79 443.19,-292.29\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"443.95,-288.87 433.42,-290.07 442.4,-295.7 443.95,-288.87\"/>\n</g>\n<!-- 7 -->\n<g id=\"node8\" class=\"node\">\n<title>7</title>\n<path fill=\"#f5d0b4\" stroke=\"black\" d=\"M927.5,-306C927.5,-306 751.5,-306 751.5,-306 745.5,-306 739.5,-300 739.5,-294 739.5,-294 739.5,-235 739.5,-235 739.5,-229 745.5,-223 751.5,-223 751.5,-223 927.5,-223 927.5,-223 933.5,-223 939.5,-229 939.5,-235 939.5,-235 939.5,-294 939.5,-294 939.5,-300 933.5,-306 927.5,-306\"/>\n<text text-anchor=\"start\" x=\"788\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">chlorides â‰¤ 0.092</text>\n<text text-anchor=\"start\" x=\"804\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.572</text>\n<text text-anchor=\"start\" x=\"794.5\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 588</text>\n<text text-anchor=\"start\" x=\"747.5\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [335, 182, 48, 20, 3, 0]</text>\n<text text-anchor=\"start\" x=\"812\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 3</text>\n</g>\n<!-- 1&#45;&gt;7 -->\n<g id=\"edge7\" class=\"edge\">\n<title>1&#45;&gt;7</title>\n<path fill=\"none\" stroke=\"black\" d=\"M839.5,-341.91C839.5,-333.65 839.5,-324.86 839.5,-316.3\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"843,-316.02 839.5,-306.02 836,-316.02 843,-316.02\"/>\n</g>\n<!-- 3 -->\n<g id=\"node4\" class=\"node\">\n<title>3</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M187.5,-179.5C187.5,-179.5 49.5,-179.5 49.5,-179.5 43.5,-179.5 37.5,-173.5 37.5,-167.5 37.5,-167.5 37.5,-123.5 37.5,-123.5 37.5,-117.5 43.5,-111.5 49.5,-111.5 49.5,-111.5 187.5,-111.5 187.5,-111.5 193.5,-111.5 199.5,-117.5 199.5,-123.5 199.5,-123.5 199.5,-167.5 199.5,-167.5 199.5,-173.5 193.5,-179.5 187.5,-179.5\"/>\n<text text-anchor=\"start\" x=\"90.5\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"77.5\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 39</text>\n<text text-anchor=\"start\" x=\"45.5\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [39, 0, 0, 0, 0, 0]</text>\n<text text-anchor=\"start\" x=\"91\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 3</text>\n</g>\n<!-- 2&#45;&gt;3 -->\n<g id=\"edge3\" class=\"edge\">\n<title>2&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M253.68,-222.91C231.72,-210.49 207.65,-196.89 185.99,-184.64\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"187.61,-181.54 177.18,-179.67 184.16,-187.63 187.61,-181.54\"/>\n</g>\n<!-- 4 -->\n<g id=\"node5\" class=\"node\">\n<title>4</title>\n<path fill=\"#e7fcf0\" stroke=\"black\" d=\"M421,-187C421,-187 230,-187 230,-187 224,-187 218,-181 218,-175 218,-175 218,-116 218,-116 218,-110 224,-104 230,-104 230,-104 421,-104 421,-104 427,-104 433,-110 433,-116 433,-116 433,-175 433,-175 433,-181 427,-187 421,-187\"/>\n<text text-anchor=\"start\" x=\"283\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">alcohol â‰¤ 10.3</text>\n<text text-anchor=\"start\" x=\"290\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.739</text>\n<text text-anchor=\"start\" x=\"280.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 852</text>\n<text text-anchor=\"start\" x=\"226\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [34, 211, 297, 221, 84, 5]</text>\n<text text-anchor=\"start\" x=\"298\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 5</text>\n</g>\n<!-- 2&#45;&gt;4 -->\n<g id=\"edge4\" class=\"edge\">\n<title>2&#45;&gt;4</title>\n<path fill=\"none\" stroke=\"black\" d=\"M325.5,-222.91C325.5,-214.65 325.5,-205.86 325.5,-197.3\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"329,-197.02 325.5,-187.02 322,-197.02 329,-197.02\"/>\n</g>\n<!-- 5 -->\n<g id=\"node6\" class=\"node\">\n<title>5</title>\n<path fill=\"#b8f6d2\" stroke=\"black\" d=\"M195,-68C195,-68 12,-68 12,-68 6,-68 0,-62 0,-56 0,-56 0,-12 0,-12 0,-6 6,0 12,0 12,0 195,0 195,0 201,0 207,-6 207,-12 207,-12 207,-56 207,-56 207,-62 201,-68 195,-68\"/>\n<text text-anchor=\"start\" x=\"68\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.664</text>\n<text text-anchor=\"start\" x=\"58.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 497</text>\n<text text-anchor=\"start\" x=\"8\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [34, 105, 245, 104, 9, 0]</text>\n<text text-anchor=\"start\" x=\"76\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 5</text>\n</g>\n<!-- 4&#45;&gt;5 -->\n<g id=\"edge5\" class=\"edge\">\n<title>4&#45;&gt;5</title>\n<path fill=\"none\" stroke=\"black\" d=\"M243.15,-103.88C222.3,-93.6 200,-82.6 179.48,-72.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"181.01,-69.33 170.49,-68.04 177.91,-75.61 181.01,-69.33\"/>\n</g>\n<!-- 6 -->\n<g id=\"node7\" class=\"node\">\n<title>6</title>\n<path fill=\"#f6fbfe\" stroke=\"black\" d=\"M413.5,-68C413.5,-68 237.5,-68 237.5,-68 231.5,-68 225.5,-62 225.5,-56 225.5,-56 225.5,-12 225.5,-12 225.5,-6 231.5,0 237.5,0 237.5,0 413.5,0 413.5,0 419.5,0 425.5,-6 425.5,-12 425.5,-12 425.5,-56 425.5,-56 425.5,-62 419.5,-68 413.5,-68\"/>\n<text text-anchor=\"start\" x=\"290\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.736</text>\n<text text-anchor=\"start\" x=\"280.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 355</text>\n<text text-anchor=\"start\" x=\"233.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 106, 52, 117, 75, 5]</text>\n<text text-anchor=\"start\" x=\"298\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 6</text>\n</g>\n<!-- 4&#45;&gt;6 -->\n<g id=\"edge6\" class=\"edge\">\n<title>4&#45;&gt;6</title>\n<path fill=\"none\" stroke=\"black\" d=\"M325.5,-103.73C325.5,-95.52 325.5,-86.86 325.5,-78.56\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"329,-78.3 325.5,-68.3 322,-78.3 329,-78.3\"/>\n</g>\n<!-- 8 -->\n<g id=\"node9\" class=\"node\">\n<title>8</title>\n<path fill=\"#f2fbe4\" stroke=\"black\" d=\"M822.5,-187C822.5,-187 646.5,-187 646.5,-187 640.5,-187 634.5,-181 634.5,-175 634.5,-175 634.5,-116 634.5,-116 634.5,-110 640.5,-104 646.5,-104 646.5,-104 822.5,-104 822.5,-104 828.5,-104 834.5,-110 834.5,-116 834.5,-116 834.5,-175 834.5,-175 834.5,-181 828.5,-187 822.5,-187\"/>\n<text text-anchor=\"start\" x=\"688.5\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">density â‰¤ 0.997</text>\n<text text-anchor=\"start\" x=\"699\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.625</text>\n<text text-anchor=\"start\" x=\"689.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 354</text>\n<text text-anchor=\"start\" x=\"642.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [135, 165, 35, 16, 3, 0]</text>\n<text text-anchor=\"start\" x=\"707\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 4</text>\n</g>\n<!-- 7&#45;&gt;8 -->\n<g id=\"edge8\" class=\"edge\">\n<title>7&#45;&gt;8</title>\n<path fill=\"none\" stroke=\"black\" d=\"M803.07,-222.91C794.85,-213.74 786.04,-203.93 777.57,-194.49\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"780.15,-192.13 770.86,-187.02 774.94,-196.8 780.15,-192.13\"/>\n</g>\n<!-- 11 -->\n<g id=\"node12\" class=\"node\">\n<title>11</title>\n<path fill=\"#e99558\" stroke=\"black\" d=\"M1026,-187C1026,-187 865,-187 865,-187 859,-187 853,-181 853,-175 853,-175 853,-116 853,-116 853,-110 859,-104 865,-104 865,-104 1026,-104 1026,-104 1032,-104 1038,-110 1038,-116 1038,-116 1038,-175 1038,-175 1038,-181 1032,-187 1026,-187\"/>\n<text text-anchor=\"start\" x=\"895.5\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">alcohol â‰¤ 10.991</text>\n<text text-anchor=\"start\" x=\"910\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.261</text>\n<text text-anchor=\"start\" x=\"900.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 234</text>\n<text text-anchor=\"start\" x=\"861\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [200, 17, 13, 4, 0, 0]</text>\n<text text-anchor=\"start\" x=\"918\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 3</text>\n</g>\n<!-- 7&#45;&gt;11 -->\n<g id=\"edge11\" class=\"edge\">\n<title>7&#45;&gt;11</title>\n<path fill=\"none\" stroke=\"black\" d=\"M876.28,-222.91C884.58,-213.74 893.47,-203.93 902.02,-194.49\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"904.67,-196.78 908.79,-187.02 899.48,-192.08 904.67,-196.78\"/>\n</g>\n<!-- 9 -->\n<g id=\"node10\" class=\"node\">\n<title>9</title>\n<path fill=\"#cdf299\" stroke=\"black\" d=\"M623.5,-68C623.5,-68 455.5,-68 455.5,-68 449.5,-68 443.5,-62 443.5,-56 443.5,-56 443.5,-12 443.5,-12 443.5,-6 449.5,0 455.5,0 455.5,0 623.5,0 623.5,0 629.5,0 635.5,-6 635.5,-12 635.5,-12 635.5,-56 635.5,-56 635.5,-62 629.5,-68 623.5,-68\"/>\n<text text-anchor=\"start\" x=\"504\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.554</text>\n<text text-anchor=\"start\" x=\"494.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 248</text>\n<text text-anchor=\"start\" x=\"451.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [55, 154, 22, 14, 3, 0]</text>\n<text text-anchor=\"start\" x=\"512\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 4</text>\n</g>\n<!-- 8&#45;&gt;9 -->\n<g id=\"edge9\" class=\"edge\">\n<title>8&#45;&gt;9</title>\n<path fill=\"none\" stroke=\"black\" d=\"M662.17,-103.88C644.26,-93.83 625.14,-83.09 607.45,-73.16\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"608.78,-69.89 598.34,-68.04 605.35,-75.99 608.78,-69.89\"/>\n</g>\n<!-- 10 -->\n<g id=\"node11\" class=\"node\">\n<title>10</title>\n<path fill=\"#eca470\" stroke=\"black\" d=\"M819,-68C819,-68 666,-68 666,-68 660,-68 654,-62 654,-56 654,-56 654,-12 654,-12 654,-6 660,0 666,0 666,0 819,0 819,0 825,0 831,-6 831,-12 831,-12 831,-56 831,-56 831,-62 825,-68 819,-68\"/>\n<text text-anchor=\"start\" x=\"707\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.404</text>\n<text text-anchor=\"start\" x=\"697.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 106</text>\n<text text-anchor=\"start\" x=\"662\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [80, 11, 13, 2, 0, 0]</text>\n<text text-anchor=\"start\" x=\"715\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 3</text>\n</g>\n<!-- 8&#45;&gt;10 -->\n<g id=\"edge10\" class=\"edge\">\n<title>8&#45;&gt;10</title>\n<path fill=\"none\" stroke=\"black\" d=\"M737.48,-103.73C738.09,-95.43 738.73,-86.67 739.34,-78.28\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"742.83,-78.53 740.07,-68.3 735.85,-78.02 742.83,-78.53\"/>\n</g>\n<!-- 12 -->\n<g id=\"node13\" class=\"node\">\n<title>12</title>\n<path fill=\"#e89050\" stroke=\"black\" d=\"M1014,-68C1014,-68 861,-68 861,-68 855,-68 849,-62 849,-56 849,-56 849,-12 849,-12 849,-6 855,0 861,0 861,0 1014,0 1014,0 1020,0 1026,-6 1026,-12 1026,-12 1026,-56 1026,-56 1026,-62 1020,-68 1014,-68\"/>\n<text text-anchor=\"start\" x=\"902\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.205</text>\n<text text-anchor=\"start\" x=\"892.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 225</text>\n<text text-anchor=\"start\" x=\"857\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [200, 8, 13, 4, 0, 0]</text>\n<text text-anchor=\"start\" x=\"910\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 3</text>\n</g>\n<!-- 11&#45;&gt;12 -->\n<g id=\"edge12\" class=\"edge\">\n<title>11&#45;&gt;12</title>\n<path fill=\"none\" stroke=\"black\" d=\"M942.52,-103.73C941.91,-95.43 941.27,-86.67 940.66,-78.28\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"944.15,-78.02 939.93,-68.3 937.17,-78.53 944.15,-78.02\"/>\n</g>\n<!-- 13 -->\n<g id=\"node14\" class=\"node\">\n<title>13</title>\n<path fill=\"#9de539\" stroke=\"black\" d=\"M1187,-68C1187,-68 1056,-68 1056,-68 1050,-68 1044,-62 1044,-56 1044,-56 1044,-12 1044,-12 1044,-6 1050,0 1056,0 1056,0 1187,0 1187,0 1193,0 1199,-6 1199,-12 1199,-12 1199,-56 1199,-56 1199,-62 1193,-68 1187,-68\"/>\n<text text-anchor=\"start\" x=\"1093.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1084\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 9</text>\n<text text-anchor=\"start\" x=\"1052\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 9, 0, 0, 0, 0]</text>\n<text text-anchor=\"start\" x=\"1094\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 4</text>\n</g>\n<!-- 11&#45;&gt;13 -->\n<g id=\"edge13\" class=\"edge\">\n<title>11&#45;&gt;13</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1011.04,-103.73C1026.95,-93.82 1043.92,-83.27 1059.66,-73.48\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1061.62,-76.38 1068.26,-68.13 1057.92,-70.44 1061.62,-76.38\"/>\n</g>\n<!-- 15 -->\n<g id=\"node16\" class=\"node\">\n<title>15</title>\n<path fill=\"#f5fafe\" stroke=\"black\" d=\"M1693.5,-306C1693.5,-306 1495.5,-306 1495.5,-306 1489.5,-306 1483.5,-300 1483.5,-294 1483.5,-294 1483.5,-235 1483.5,-235 1483.5,-229 1489.5,-223 1495.5,-223 1495.5,-223 1693.5,-223 1693.5,-223 1699.5,-223 1705.5,-229 1705.5,-235 1705.5,-235 1705.5,-294 1705.5,-294 1705.5,-300 1699.5,-306 1693.5,-306\"/>\n<text text-anchor=\"start\" x=\"1548.5\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">alcohol â‰¤ 9.897</text>\n<text text-anchor=\"start\" x=\"1559\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.804</text>\n<text text-anchor=\"start\" x=\"1549.5\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 510</text>\n<text text-anchor=\"start\" x=\"1491.5\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [52, 57, 118, 137, 101, 45]</text>\n<text text-anchor=\"start\" x=\"1567\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 6</text>\n</g>\n<!-- 14&#45;&gt;15 -->\n<g id=\"edge15\" class=\"edge\">\n<title>14&#45;&gt;15</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1594.5,-341.91C1594.5,-333.65 1594.5,-324.86 1594.5,-316.3\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1598,-316.02 1594.5,-306.02 1591,-316.02 1598,-316.02\"/>\n</g>\n<!-- 22 -->\n<g id=\"node23\" class=\"node\">\n<title>22</title>\n<path fill=\"#f8cce6\" stroke=\"black\" d=\"M2290.5,-306C2290.5,-306 2114.5,-306 2114.5,-306 2108.5,-306 2102.5,-300 2102.5,-294 2102.5,-294 2102.5,-235 2102.5,-235 2102.5,-229 2108.5,-223 2114.5,-223 2114.5,-223 2290.5,-223 2290.5,-223 2296.5,-223 2302.5,-229 2302.5,-235 2302.5,-235 2302.5,-294 2302.5,-294 2302.5,-300 2296.5,-306 2290.5,-306\"/>\n<text text-anchor=\"start\" x=\"2151\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">chlorides â‰¤ 0.086</text>\n<text text-anchor=\"start\" x=\"2167\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.593</text>\n<text text-anchor=\"start\" x=\"2157.5\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 783</text>\n<text text-anchor=\"start\" x=\"2110.5\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1, 11, 89, 275, 407]</text>\n<text text-anchor=\"start\" x=\"2175\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 8</text>\n</g>\n<!-- 14&#45;&gt;22 -->\n<g id=\"edge22\" class=\"edge\">\n<title>14&#45;&gt;22</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1709.57,-360.36C1819.41,-339.22 1983.76,-307.59 2092.04,-286.76\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2092.85,-290.16 2102.01,-284.84 2091.53,-283.29 2092.85,-290.16\"/>\n</g>\n<!-- 16 -->\n<g id=\"node17\" class=\"node\">\n<title>16</title>\n<path fill=\"#e5fcef\" stroke=\"black\" d=\"M1572,-187C1572,-187 1411,-187 1411,-187 1405,-187 1399,-181 1399,-175 1399,-175 1399,-116 1399,-116 1399,-110 1405,-104 1411,-104 1411,-104 1572,-104 1572,-104 1578,-104 1584,-110 1584,-116 1584,-116 1584,-175 1584,-175 1584,-181 1578,-187 1572,-187\"/>\n<text text-anchor=\"start\" x=\"1445.5\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">alcohol â‰¤ 9.819</text>\n<text text-anchor=\"start\" x=\"1456\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.753</text>\n<text text-anchor=\"start\" x=\"1446.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 223</text>\n<text text-anchor=\"start\" x=\"1407\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [46, 41, 75, 53, 4, 4]</text>\n<text text-anchor=\"start\" x=\"1464\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 5</text>\n</g>\n<!-- 15&#45;&gt;16 -->\n<g id=\"edge16\" class=\"edge\">\n<title>15&#45;&gt;16</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1558.76,-222.91C1550.78,-213.83 1542.23,-204.12 1533.99,-194.77\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1536.41,-192.21 1527.17,-187.02 1531.15,-196.84 1536.41,-192.21\"/>\n</g>\n<!-- 19 -->\n<g id=\"node20\" class=\"node\">\n<title>19</title>\n<path fill=\"#f7f2fd\" stroke=\"black\" d=\"M1782.5,-187C1782.5,-187 1614.5,-187 1614.5,-187 1608.5,-187 1602.5,-181 1602.5,-175 1602.5,-175 1602.5,-116 1602.5,-116 1602.5,-110 1608.5,-104 1614.5,-104 1614.5,-104 1782.5,-104 1782.5,-104 1788.5,-104 1794.5,-110 1794.5,-116 1794.5,-116 1794.5,-175 1794.5,-175 1794.5,-181 1788.5,-187 1782.5,-187\"/>\n<text text-anchor=\"start\" x=\"1620.5\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">free sulfur dioxide â‰¤ 6.144</text>\n<text text-anchor=\"start\" x=\"1663\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.754</text>\n<text text-anchor=\"start\" x=\"1653.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 287</text>\n<text text-anchor=\"start\" x=\"1610.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [6, 16, 43, 84, 97, 41]</text>\n<text text-anchor=\"start\" x=\"1671\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 7</text>\n</g>\n<!-- 15&#45;&gt;19 -->\n<g id=\"edge19\" class=\"edge\">\n<title>15&#45;&gt;19</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1630.58,-222.91C1638.65,-213.83 1647.28,-204.12 1655.59,-194.77\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1658.45,-196.82 1662.48,-187.02 1653.22,-192.17 1658.45,-196.82\"/>\n</g>\n<!-- 17 -->\n<g id=\"node18\" class=\"node\">\n<title>17</title>\n<path fill=\"#e1fbec\" stroke=\"black\" d=\"M1390,-68C1390,-68 1229,-68 1229,-68 1223,-68 1217,-62 1217,-56 1217,-56 1217,-12 1217,-12 1217,-6 1223,0 1229,0 1229,0 1390,0 1390,0 1396,0 1402,-6 1402,-12 1402,-12 1402,-56 1402,-56 1402,-62 1396,-68 1390,-68\"/>\n<text text-anchor=\"start\" x=\"1277.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.73</text>\n<text text-anchor=\"start\" x=\"1264.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 198</text>\n<text text-anchor=\"start\" x=\"1225\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [25, 39, 75, 53, 4, 2]</text>\n<text text-anchor=\"start\" x=\"1282\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 5</text>\n</g>\n<!-- 16&#45;&gt;17 -->\n<g id=\"edge17\" class=\"edge\">\n<title>16&#45;&gt;17</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1423.99,-103.88C1407.43,-93.92 1389.76,-83.29 1373.37,-73.43\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1374.79,-70.2 1364.42,-68.04 1371.19,-76.2 1374.79,-70.2\"/>\n</g>\n<!-- 18 -->\n<g id=\"node19\" class=\"node\">\n<title>18</title>\n<path fill=\"#ea975b\" stroke=\"black\" d=\"M1570.5,-68C1570.5,-68 1432.5,-68 1432.5,-68 1426.5,-68 1420.5,-62 1420.5,-56 1420.5,-56 1420.5,-12 1420.5,-12 1420.5,-6 1426.5,0 1432.5,0 1432.5,0 1570.5,0 1570.5,0 1576.5,0 1582.5,-6 1582.5,-12 1582.5,-12 1582.5,-56 1582.5,-56 1582.5,-62 1576.5,-68 1570.5,-68\"/>\n<text text-anchor=\"start\" x=\"1466\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.282</text>\n<text text-anchor=\"start\" x=\"1460.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 25</text>\n<text text-anchor=\"start\" x=\"1428.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [21, 2, 0, 0, 0, 2]</text>\n<text text-anchor=\"start\" x=\"1474\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 3</text>\n</g>\n<!-- 16&#45;&gt;18 -->\n<g id=\"edge18\" class=\"edge\">\n<title>16&#45;&gt;18</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1495.22,-103.73C1495.98,-95.43 1496.78,-86.67 1497.55,-78.28\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1501.03,-78.58 1498.46,-68.3 1494.06,-77.94 1501.03,-78.58\"/>\n</g>\n<!-- 20 -->\n<g id=\"node21\" class=\"node\">\n<title>20</title>\n<path fill=\"#fbe1f0\" stroke=\"black\" d=\"M1766,-68C1766,-68 1613,-68 1613,-68 1607,-68 1601,-62 1601,-56 1601,-56 1601,-12 1601,-12 1601,-6 1607,0 1613,0 1613,0 1766,0 1766,0 1772,0 1778,-6 1778,-12 1778,-12 1778,-56 1778,-56 1778,-62 1772,-68 1766,-68\"/>\n<text text-anchor=\"start\" x=\"1654\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.658</text>\n<text text-anchor=\"start\" x=\"1648.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 70</text>\n<text text-anchor=\"start\" x=\"1609\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 0, 4, 24, 11, 31]</text>\n<text text-anchor=\"start\" x=\"1662\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 8</text>\n</g>\n<!-- 19&#45;&gt;20 -->\n<g id=\"edge20\" class=\"edge\">\n<title>19&#45;&gt;20</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1695.15,-103.73C1694.47,-95.43 1693.75,-86.67 1693.06,-78.28\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1696.54,-77.98 1692.24,-68.3 1689.57,-78.55 1696.54,-77.98\"/>\n</g>\n<!-- 21 -->\n<g id=\"node22\" class=\"node\">\n<title>21</title>\n<path fill=\"#eadefb\" stroke=\"black\" d=\"M1976.5,-68C1976.5,-68 1808.5,-68 1808.5,-68 1802.5,-68 1796.5,-62 1796.5,-56 1796.5,-56 1796.5,-12 1796.5,-12 1796.5,-6 1802.5,0 1808.5,0 1808.5,0 1976.5,0 1976.5,0 1982.5,0 1988.5,-6 1988.5,-12 1988.5,-12 1988.5,-56 1988.5,-56 1988.5,-62 1982.5,-68 1976.5,-68\"/>\n<text text-anchor=\"start\" x=\"1857\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.726</text>\n<text text-anchor=\"start\" x=\"1847.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 217</text>\n<text text-anchor=\"start\" x=\"1804.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [6, 16, 39, 60, 86, 10]</text>\n<text text-anchor=\"start\" x=\"1865\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 7</text>\n</g>\n<!-- 19&#45;&gt;21 -->\n<g id=\"edge21\" class=\"edge\">\n<title>19&#45;&gt;21</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1770.46,-103.88C1788.28,-93.83 1807.3,-83.09 1824.9,-73.16\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1826.97,-76.01 1833.96,-68.04 1823.53,-69.91 1826.97,-76.01\"/>\n</g>\n<!-- 23 -->\n<g id=\"node24\" class=\"node\">\n<title>23</title>\n<path fill=\"#f5b1d8\" stroke=\"black\" d=\"M2286.5,-187C2286.5,-187 2118.5,-187 2118.5,-187 2112.5,-187 2106.5,-181 2106.5,-175 2106.5,-175 2106.5,-116 2106.5,-116 2106.5,-110 2112.5,-104 2118.5,-104 2118.5,-104 2286.5,-104 2286.5,-104 2292.5,-104 2298.5,-110 2298.5,-116 2298.5,-116 2298.5,-175 2298.5,-175 2298.5,-181 2292.5,-187 2286.5,-187\"/>\n<text text-anchor=\"start\" x=\"2169\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">pH â‰¤ 3.249</text>\n<text text-anchor=\"start\" x=\"2167\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.553</text>\n<text text-anchor=\"start\" x=\"2157.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 698</text>\n<text text-anchor=\"start\" x=\"2114.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 0, 5, 68, 218, 407]</text>\n<text text-anchor=\"start\" x=\"2175\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 8</text>\n</g>\n<!-- 22&#45;&gt;23 -->\n<g id=\"edge23\" class=\"edge\">\n<title>22&#45;&gt;23</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2202.5,-222.91C2202.5,-214.65 2202.5,-205.86 2202.5,-197.3\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2206,-197.02 2202.5,-187.02 2199,-197.02 2206,-197.02\"/>\n</g>\n<!-- 26 -->\n<g id=\"node27\" class=\"node\">\n<title>26</title>\n<path fill=\"#b890f0\" stroke=\"black\" d=\"M2578.5,-187C2578.5,-187 2432.5,-187 2432.5,-187 2426.5,-187 2420.5,-181 2420.5,-175 2420.5,-175 2420.5,-116 2420.5,-116 2420.5,-110 2426.5,-104 2432.5,-104 2432.5,-104 2578.5,-104 2578.5,-104 2584.5,-104 2590.5,-110 2590.5,-116 2590.5,-116 2590.5,-175 2590.5,-175 2590.5,-181 2584.5,-187 2578.5,-187\"/>\n<text text-anchor=\"start\" x=\"2439\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">volatile acidity â‰¤ 0.575</text>\n<text text-anchor=\"start\" x=\"2470\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.484</text>\n<text text-anchor=\"start\" x=\"2464.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 85</text>\n<text text-anchor=\"start\" x=\"2428.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1, 6, 21, 57, 0]</text>\n<text text-anchor=\"start\" x=\"2478\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 7</text>\n</g>\n<!-- 22&#45;&gt;26 -->\n<g id=\"edge26\" class=\"edge\">\n<title>22&#45;&gt;26</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2302.55,-224.87C2337.37,-211.42 2376.31,-196.38 2410.69,-183.11\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2412.2,-186.28 2420.26,-179.41 2409.67,-179.75 2412.2,-186.28\"/>\n</g>\n<!-- 24 -->\n<g id=\"node25\" class=\"node\">\n<title>24</title>\n<path fill=\"#eb66b3\" stroke=\"black\" d=\"M2180,-68C2180,-68 2019,-68 2019,-68 2013,-68 2007,-62 2007,-56 2007,-56 2007,-12 2007,-12 2007,-6 2013,0 2019,0 2019,0 2180,0 2180,0 2186,0 2192,-6 2192,-12 2192,-12 2192,-56 2192,-56 2192,-62 2186,-68 2180,-68\"/>\n<text text-anchor=\"start\" x=\"2064\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.326</text>\n<text text-anchor=\"start\" x=\"2054.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 299</text>\n<text text-anchor=\"start\" x=\"2015\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 0, 1, 12, 45, 241]</text>\n<text text-anchor=\"start\" x=\"2072\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 8</text>\n</g>\n<!-- 23&#45;&gt;24 -->\n<g id=\"edge24\" class=\"edge\">\n<title>23&#45;&gt;24</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2164.15,-103.73C2155.57,-94.61 2146.47,-84.93 2137.89,-75.81\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2140.22,-73.19 2130.82,-68.3 2135.13,-77.98 2140.22,-73.19\"/>\n</g>\n<!-- 25 -->\n<g id=\"node26\" class=\"node\">\n<title>25</title>\n<path fill=\"#fbf9fe\" stroke=\"black\" d=\"M2390.5,-68C2390.5,-68 2222.5,-68 2222.5,-68 2216.5,-68 2210.5,-62 2210.5,-56 2210.5,-56 2210.5,-12 2210.5,-12 2210.5,-6 2216.5,0 2222.5,0 2222.5,0 2390.5,0 2390.5,0 2396.5,0 2402.5,-6 2402.5,-12 2402.5,-12 2402.5,-56 2402.5,-56 2402.5,-62 2396.5,-68 2390.5,-68\"/>\n<text text-anchor=\"start\" x=\"2271\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.619</text>\n<text text-anchor=\"start\" x=\"2261.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 399</text>\n<text text-anchor=\"start\" x=\"2218.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 0, 4, 56, 173, 166]</text>\n<text text-anchor=\"start\" x=\"2279\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 7</text>\n</g>\n<!-- 23&#45;&gt;25 -->\n<g id=\"edge25\" class=\"edge\">\n<title>23&#45;&gt;25</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2241.23,-103.73C2249.89,-94.61 2259.08,-84.93 2267.74,-75.81\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2270.52,-77.96 2274.87,-68.3 2265.45,-73.14 2270.52,-77.96\"/>\n</g>\n<!-- 27 -->\n<g id=\"node28\" class=\"node\">\n<title>27</title>\n<path fill=\"#a876ed\" stroke=\"black\" d=\"M2578.5,-68C2578.5,-68 2432.5,-68 2432.5,-68 2426.5,-68 2420.5,-62 2420.5,-56 2420.5,-56 2420.5,-12 2420.5,-12 2420.5,-6 2426.5,0 2432.5,0 2432.5,0 2578.5,0 2578.5,0 2584.5,0 2590.5,-6 2590.5,-12 2590.5,-12 2590.5,-56 2590.5,-56 2590.5,-62 2584.5,-68 2578.5,-68\"/>\n<text text-anchor=\"start\" x=\"2470\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.398</text>\n<text text-anchor=\"start\" x=\"2464.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 72</text>\n<text text-anchor=\"start\" x=\"2428.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1, 3, 14, 54, 0]</text>\n<text text-anchor=\"start\" x=\"2478\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 7</text>\n</g>\n<!-- 26&#45;&gt;27 -->\n<g id=\"edge27\" class=\"edge\">\n<title>26&#45;&gt;27</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2505.5,-103.73C2505.5,-95.52 2505.5,-86.86 2505.5,-78.56\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2509,-78.3 2505.5,-68.3 2502,-78.3 2509,-78.3\"/>\n</g>\n<!-- 28 -->\n<g id=\"node29\" class=\"node\">\n<title>28</title>\n<path fill=\"#b0d8f5\" stroke=\"black\" d=\"M2752,-68C2752,-68 2621,-68 2621,-68 2615,-68 2609,-62 2609,-56 2609,-56 2609,-12 2609,-12 2609,-6 2615,0 2621,0 2621,0 2752,0 2752,0 2758,0 2764,-6 2764,-12 2764,-12 2764,-56 2764,-56 2764,-62 2758,-68 2752,-68\"/>\n<text text-anchor=\"start\" x=\"2651\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.604</text>\n<text text-anchor=\"start\" x=\"2645.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 13</text>\n<text text-anchor=\"start\" x=\"2617\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 0, 3, 7, 3, 0]</text>\n<text text-anchor=\"start\" x=\"2659\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 6</text>\n</g>\n<!-- 26&#45;&gt;28 -->\n<g id=\"edge28\" class=\"edge\">\n<title>26&#45;&gt;28</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2572.64,-103.88C2589.11,-93.92 2606.68,-83.29 2622.98,-73.43\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2625.14,-76.21 2631.88,-68.04 2621.51,-70.22 2625.14,-76.21\"/>\n</g>\n</g>\n</svg>\n",
            "text/plain": [
              "<graphviz.sources.Source at 0x7d130ff74df0>"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SOAL 3 [15]"
      ],
      "metadata": {
        "id": "BRkqj8a3PaKA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SOAL 3a\n",
        "\n",
        "[5] Implementasikan 2 model Random Forest (Random Forest Regressor untuk Admission Prediction dan Random Forest Classifier untuk Red Wine) Implementasi pada soal ini akan menggunakan nilai *hyperparameter*\n",
        "- `max_depth = 3`\n",
        "- `random_state = 2023`"
      ],
      "metadata": {
        "id": "9ZUOkCv1cZTW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf_red = RandomForestClassifier(max_depth=3, random_state=2023)\n",
        "rf_red.fit(X_train_red, Y_train_red)"
      ],
      "metadata": {
        "id": "QRIKzA7SNSpu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "outputId": "3c0e6ae6-1699-4974-a611-e0654433b88b"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(max_depth=3, random_state=2023)"
            ],
            "text/html": [
              "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=3, random_state=2023)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=3, random_state=2023)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rf_adm = RandomForestRegressor(max_depth=3, random_state=2023)\n",
        "rf_adm.fit(X_train_admission, Y_train_admission)\n",
        "\n",
        "regression_metrics(rf_adm.predict(X_test_admission), Y_test_admission)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdVKjieQ4_i6",
        "outputId": "4021075f-25fe-450e-c08e-5ef8237098d6"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE: 0.04782681790213267\n",
            "MSE: 0.003893526691951049\n",
            "RMSE: 0.062398130516475005\n",
            "R_squared: 0.7567848755697186\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SOAL 3b\n",
        "\n",
        "[5] Model Random Forest dianggap kurang dapat diinterpretasikan dibandingkan dengan Decision Tree. Apakah penyebab dari hasil tersebut?"
      ],
      "metadata": {
        "id": "_OkRxbjYUxTo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Model Random Forest** dibangun menggunakan beberapa decision tree secara independen. Setiap decision tree dalam Random Forest dibangun menggunakan subset data latih yang berbeda, sehingga setiap decision tree memiliki struktur dan prediksi yang berbeda. Hal ini membuat sulit untuk memahami bagaimana model Random Forest membuat keputusan.\n",
        "\n",
        "* **Model Random Forest** juga menggunakan voting untuk membuat prediksi. Pada saat melakukan prediksi, Random Forest akan menggunakan voting untuk menentukan kelas atau nilai yang paling mungkin. Hal ini membuat sulit untuk memahami bagaimana setiap decision tree berkontribusi terhadap prediksi final."
      ],
      "metadata": {
        "id": "F9Da2uprFkT4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SOAL 3c\n",
        "\n",
        "[5] Mekanisme voting dalam Random Forest Classifier adalah cara di mana model ini membuat prediksi akhir berdasarkan hasil dari beberapa Decision Tree yang membentuk ensemble-nya. Apakah yang membedakan mekanisme ini dengan mekanisme pengambil keputusan pada Decision Tree Classifier?"
      ],
      "metadata": {
        "id": "iCdQ4qGFWomy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "* Mekanisme pengambil keputusan pada **Decision Tree Classifier** adalah dengan mengikuti cabang-cabang pohon keputusan hingga mencapai daun, yang mewakili prediksi kelas. Pada setiap node, pohon keputusan akan memilih fitur dan nilai yang paling baik untuk membagi data menjadi dua set data yang lebih kecil. Proses ini dilakukan secara berulang hingga mencapai daun (nilai kategori).\n",
        "\n",
        "* Mekanisme voting dalam **Random Forest Classifier** adalah dengan menghitung jumlah suara yang diberikan oleh setiap Decision Tree untuk setiap kelas. Kelas dengan jumlah suara terbanyak akan menjadi prediksi akhir. Jadi, hal yang membedakan adalah dari jumlah Decision Tree dan cara pengambilan keputusan akhirnya"
      ],
      "metadata": {
        "id": "FIYx8cEoF_k_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SOAL 4 [15]\n",
        "\n",
        "* [5] Lakukan prediksi terhadap data *testing* dari permasalahan regresi (Dataset Admission Prediction) (`X_test`) menggunakan model yang sudah dibangun pada soal 1 dan 2.\n",
        "* [5] Lakukan evaluasi pada hasil prediksi yang didapat terhadap label aktual (`y_test`). Metrik evaluasi yang ditampilkan adalah nilai MAE, MSE, RMSE, dan $R^{2}$ dari hasil prediksi yang didapat.  \n",
        "* [5] Bandingkanlah hasil evaluasi dari kedua model yang sudah didapat dan tuliskan analisis singkat terkait dengan perbandingan tersebut (minimal 4 poin)."
      ],
      "metadata": {
        "id": "EE20Jm5KXGi3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "adm_pred2 = dtr_adm_2.predict(X_test_admission)\n",
        "\n",
        "regression_metrics(adm_pred2, Y_test_admission)"
      ],
      "metadata": {
        "id": "fxu0rFVZNZD1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e048231e-15db-4f93-84ce-10271dd1e468"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE: 0.05423554072938112\n",
            "MSE: 0.004651897304452626\n",
            "RMSE: 0.06820481877736079\n",
            "R_squared: 0.7094120905660506\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adm_pred2 = rf_adm.predict(X_test_admission)\n",
        "\n",
        "regression_metrics(adm_pred2, Y_test_admission)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQGvyCNW5j-o",
        "outputId": "e75372a1-3b9c-4b10-eb1f-c9abac2b4dc0"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE: 0.04782681790213267\n",
            "MSE: 0.003893526691951049\n",
            "RMSE: 0.062398130516475005\n",
            "R_squared: 0.7567848755697186\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SOAL 5 [15]\n",
        "\n",
        "* [5] Lakukan prediksi terhadap data *testing* dari permasalahan klasifikasi (Dataset Red Wine Prediction) (`X_test`) menggunakan model yang sudah dibangun pada soal 1 dan 2.\n",
        "* [5] Lakukan evaluasi pada hasil prediksi yang didapat terhadap label aktual (`y_test`). Metrik evaluasi yang ditampilkan adalah nilai Accuracy, Precision, Recall, dan F1-Score dari hasil prediksi yang didapat.  \n",
        "* [5] Bandingkanlah hasil evaluasi yang didapat dan tuliskan analisis singkat terkait dengan perbandingan tersebut (minimal 4 poin)."
      ],
      "metadata": {
        "id": "2c43pO0TXW7R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "red_pred1 = dtc_red_2.predict(X_test_red)\n",
        "\n",
        "classification_metrics(red_pred1, Y_test_red)"
      ],
      "metadata": {
        "id": "ImZkNRrgNo96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c826ac6-3748-4459-8de6-763ab914b2d7"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5043227665706052\n",
            "F1 Score: 0.49890891932476866\n",
            "Recall Score: 0.5079135448132686\n",
            "Precision Score: 0.534874684750168\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "red_pred2 = rf_red.predict(X_test_red)\n",
        "\n",
        "classification_metrics(red_pred2, Y_test_red)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVBAWKE_56gD",
        "outputId": "1b991e5a-42e5-4181-f087-68b495685528"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5720461095100865\n",
            "F1 Score: 0.53014422588943\n",
            "Recall Score: 0.5741072665999163\n",
            "Precision Score: 0.5785118680574375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SOAL 6 [15]\n",
        "\n",
        "Gunakan GridSearchCV untuk mencari hyperparameter yang baik untuk model Random Forest Regressor, Random Forest Classifier, Decision Tree Regressor, dan Decision Tree Classifier."
      ],
      "metadata": {
        "id": "w6pC9g6aXuiM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SOAL 6a\n",
        "[9]\n",
        "Proses Grid search diwajibkan melakukan tuning pada hyperparameter berikut: **criterion, max_depth, min_samples_split**.\n",
        "*Namun, kalian masih boleh mengambil hyperparameter lain.*"
      ],
      "metadata": {
        "id": "I9-t_z3AYC-6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest Regressor\n",
        "\n",
        "param_grid = {'criterion': ['squared_error', 'friedman_mse', 'absolute_error'],\n",
        "               'min_samples_split': [10, 20, 50],\n",
        "               'max_depth' : [5, 10, 12, None]}\n",
        "\n",
        "dtr = DecisionTreeRegressor()\n",
        "clf_dtr = GridSearchCV(estimator= dtr,\n",
        "                   param_grid=param_grid, cv= 5)\n",
        "\n",
        "clf_dtr.fit(X_train_admission, Y_train_admission)"
      ],
      "metadata": {
        "id": "gn0YhgwoNtU6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "b6d1285c-e456-4d5d-f088-1269e0793bdf"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, estimator=DecisionTreeRegressor(),\n",
              "             param_grid={'criterion': ['squared_error', 'friedman_mse',\n",
              "                                       'absolute_error'],\n",
              "                         'max_depth': [5, 10, 12, None],\n",
              "                         'min_samples_split': [10, 20, 50]})"
            ],
            "text/html": [
              "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=DecisionTreeRegressor(),\n",
              "             param_grid={&#x27;criterion&#x27;: [&#x27;squared_error&#x27;, &#x27;friedman_mse&#x27;,\n",
              "                                       &#x27;absolute_error&#x27;],\n",
              "                         &#x27;max_depth&#x27;: [5, 10, 12, None],\n",
              "                         &#x27;min_samples_split&#x27;: [10, 20, 50]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=DecisionTreeRegressor(),\n",
              "             param_grid={&#x27;criterion&#x27;: [&#x27;squared_error&#x27;, &#x27;friedman_mse&#x27;,\n",
              "                                       &#x27;absolute_error&#x27;],\n",
              "                         &#x27;max_depth&#x27;: [5, 10, 12, None],\n",
              "                         &#x27;min_samples_split&#x27;: [10, 20, 50]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest Classifier\n",
        "\n",
        "param_grid = {'criterion': ['gini', 'entropy', 'log_loss'],\n",
        "               'min_samples_split': [10, 20, 50],\n",
        "               'max_depth' : [5, 10, 12, None]}\n",
        "\n",
        "dtc = DecisionTreeClassifier()\n",
        "clf_dtc = GridSearchCV(estimator= dtc,\n",
        "                   param_grid=param_grid, cv= 5)\n",
        "\n",
        "clf_dtc.fit(X_train_red, Y_train_red)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "3D1mu_Wx-FO_",
        "outputId": "adaabde8-5e5d-4ca8-88a8-d93008832cdb"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(),\n",
              "             param_grid={'criterion': ['gini', 'entropy', 'log_loss'],\n",
              "                         'max_depth': [5, 10, 12, None],\n",
              "                         'min_samples_split': [10, 20, 50]})"
            ],
            "text/html": [
              "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=DecisionTreeClassifier(),\n",
              "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;, &#x27;log_loss&#x27;],\n",
              "                         &#x27;max_depth&#x27;: [5, 10, 12, None],\n",
              "                         &#x27;min_samples_split&#x27;: [10, 20, 50]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=DecisionTreeClassifier(),\n",
              "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;, &#x27;log_loss&#x27;],\n",
              "                         &#x27;max_depth&#x27;: [5, 10, 12, None],\n",
              "                         &#x27;min_samples_split&#x27;: [10, 20, 50]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest Regressor\n",
        "\n",
        "param_grid = {'criterion': ['squared_error', 'friedman_mse', 'absolute_error'],\n",
        "               'min_samples_split': [2, 5, 10],\n",
        "               'max_depth' : [5, 10, 12, None]}\n",
        "\n",
        "rfr = RandomForestRegressor()\n",
        "clf_rfr = GridSearchCV(estimator= rfr,\n",
        "                   param_grid=param_grid, cv= 5)\n",
        "\n",
        "clf_rfr.fit(X_train_admission, Y_train_admission)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "id": "ItLdfLfO-Zn5",
        "outputId": "118e78bc-85e9-4218-f2ca-0ea798f584fe"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, estimator=RandomForestRegressor(),\n",
              "             param_grid={'criterion': ['squared_error', 'friedman_mse',\n",
              "                                       'absolute_error'],\n",
              "                         'max_depth': [5, 10, 12, None],\n",
              "                         'min_samples_split': [2, 5, 10]})"
            ],
            "text/html": [
              "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=RandomForestRegressor(),\n",
              "             param_grid={&#x27;criterion&#x27;: [&#x27;squared_error&#x27;, &#x27;friedman_mse&#x27;,\n",
              "                                       &#x27;absolute_error&#x27;],\n",
              "                         &#x27;max_depth&#x27;: [5, 10, 12, None],\n",
              "                         &#x27;min_samples_split&#x27;: [2, 5, 10]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=RandomForestRegressor(),\n",
              "             param_grid={&#x27;criterion&#x27;: [&#x27;squared_error&#x27;, &#x27;friedman_mse&#x27;,\n",
              "                                       &#x27;absolute_error&#x27;],\n",
              "                         &#x27;max_depth&#x27;: [5, 10, 12, None],\n",
              "                         &#x27;min_samples_split&#x27;: [2, 5, 10]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest Classifier\n",
        "\n",
        "param_grid = {'criterion': ['gini', 'entropy'],\n",
        "               'min_samples_split': [2, 5, 10],\n",
        "               'max_depth' : [5, 10, 12, None]}\n",
        "\n",
        "rfc = RandomForestClassifier()\n",
        "clf_rfc = GridSearchCV(estimator= rfc,\n",
        "                   param_grid=param_grid, cv= 5)\n",
        "\n",
        "clf_rfc.fit(X_train_red, Y_train_red)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "id": "W9-D6GSW-s2C",
        "outputId": "0e55606c-abe1-4474-e90b-284365859f17"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
              "             param_grid={'criterion': ['gini', 'entropy'],\n",
              "                         'max_depth': [5, 10, 12, None],\n",
              "                         'min_samples_split': [2, 5, 10]})"
            ],
            "text/html": [
              "<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
              "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n",
              "                         &#x27;max_depth&#x27;: [5, 10, 12, None],\n",
              "                         &#x27;min_samples_split&#x27;: [2, 5, 10]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
              "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n",
              "                         &#x27;max_depth&#x27;: [5, 10, 12, None],\n",
              "                         &#x27;min_samples_split&#x27;: [2, 5, 10]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SOAL 6b\n",
        "[1]\n",
        "\n",
        "Tampilkan hyperparameter terbaik yang kalian dapatkan dari proses Grid Search untuk model Random Forest Regressor, Random Forest Classifier, Decision Tree Regressor, dan Decision Tree Classifier dari nomor 5a."
      ],
      "metadata": {
        "id": "Z2PbwARdYPYa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf_dtr.best_params_"
      ],
      "metadata": {
        "id": "IblBzKlgNuL5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c18efba-099b-4667-c345-372aa6309b10"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'criterion': 'squared_error', 'max_depth': 12, 'min_samples_split': 20}"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf_dtc.best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LslETqSc_mLd",
        "outputId": "117eeeea-b2ab-4611-e280-7227bf1964b3"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'criterion': 'log_loss', 'max_depth': None, 'min_samples_split': 10}"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf_rfr.best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XhVhXEK_pKw",
        "outputId": "6454ccbd-9f83-4aa2-8e3e-902fb78d5ef5"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'criterion': 'squared_error', 'max_depth': None, 'min_samples_split': 10}"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf_rfc.best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uM_ZUuOT_r8u",
        "outputId": "ab4f38c7-3c6b-45ae-fa28-e7f9bed59b1e"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2}"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SOAL 6c\n",
        "[2.5]\n",
        "\n",
        "Buatlah 2 model Random Forest (Random Forest Classifier dan Random Forest Regressor) dan 2 model Decision Tree (Decision Tree Classifier dan Decision Tree Regressor) berdasarkan hyperparameter yang kalian dapatkan dari **soal 5a**"
      ],
      "metadata": {
        "id": "FD6Jht9eYktq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest Regressor\n",
        "\n",
        "optimized_rf_regressor = RandomForestRegressor(**clf_rfr.best_params_)\n",
        "\n",
        "optimized_rf_regressor.fit(X_train_admission, Y_train_admission)"
      ],
      "metadata": {
        "id": "Cc5iczltNve1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "outputId": "13035280-8447-4e3e-8414-bfa163b0d521"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(min_samples_split=10)"
            ],
            "text/html": [
              "<style>#sk-container-id-10 {color: black;background-color: white;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(min_samples_split=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" checked><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(min_samples_split=10)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest Classifier\n",
        "\n",
        "optimized_rf_classifier = RandomForestClassifier(**clf_rfc.best_params_)\n",
        "\n",
        "optimized_rf_classifier.fit(X_train_red, Y_train_red)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "OZ48-hmWAMTH",
        "outputId": "8a137b64-248a-481d-e719-0804dd013dee"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier()"
            ],
            "text/html": [
              "<style>#sk-container-id-11 {color: black;background-color: white;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" checked><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Tree Regressor\n",
        "\n",
        "optimized_dt_regressor = DecisionTreeRegressor(**clf_dtr.best_params_)\n",
        "\n",
        "optimized_dt_regressor.fit(X_train_admission, Y_train_admission)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "PIL8duMJAd7M",
        "outputId": "7fc88b90-7b8a-4bad-fa1b-3c63722bba6c"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeRegressor(max_depth=12, min_samples_split=20)"
            ],
            "text/html": [
              "<style>#sk-container-id-12 {color: black;background-color: white;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeRegressor(max_depth=12, min_samples_split=20)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" checked><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor(max_depth=12, min_samples_split=20)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Tree Classifier\n",
        "\n",
        "optimized_dt_classifier = DecisionTreeClassifier(**clf_dtc.best_params_)\n",
        "\n",
        "optimized_dt_classifier.fit(X_train_red, Y_train_red)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "iApS88RLAt18",
        "outputId": "e98a3ce7-213a-44a8-dd63-f0ab1336dc1b"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(criterion='log_loss', min_samples_split=10)"
            ],
            "text/html": [
              "<style>#sk-container-id-13 {color: black;background-color: white;}#sk-container-id-13 pre{padding: 0;}#sk-container-id-13 div.sk-toggleable {background-color: white;}#sk-container-id-13 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-13 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-13 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-13 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-13 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-13 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-13 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-13 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-13 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-13 div.sk-item {position: relative;z-index: 1;}#sk-container-id-13 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-13 div.sk-item::before, #sk-container-id-13 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-13 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-13 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-13 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-13 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-13 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-13 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-13 div.sk-label-container {text-align: center;}#sk-container-id-13 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-13 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-13\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(criterion=&#x27;log_loss&#x27;, min_samples_split=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" checked><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(criterion=&#x27;log_loss&#x27;, min_samples_split=10)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SOAL 6d\n",
        "[2.5]\n",
        "\n",
        "Lakukan 4 buah prediksi (karena terdapat 4 model) dengan X_test dari masing-masing dataset dan **munculkan** hasil evaluasi terhadap label y_test dari masing-masing dataset.\n",
        "\n",
        "**Note**: Terdapat 2 function metrics, yakni `regression_metrics` dan `classification_metrics`.\n"
      ],
      "metadata": {
        "id": "WxFhMf8AYqBj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest Regressor\n",
        "\n",
        "rfr_pred = optimized_rf_regressor.predict(X_test_admission)\n",
        "\n",
        "regression_metrics(rfr_pred, Y_test_admission)"
      ],
      "metadata": {
        "id": "NGL7-HtANxEV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cba5c1a1-42c6-43b2-9311-c3c5e697b15a"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE: 0.04446211510833015\n",
            "MSE: 0.0033638956800332446\n",
            "RMSE: 0.057999100682969595\n",
            "R_squared: 0.7898690901282107\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest Classifier\n",
        "\n",
        "rfc_pred = optimized_rf_classifier.predict(X_test_red)\n",
        "\n",
        "classification_metrics(rfc_pred, Y_test_red)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3F-ttcJBPYQ",
        "outputId": "4e21379d-83d0-4b9c-ca94-7352fd133a6a"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8530259365994236\n",
            "F1 Score: 0.8438073833034417\n",
            "Recall Score: 0.8473811079432961\n",
            "Precision Score: 0.8432134338750096\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Tree Regressor\n",
        "\n",
        "dtr_pred = optimized_dt_regressor.predict(X_test_admission)\n",
        "\n",
        "regression_metrics(dtr_pred, Y_test_admission)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aor_UxVTBXTt",
        "outputId": "6ff2c47a-f240-4bd1-d668-1c0dc7a068f3"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE: 0.05681643544180033\n",
            "MSE: 0.0054691650026612\n",
            "RMSE: 0.07395380316563308\n",
            "R_squared: 0.6583602086504694\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Tree Classifier\n",
        "\n",
        "dtc_pred = optimized_dt_classifier.predict(X_test_red)\n",
        "\n",
        "classification_metrics(dtc_pred, Y_test_red)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noEkprnUBikq",
        "outputId": "22226750-890a-4243-b8f8-18f1eb224695"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7435158501440923\n",
            "F1 Score: 0.7407017995460329\n",
            "Recall Score: 0.7388955179660365\n",
            "Precision Score: 0.7442977151568625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SOAL 7 [5]\n",
        "1. [2] Jelaskan konsep bootstrapping dalam konteks Random Forests. Bagaimana hal ini berkontribusi pada keragaman dari berbagai decision trees yang terbentuk?\n",
        "2. [1] Bagaimana prediksi dari seluruh Decision Tree Regressor digabungkan dalam Random Forest Regressor?\n",
        "3. [2] Jelaskanlah bagaimana Random Forest dapat digunakan untuk masalah klasifikasi multi-kelas, seperti pada kasus prediksi kelas Red Wine pada Lab 4 ini."
      ],
      "metadata": {
        "id": "xQUbE0GUZIH5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LT3wjqGWHFXk"
      },
      "source": [
        "**1. Bootstrap Random Forest**\n",
        "\n",
        "Bootstrapping adalah metode untuk menghasilkan sampel data baru dari sampel data asli. Dalam konteks Random Forests, bootstrapping digunakan untuk menghasilkan sejumlah sampel data baru dari sampel data asli. Setiap sampel data baru ini disebut sebagai bootstrap sample.\n",
        "\n",
        "Dalam Random Forests, bootstrapping digunakan untuk melatih sejumlah decision trees. Setiap decision tree dilatih pada bootstrap sample yang berbeda. Hal ini dilakukan untuk meningkatkan keragaman dari berbagai decision trees yang terbentuk.\n",
        "\n",
        "Keragaman dari berbagai decision trees yang terbentuk berkontribusi pada peningkatan akurasi dan robustness dari Random Forests. Hal ini dikarenakan setiap decision tree akan memiliki kekuatan dan kelemahannya masing-masing. Dengan memiliki sejumlah decision trees yang berbeda, Random Forests dapat mengurangi efek dari kesalahan yang terjadi pada satu decision tree.\n",
        "\n",
        "Berikut adalah penjelasan lebih lanjut tentang bagaimana bootstrapping berkontribusi pada keragaman dari berbagai decision trees yang terbentuk:\n",
        "\n",
        "**Random sampling**\n",
        "Saat bootstrapping dilakukan, data disampling secara acak dari sampel data asli. Hal ini menyebabkan setiap bootstrap sample memiliki data yang berbeda dengan bootstrap sample lainnya.\n",
        "\n",
        "**Replacement**\n",
        "Data dapat disampling secara acak dengan atau tanpa replacement. Jika dilakukan dengan replacement, data dapat muncul lebih dari satu kali dalam bootstrap sample yang sama. Hal ini juga berkontribusi pada keragaman dari bootstrap sample.\n",
        "\n",
        "**Random feature sampling**\n",
        "Dalam Random Forests, setiap decision tree dilatih pada subset dari fitur-fitur yang ada. Fitur-fitur dipilih secara acak dari seluruh fitur yang ada. Hal ini juga berkontribusi pada keragaman dari berbagai decision trees yang terbentuk.\n",
        "\n",
        "Secara umum, bootstrapping adalah teknik yang penting dalam Random Forests. Teknik ini berkontribusi pada peningkatan akurasi dan robustness dari Random Forests dengan meningkatkan keragaman dari berbagai decision trees yang terbentuk..\n",
        "\n",
        "**2. Penggabungan Prediksi**\n",
        "\n",
        "Dalam Random Forest Regressor, prediksi dari seluruh decision trees digabungkan dengan menggunakan rata-rata. Hal ini dilakukan untuk menghasilkan prediksi yang lebih akurat dan stabil.\n",
        "\n",
        "Misalnya, jika ada 100 decision trees dalam ensemble, maka prediksi final untuk sebuah titik data adalah rata-rata dari prediksi 100 decision trees tersebut.\n",
        "\n",
        "Secara sederhana, prediksi dari setiap decision tree merupakan prediksi nilai target untuk sebuah titik data. Prediksi final dari Random Forest Regressor adalah rata-rata dari prediksi dari seluruh decision trees.\n",
        "\n",
        "Proses ini dilakukan untuk mengurangi varians dari prediksi, sehingga menghasilkan prediksi yang lebih akurat dan stabil.\n",
        "\n",
        "**3. Random Forest dalam klasifikasi Multi-Kelas**\n",
        "\n",
        "Dalam konteks klasifikasi multi-kelas, seperti prediksi kelas Red Wine, setiap pohon dalam Random Forest akan memberikan sebuah \"vote\" untuk setiap kelas yang mungkin. Kelas dengan vote terbanyak dari semua pohon dalam hutan dianggap sebagai prediksi akhir.\n",
        "\n",
        "Sebagai contoh, anggap kita memiliki masalah klasifikasi dengan 3 kelas: A, B, dan C. Jika kita memiliki Random Forest dengan 100 pohon, dan untuk suatu contoh, 50 pohon memprediksi kelas A, 30 memprediksi kelas B, dan 20 memprediksi kelas C, maka prediksi akhir untuk contoh tersebut akan menjadi kelas A, karena itu adalah kelas dengan vote terbanyak.\n",
        "\n",
        "Hal ini memungkinkan Random Forest untuk menangani masalah klasifikasi multi-kelas dengan efisien, memanfaatkan \"kekuatan dari banyak pohon\" untuk memberikan prediksi yang lebih kuat dan akurat."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SOAL 8 [5]\n",
        "\n",
        "1. [2.5] Random Forest memasukkan unsur *randomness* melalui bootstrapping dan *feature selection*. Bagaimanakah hal ini dapat memengaruhi reproduksibilitas hasil, dan apa yang dapat dilakukan untuk memastikan *output* yang konsisten?\n",
        "2. [2.5] Apakah *scaling* atau *feature normalization* diperlukan untuk Random Forest? Mengapa atau mengapa tidak?"
      ],
      "metadata": {
        "id": "M9Kf55-Zbsnb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Unsur randomness dalam Random Forest dapat memengaruhi reproduksibilitas hasil dalam:\n",
        "* Perubahan sampel bootstrap  \n",
        "Bootstrapping adalah proses pengambilan sampel ulang dengan pengembalian dari data pelatihan. Setiap kali bootstrapping dilakukan, sampel yang dihasilkan mungkin berbeda. Hal ini dapat menyebabkan perbedaan dalam model yang dilatih, dan akhirnya menghasilkan hasil yang berbeda.\n",
        "\n",
        "* Perubahan pemilihan fitur  \n",
        "Pada setiap node decision tree, fitur yang digunakan untuk membagi data dipilih secara acak dari daftar semua fitur. Hal ini dapat menyebabkan perbedaan dalam model yang dilatih, dan akhirnya menghasilkan hasil yang berbeda.\n",
        "\n",
        "2. Scaling atau Feature Normalization untuk Random Forest**\n",
        "\n",
        "*Scaling* atau *feature normalization* umumnya **tidak diperlukan** untuk Random Forest. Alasan utamanya adalah:\n",
        "\n",
        "- **Karakteristik**: Random Forest terdiri dari decision tree. decision tree membagi sampel berdasarkan pemisahan pada nilai variabel, bukan pada jarak antar titik data. Oleh karena itu, mereka cenderung tidak peka terhadap perbedaan skala antar fitur.\n",
        "  \n",
        "- **Pemisahan Berdasarkan Nilai**: Karena pemisahan pada pohon dilakukan berdasarkan nilai dari suatu fitur dan bukan berdasarkan jarak, *scaling* fitur tidak akan mengubah cara pohon membuat keputusan."
      ],
      "metadata": {
        "id": "GFwh-hlsEIvx"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "p9cZkSNOLL2C",
        "6sTzwrwcERjY"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}